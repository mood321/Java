###   Mysql  学习记录
#### Server层和存储引擎层

<img src="https://s2.ax1x.com/2019/12/05/QGhBNV.png" alt="QGhBNV.png" border="0" />
<p>Server层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖MySQL的大多数核心服务功能，以及所有的内置函数（如日期、时间、
<p>数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。
<p>而存储引擎层负责数据的存储和提取。其架构模式是插件式的，支持InnoDB、MyISAM、Memory等多个存储引擎。现在最常用的存储引擎是
<p>InnoDB，它从MySQL 5.5.5版本开始成为了默认存储引擎。
<p>也就是说，你执行create table建表的时候，如果不指定引擎类型，默认使用的就是InnoDB。不过，你也可以通过指定存储引擎的类型来
<p>选择别的引擎，比如在create table语句中使用engine=memory, 来指定使用内存引擎创建表。不同存储引擎的表数据存取方式不同，
<p>支持的功能也不同，在后面的文章中，我们会讨论到引擎的选择。
<p>不同的存储引擎共用一个Server层，也就是从连接器到执行器的部分
<p> 1 连接器 第一步，你会先连接到这个数据库上，这时候接待你的就是连接器。连接器负责跟客户端建立连接、获取权限、维持和管理连接
<p> ps:客户端如果太长时间没动静，连接器就会自动将它断开。这个时间是由参数wait_timeout控制的，默认值是8小时
<p>解决这个问题呢？你可以考虑以下两种方案。
<p> 1 定期断开长连接。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连。
<p> 2 如果你用的是MySQL 5.7或更新版本，可以在每次执行一个比较大的操作后，通过执行 mysql_reset_connection来重新初始化连接资源。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。

<p> 2 查询缓存 
<p> MySQL拿到一个查询请求后，会先到查询缓存看看，之前是不是执行过这条语句。之前执行过的语句及其结果可能会以key-value对的形式，被直接缓存在内存中。key是查询的语句，value是查询的结果。如果你的查询能够直接在这个缓存中找到key，那么这个value就会被直接返回给客户端
<p> ps： 每次操作后 整个表缓存会失效  (不推荐用本身的缓存) and 数据会在8之后 取消了缓存   

<p> 3 分析器
<p>     如果没有命中查询缓存，就要开始真正执行语句了。首先，MySQL需要知道你要做什么，因此需要对SQL语句做解析
<p> ps: 这一步会检查语法错误 “You have an error in your SQL syntax”的错误提醒

<p> 4 优化器
<p> MySQL就知道你要做什么了。在开始执行之前，还要先经过优化器的处理。
<p>   优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序
<p> 1、选择最合适的索引；
 <p>2、选择表扫还是走索引；
<p> 3、选择表关联顺序；
<p> 4、优化 where 子句；
<p> 5、排除管理中无用表；
<p> 6、决定 order by 和 group by 是否走索引；
<p> 7、尝试使用 inner join 替换 outer join；
<p> 8、简化子查询，决定结果缓存；
<p> 9、合并试图；

<p> 5  执行器
<p> 进入了执行器阶段，开始执行语句 会判断是否有执行的权限 
<pre><code>
select * from T where ID=10;
</code></pre>
<p>如果有权限，就打开表继续执行。打开表的时候，执行器就会根据表的引擎定义，去使用这个引擎提供的接口。
<p>比如我们这个例子中的表T中，ID字段没有索引，那么执行器的执行流程是这样的：
<p>调用InnoDB引擎接口取这个表的第一行，判断ID值是不是10，如果不是则跳过，如果是则将这行存在结果集中；
<p>调用引擎接口取“下一行”，重复相同的判断逻辑，直到取到这个表的最后一行。
<p>执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端。
<p>至此，这个语句就执行完成了  

<p>对于有索引的表，执行的逻辑也差不多。第一次调用的是“取满足条件的第一行”这个接口，
<p>之后循环取“满足条件的下一行”这个接口，这些接口都是引擎中已经定义好的。
<p>你会在数据库的慢查询日志中看到一个rows_examined的字段，表示这个语句执行过程中扫描了多少行。
<p>这个值就是在执行器每次调用引擎获取数据行的时候累加的。


### redo log（重做日志）和 binlog（归档日志）
#### 重要的日志模块：redo log
<p>1 就是MySQL里经常说到的WAL技术，WAL的全称是Write-Ahead Logging，它的关键点就是先写日志，再写磁盘
<p>2 具体来说，当有一条记录需要更新的时候，InnoDB引擎就会先把记录写到redo log（粉板）里面，并更新内存，这个时候更新就算完成了。
<p>同时，InnoDB引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做
<p> 如果日志满了  会把一部分记录写到磁盘 腾出空间 让后面日志可以继续写
<p> InnoDB的redo log是固定大小的，比如可以配置为一组4个文件，每个文件的大小是1GB，总共就可以记录4GB的操作
<p>3  crash-safe
 <p>write pos是当前记录的位置，一边写一边后移，写到第3号文件末尾后就回到0号文件开头。checkpoint是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。  
<p>write pos和checkpoint之间的是“粉板”上还空着的部分，可以用来记录新的操作。如果write pos追上checkpoint，表示“粉板”满了，这时候不能再执行新的更新，得停下来先擦掉一些记录，把checkpoint推进一下。
<p>有了redo log，InnoDB就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为crash-safe

#### 重要的日志模块：binlog
<p>MySQL整体来看，其实就有两块：一块是Server层，它主要做的是MySQL功能层面的事情；还有一块是引擎层，负责存储相关的具体事宜。
<p>上面我们聊到的粉板redo log是InnoDB引擎特有的日志，而Server层也有自己的日志，称为binlog（归档日志）
<p>这两种日志有以下三点不同。

<p>redo log是InnoDB引擎特有的；binlog是MySQL的Server层实现的，所有引擎都可以使用。

<p>redo log是物理日志，记录的是“在某个数据页上做了什么修改”；binlog是逻辑日志，记录的是这个语句的原始逻辑，比如“给ID=2这一行的c字段加1 ”。

<p>redo log是循环写的，空间固定会用完；binlog是可以追加写入的。“追加写”是指binlog文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。

<p>有了对这两个日志的概念性理解，我们再来看执行器和InnoDB引擎在执行这个简单的update语句时的内部流程。

<p>执行器先找引擎取ID=2这一行。ID是主键，引擎直接用树搜索找到这一行。如果ID=2这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。

<p>执行器拿到引擎给的行数据，把这个值加上1，比如原来是N，现在就是N+1，得到新的一行数据，再调用引擎接口写入这行新数据。

<p>引擎将这行新数据更新到内存中，同时将这个更新操作记录到redo log里面，此时redo log处于prepare状态。然后告知执行器执行完成了，随时可以提交事务。

<p>执行器生成这个操作的binlog，并把binlog写入磁盘。

<p>执行器调用引擎的提交事务接口，引擎把刚刚写入的redo log改成提交（commit）状态，更新完成。

#### 两阶段提交
<p>由于redo log和binlog是两个独立的逻辑，如果不用两阶段提交，要么就是先写完redo log再写binlog，或者采用反过来的顺序。我们看看这两种方式会有什么问题。

<p>仍然用前面的update语句来做例子。假设当前ID=2的行，字段c的值是0，再假设执行update语句过程中在写完第一个日志后，第二个日志还没有写完期间发生了crash，会出现什么情况呢？

<p>先写redo log后写binlog。假设在redo log写完，binlog还没有写完的时候，MySQL进程异常重启。由于我们前面说过的，redo log写完之后，系统即使崩溃，仍然能够把数据恢复回来，所以恢复后这一行c的值是1。
<p>但是由于binlog没写完就crash了，这时候binlog里面就没有记录这个语句。因此，之后备份日志的时候，存起来的binlog里面就没有这条语句。
<p>然后你会发现，如果需要用这个binlog来恢复临时库的话，由于这个语句的binlog丢失，这个临时库就会少了这一次更新，恢复出来的这一行c的值就是0，与原库的值不同。

<p>先写binlog后写redo log。如果在binlog写完之后crash，由于redo log还没写，崩溃恢复以后这个事务无效，所以这一行c的值是0。但是binlog里面已经记录了“把c从0改成1”这个日志。所以，在之后用binlog来恢复的时候就多了一个事务出来，恢复出来的这一行c的值就是1，与原库的值不同。

<p>可以看到，如果不使用“两阶段提交”，那么数据库的状态就有可能和用它的日志恢复出来的库的状态不一致。


### 事物
#### 隔离性与隔离级别
<p>提到事务，你肯定会想到ACID（Atomicity、Consistency、Isolation、Durability，即原子性、一致性、隔离性、持久性），
今天我们就来说说其中I，也就是“隔离性”。

<p>当数据库上有多个事务同时执行的时候，就可能出现脏读（dirty read）、不可重复读（non-repeatable read）、幻读（phantom read）的问题，
<p>为了解决这些问题，就有了“隔离级别”的概念。

<p>在谈隔离级别之前，你首先要知道，你隔离得越严实，效率就会越低。因此很多时候，我们都要在二者之间寻找一个平衡点。SQL标准的事务隔离级别包括：
<p>读未提交（read uncommitted）、读提交（read committed）、可重复读（repeatable read）和串行化（serializable ）。下面我逐一为你解释：
    <li>读未提交是指，一个事务还没提交时，它做的变更就能被别的事务看到。
    <li>读提交是指，一个事务提交之后，它做的变更才会被其他事务看到。
    <li>可重复读是指，一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。
    <li>串行化，顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。
 <p> 现在有两个事物同时启动   
<table>
 <tr> <td>事物1</td><td>事物2</td>    </tr>
 <tr> <td>启动事物1 得到值1</td><td>启动事物2</td>    </tr>
 <tr> <td></td><td>得到值1</td>    </tr>
 <tr> <td></td><td>将1改成2</td>    </tr>
 <tr> <td>查询值V1</td><td></td>    </tr>
 <tr> <td></td><td>提交事物2</td>    </tr>
 <tr> <td>查询得到值V2</td><td></td>    </tr>
 <tr> <td>提交事物1</td><td></td>    </tr>
 <tr> <td>查询得到值V3</td><td></td>    </tr>
 </table>
 
<p> 我们来看看在不同的隔离级别下，事务A会有哪些不同的返回结果，也就是图里面V1、V2、V3的返回值分别是什么。
 
 <li>若隔离级别是“读未提交”， 则V1的值就是2。这时候事务B虽然还没有提交，但是结果已经被A看到了。因此，V2、V3也都是2。
<li> 若隔离级别是“读提交”，则V1是1，V2的值是2。事务B的更新在提交后才能被A看到。所以， V3的值也是2。
<li 若隔离级别是“可重复读”，则V1、V2是1，V3是2。之所以V2还是1，遵循的就是这个要求：事务在执行期间看到的数据前后必须是一致的。
<li> 若隔离级别是“串行化”，则在事务B执行“将1改成2”的时候，会被锁住。直到事务A提交后，事务B才可以继续执行。所以从A的角度看， V1、V2值是1，V3的值是2。
<p> 在实现上，数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。在“可重复读”隔离级别下，这个视图是在事务启动时创建的，
<p>整个事务存在期间都用这个视图。在“读提交”隔离级别下，这个视图是在每个SQL语句开始执行的时候创建的。这里需要注意的是，
<p>“读未提交”隔离级别下直接返回记录上的最新值，没有视图概念；而“串行化”隔离级别下直接用加锁的方式来避免并行访问。
 
<p> 我们可以看到在不同的隔离级别下，数据库行为是有所不同的。Oracle数据库的默认隔离级别其实就是“读提交”，因此对于一些从Oracle迁移到MySQL的应用，
<p>为保证数据库隔离级别的一致，你一定要记得将MySQL的隔离级别设置为“读提交”。
 
 <p>配置的方式是，将启动参数transaction-isolation的值设置成READ-COMMITTED。你可以用show variables来查看当前的值。
 
####  事务隔离的实现
<p>假设一个值从1被按顺序改成了2、3、4，当前值是4，但是在查询这条记录的时候，不同时刻启动的事务会有不同的read-view。
<p>如图中看到的，在视图A、B、C里面，这一个记录的值分别是1、2、4，同一条记录在系统中可以存在多个版本，就是数据库的多版本并发控制（MVCC）。
<p>对于read-view A，要得到1，就必须将当前值依次执行图中所有的回滚操作得到。
<p> 同时你会发现，即使现在有另外一个事务正在将4改成5，这个事务跟read-view A、B、C对应的事务是不会冲突的。
<p> 你一定会问，回滚日志总不能一直保留吧，什么时候删除呢？答案是，在不需要的时候才删除。也就是说，系统会判断，当没有事务再需要用到这些回滚日志时，
<p>回滚日志会被删除。
<p> 什么时候才不需要了呢？就是当系统里没有比这个回滚日志更早的read-view的时候。
 <p> ps： 少用长事物

#### MVCC 
<a href="https://www.cnblogs.com/AnXinliang/p/9955331.html">MVCC并发控制</a>
<p> 他本质就是处理数据的版本号和自己事物的版本号  来判断状态
<p>版本号
<li>系统版本号：是一个递增的数字，每开始一个新的事务，系统版本号就会自动递增。
<li>事务版本号：事务开始时的系统版本号。
<p>隐藏的列
<li>MVCC 在每行记录后面都保存着两个隐藏的列，用来存储两个版本号：

<li>创建版本号：指示创建一个数据行的快照时的系统版本号；
<li>删除版本号：如果该快照的删除版本号大于当前事务版本号表示该快照有效，否则表示该快照已经被删除了。
<p>Undo 日志
<li>MVCC 使用到的快照存储在 Undo 日志中，该日志通过回滚指针把一个数据行（Record）的所有快照连接起来。
<p>实现过程
<p>以下实现过程针对可重复读隔离级别。

<p>当开始新一个事务时，该事务的版本号肯定会大于当前所有数据行快照的创建版本号，理解这一点很关键。

<p>1. SELECT

<p>多个事务必须读取到同一个数据行的快照，并且这个快照是距离现在最近的一个有效快照。但是也有例外，如果有一个事务正在修改该数据行，
<p>那么它可以读取事务本身所做的修改，而不用和其它事务的读取结果一致。
<p>把没有对一个数据行做修改的事务称为 T，T 所要读取的数据行快照的创建版本号必须小于 T 的版本号，因为如果大于或者等于 T 的版本号，
<p>那么表示该数据行快照是其它事务的最新修改，因此不能去读取它。除此之外，T 所要读取的数据行快照的删除版本号必须大于 T 的版本号，
<p>因为如果小于等于 T 的版本号，那么表示该数据行快照是已经被删除的，不应该去读取它。

<p>2. INSERT
<p>将当前系统版本号作为数据行快照的创建版本号。

<p>3. DELETE
<p>将当前系统版本号作为数据行快照的删除版本号。

<p>4. UPDATE
<p>将当前系统版本号作为更新前的数据行快照的删除版本号，并将当前系统版本号作为更新后的数据行快照的创建版本号。可以理解为先执行 DELETE 后执行 INSERT。

<p>Next-Key Locks
<p>Next-Key Locks 是 MySQL 的 InnoDB 存储引擎的一种锁实现。

<p>MVCC 不能解决幻读的问题，Next-Key Locks 就是为了解决这个问题而存在的。在可重复读（REPEATABLE READ）隔离级别下，使用 MVCC + Next-Key Locks 可以解决幻读问题。

<p>Record Locks  (记录锁)
<p>锁定一个记录上的索引，而不是记录本身。

<p>如果表没有设置索引，InnoDB 会自动在主键上创建隐藏的聚簇索引，因此 Record Locks 依然可以使用。

<p>Gap Locks (间隙锁)
<p>锁定索引之间的间隙，但是不包含索引本身。例如当一个事务执行以下语句，其它事务就不能在 t.c 中插入 15。
<pre><code>
SELECT c FROM t WHERE c BETWEEN 10 and 20 FOR UPDATE;     </code></pre>
<p>Next-Key Locks (区间锁)
<p>它是 Record Locks 和 Gap Locks 的结合，不仅锁定一个记录上的索引，也锁定索引之间的间隙。例如一个索引包含以下值：10, 11, 13, and 20，那么就需要锁定以下区间：
 <pre><code>
(negative infinity, 10]
(10, 11]
(11, 13]
(13, 20]
(20, positive infinity)   </code></pre>

### 事务的启动方式
<p>1 显式启动事务语句， begin 或 start transaction。配套的提交语句是commit，回滚语句是rollback。

<p>2 set autocommit=0，这个命令会将这个线程的自动提交关掉。意味着如果你只执行一个select语句，这个事务就启动了，而且并不会自动提交。
<p>这个事务持续存在直到你主动执行commit 或 rollback 语句，或者断开连接。

<p> ps: 推荐手动去开启 提交

### 索引
<p>索引的出现其实就是为了提高数据查询的效率，就像书的目录一样

####索引的常见模型
<p> 1 哈希表
<p>一种以键-值（key-value）存储数据的结构，我们只要输入待查找的值即key，就可以找到其对应的值即Value。哈希的思路很简单，
<p>把值放在数组里，用一个哈希函数把key换算成一个确定的位置，然后把value放在数组的这个位置。
 <p> 不可避免地，多个key值经过哈希函数的换算，会出现同一个值的情况。处理这种情况的一种方法是，拉出一个链表。
 <p> ps : 解决hash冲突: 1 开放定址（没看懂） 2 再hash  3 hashmap 所用的链表 4 公共溢出区
 <p> 哈希表这种结构适用于只有等值查询的场景，比如Memcached及其他一些NoSQL引擎。
 <p> 2 有序数组
 <p> 有序数组在等值查询和范围查询场景中的性能就都非常优秀 
 <p> 仅仅看查询效率，有序数组就是最好的数据结构了。但是，在需要更新数据的时候就麻烦了，你往中间插入一个记录就必须得挪动后面所有的记录，成本太高
 <p> 有序数组索引只适用于静态存储引擎，比如你要保存的是2017年某个城市的所有人口信息，这类不会再修改的数据
 
 <p> 3 二叉搜索树(或者多叉)
 <p> 查询复杂度是O(log(N))，你就需要保持这棵树是平衡二叉树。为了做这个保证，更新的时间复杂度也是O(log(N))
 <p>树可以有二叉，也可以有多叉。多叉树就是每个节点有多个儿子，儿子之间的大小保证从左到右递增。二叉树是搜索效率最高的，
 <p>但是实际上大多数的数据库存储却并不使用二叉树。其原因是，索引不止存在内存中，还要写到磁盘上 , 二叉树从磁盘加载到内存效率太低
 
 #### InnoDB 的索引模型
 <p> 索引类型分为主键索引和非主键索引。
 <p>     主键索引的叶子节点存的是整行数据。在InnoDB里，主键索引也被称为聚簇索引（clustered index）。
 <p>     非主键索引的叶子节点内容是主键的值。在InnoDB里，非主键索引也被称为二级索引（secondary index）。
  <p>    根据上面的索引结构说明，我们来讨论一个问题：基于主键索引和普通索引的查询有什么区别？
  <li>    如果语句是select * from T where ID=500，即主键查询方式，则只需要搜索ID这棵B+树；
  <li>   如果语句是select * from T where k=5，即普通索引查询方式，则需要先搜索k索引树，得到ID的值为500，再到ID索引树搜索一次。这个过程称为回表。
<p>   也就是说，基于非主键索引的查询需要多扫描一棵索引树。因此，我们在应用中应该尽量使用主键查询。

#### 索引维护
<p> B+树为了维护索引有序性，在插入新值的时候需要做必要的维护。如果插入新的行ID值为700，则只需要在R5的记录后面插入一个新记录。
<p>如果新插入的ID值为400，就相对麻烦了，需要逻辑上挪动后面的数据，空出位置。
 
 <p>而更糟的情况是，如果R5所在的数据页已经满了，根据B+树的算法，这时候需要申请一个新的数据页，然后挪动部分数据过去。
 <p>这个过程称为页分裂。在这种情况下，性能自然会受影响
<p> 分裂就有合并。当相邻两个页由于删除了数据，利用率很低之后，会将数据页做合并。合并的过程，可以认为是分裂过程的逆过程
<p> 1 用自增主键的插入数据模式，正符合了我们前面提到的递增插入的场景。每次插入一条新记录，都是追加操作，都不涉及到挪动其他记录，也不会触发叶子节点的分裂
<p> 2 用业务逻辑的字段做主键，则往往不容易保证有序插入，这样写数据成本相对较高。

### 
<img src="https://static001.geekbang.org/resource/image/dc/8d/dcda101051f28502bd5c4402b292e38d.png"/>
<p>  如果我执行 select * from T where k between 3 and 5，需要执行几次树的搜索操作，会扫描多少行？
<p> 这条SQL查询语句的执行流程：
<p>    在k索引树上找到k=3的记录，取得 ID = 300；
<p>    再到ID索引树查到ID=300对应的R3；
<p>    在k索引树取下一个值k=5，取得ID=500；
<p>    再回到ID索引树查到ID=500对应的R4；
<p>    在k索引树取下一个值k=6，不满足条件，循环结束。
<p>    在这个过程中，回到主键索引树搜索的过程，我们称为回表。可以看到，这个查询过程读了k索引树的3条记录（步骤1、3和5），回表了两次（步骤2和4）。
<p>    在这个例子中，由于查询结果所需要的数据只在主键索引上有，所以不得不回表。那么，有没有可能经过索引优化，避免回表过程呢？


#### 覆盖索引
<p> 如果执行的语句是select ID from T where k between 3 and 5，这时只需要查ID的值，而ID的值已经在k索引树上了，因此可以直接提供查询结果，
不需要回表。也就是说，在这个查询里面，索引k已经“覆盖了”我们的查询需求，我们称为覆盖索引。

<p> 由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段。
  
#### 最左前缀原则
<img src="https://static001.geekbang.org/resource/image/89/70/89f74c631110cfbc83298ef27dcd6370.jpg"/>
<p>如果有一个 2 列的索引 (col1, col2)，则已经对 (col1)、(col1, col2) 上建立了索引；
<p>如果有一个 3 列索引 (col1, col2, col3)，则已经对 (col1)、(col1, col2)、(col1, col2, col3) 上建立了索引；

<p>mysql 查询优化器
<p>如果建的索引是 (name, cid)。而查询的语句是 cid=1 AND name=’小红’。为什么还能利用到索引？
<p>当按照索引中所有列进行精确匹配（“=” 或 “IN”）时，索引可以被用到，并且 type 为 const。理论上索引对顺序是敏感的，但是由于 MySQL 的查询优化器会自动调整 where 子句的条件顺序以使用适合的索引，所以 MySQL 不存在 where 子句的顺序问题而造成索引失效
  
<p>  注意事项
  
<li>  范围查询
<p>  mysql 会一直向右匹配直到遇到范围查询（>、<、between、like）就停止匹配。范围列可以用到索引，但是范围列后面的列无法用到索引。即，索引最多用于一个范围列，因此如果查询条件中有两个范围列则无法全用到索引
 <li> like 语句的索引问题
<p>  如果通配符 % 不出现在开头，则可以用到索引，但根据具体情况不同可能只会用其中一个前缀
<p>  在 like “value%” 可以使用索引，但是 like “%value%” 不会使用索引，走的是全表扫描
<li>  不要在列上进行运算
<p>  如果查询条件中含有函数或表达式，将导致索引失效而进行全表扫描
 <p> 例如 select * from user where YEAR(birthday) < 1990
 <p> 可以改造成 select * from users where birthday <’1990-01-01′
<li>  索引不会包含有 NULL 值的列
<p>  只要列中包含有 NULL 值都将不会被包含在索引中，复合索引中只要有一列含有 NULL 值，那么这一列对于此复合索引就是无效的。所以在数据库设计时不要让字段的默认值为 NULL
<p>  尽量选择区分度高的列作为索引，区分度的公式是 count(distinct col)/count(*)，表示字段不重复的比例，
<p>比例越大我们扫描的记录数越少，唯一键的区分度是 1，而一些状态、性别字段可能在大数据面前区分度就是 0。一般需要 join 的字段都要求区分度 0.1 以上，即平均 1 条扫描 10 条记录
<li>  覆盖索引的好处
<p>  如果一个索引包含所有需要的查询的字段的值，我们称之为覆盖索引。覆盖索引是非常有用的工具，能够极大的提高性能。因为，只需要读取索引，而无需读表，极大减少数据访问量

#### 索引下推
<p>如果现在有一个需求：检索出表中“名字第一个字是张，而且年龄是10岁的所有男孩”。那么，SQL语句是这么写的：
<pre><code>
mysql> select * from tuser where name like '张%' and age=10 and ismale=1;
</code></pre>

<p>在MySQL 5.6之前，只能从ID3开始一个个回表。到主键索引上找出数据行，再对比字段值。

<p>而MySQL 5.6 引入的索引下推优化（index condition pushdown)， 可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。
 <img src="https://static001.geekbang.org/resource/image/b3/ac/b32aa8b1f75611e0759e52f5915539ac.jpg"/>
 <p>无下推流程
 <img src="https://static001.geekbang.org/resource/image/76/1b/76e385f3df5a694cc4238c7b65acfe1b.jpg"/>
 <p>有下推流程
 
 
 ### 锁
 <p> 数据库锁设计的初衷是处理并发问题。作为多用户共享的资源，当出现并发访问的时候，数据库需要合理地控制资源的访问规则。而锁就是用来实现这些访问规则的重要数据结构。
<p>根据加锁的范围，MySQL里面的锁大致可以分成全局锁、表级锁和行锁三类 

####  全局锁
<p>MySQL提供了一个加全局读锁的方法，命令是 Flush tables with read lock (FTWRL)。当你需要让整个库处于只读状态的时候，
<p>可以使用这个命令，之后其他线程的以下语句会被阻塞：数据更新语句（数据的增删改）、数据定义语句（包括建表、修改表结构等）和更新类事务的提交语句。

<p>全局锁的典型使用场景是，做全库逻辑备份

<p> 对主从库备份的问题
<li>如果你在主库上备份，那么在备份期间都不能执行更新，业务基本上就得停摆；
<li>如果你在从库上备份，那么备份期间从库不能执行主库同步过来的binlog，会导致主从延迟
<p> 不加锁备份的问题
<p> 如果有写操作 操作多个表 备份数据表的数据可能不一致
<p>时间顺序上是先备份账户余额表(u_account)，然后用户购买，然后备份用户课程表(u_course) 
<p> 其他方案
<p> 1   事物 
<p>官方自带的逻辑备份工具是mysqldump。当mysqldump使用参数–single-transaction的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。而由于MVCC的支持，这个过程中数据是可以正常更新的
<p> 缺点: 一致性读是好，但前提是引擎要支持这个隔离级别  MyISAM就不支持
<p> 2 set global readonly=true 方案
<li>一是，在有些系统中，readonly的值会被用来做其他逻辑，比如用来判断一个库是主库还是备库。因此，修改global变量的方式影响面更大，我不建议你使用。
<li>二是，在异常处理机制上有差异。如果执行FTWRL命令之后由于客户端发生异常断开，那么MySQL会自动释放这个全局锁整个库回到可以正常更新的状态。而将整个库设置为readonly之后，如果客户端发生异常，则数据库就会一直保持readonly状态，这样会导致整个库长时间处于不可写状态，风险较高。

#### 表级锁
<p> MySQL里面表级别的锁有两种：一种是表锁，一种是元数据锁（meta data lock，MDL)。
<p> 表锁的语法是 lock tables … read/write。与FTWRL类似，可以用unlock tables主动释放锁，也可以在客户端断开的时候自动释放。需要注意，lock tables语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。
 
<p> 举个例子, 如果在某个线程A中执行lock tables t1 read, t2 write; 这个语句，则其他线程写t1、读写t2的语句都会被阻塞。同时，线程A在执行unlock tables之前，也只能执行读t1、读写t2的操作。连写t1都不允许，自然也不能访问其他表。
 
<p> 在还没有出现更细粒度的锁的时候，表锁是最常用的处理并发的方式。而对于InnoDB这种支持行锁的引擎，一般不使用lock tables命令来控制并发，毕竟锁住整个表的影响面还是太大

<p> 另一类表级的锁是MDL（metadata lock)。MDL不需要显式使用，在访问一个表的时候会被自动加上。MDL的作用是，保证读写的正确性。你可以想象一下，如果一个查询正在遍历一个表中的数据，而执行期间另一个线程对这个表结构做变更，删了一列，那么查询线程拿到的结果跟表结构对不上，肯定是不行的。

<p> 因此，在MySQL 5.5版本中引入了MDL，当对一个表做增删改查操作的时候，加MDL读锁；当要对表做结构变更操作的时候，加MDL写锁。

<li>读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查。

<li>读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行

<img src="https://static001.geekbang.org/resource/image/7c/ce/7cf6a3bf90d72d1f0fc156ececdfb0ce.jpg"/>

#### 行锁
<p> 行锁就是针对数据表中行记录的锁。这很好理解，比如事务A更新了一行，而这时候事务B也要更新同一行，则必须等事务A的操作完成后才能进行更新

##### 两阶段锁说起
<p>在InnoDB事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议

##### 死锁和死锁检测
<p>当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为死锁
<img src="https://static001.geekbang.org/resource/image/4d/52/4d0eeec7b136371b79248a0aed005a52.jpg"/>
<p>两种策略：

<li>一种策略是，直接进入等待，直到超时。这个超时时间可以通过参数innodb_lock_wait_timeout来设置。
<li>另一种策略是，发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数innodb_deadlock_detect设置为on，表示开启这个逻辑。

<p>那如果是我们上面说到的所有事务都要更新同一行的场景呢？

<p>每个新来的被堵住的线程，都要判断会不会由于自己的加入导致了死锁，这是一个时间复杂度是O(n)的操作。假设有1000个并发线程要同时更新同一行，那么死锁检测操作就是100万这个量级的。虽然最终检测的结果是没有死锁，但是这期间要消耗大量的CPU资源。因此，你就会看到CPU利用率很高，但是每秒却执行不了几个事务。

<p>根据上面的分析，我们来讨论一下，怎么解决由这种热点行更新导致的性能问题呢？
<li> 一种头痛医头的方法，就是如果你能确保这个业务一定不会出现死锁，可以临时把死锁检测关掉。
<li> 另一个思路是控制并发度

### 8  事务到底是隔离的还是不隔离的？
<p>  如果是可重复读隔离级别，事务T启动的时候会创建一个视图read-view，之后事务T执行期间，即使有其他事务修改了数据，事务T看到的仍然跟在启动时看到的一样。也就是说，一个在可重复读隔离级别下执行的事务 不收其他事物影响
<p> 但如果update 一行 遇到了锁 情况就不一样了
<img src="https://static001.geekbang.org/resource/image/82/d6/823acf76e53c0bdba7beab45e72e90d6.png">

<p> 结论:事务B查到的k的值是3，而事务A查到的k的值是1

<p>在MySQL里，有两个“视图”的概念：
   
<li>   一个是view。它是一个用查询语句定义的虚拟表，在调用的时候执行查询语句并生成结果。创建视图的语法是create view … ，而它的查询方法与表一样。
<li>   另一个是InnoDB在实现MVCC时用到的一致性读视图，即consistent read view，用于支持RC（Read Committed，读提交）和RR（Repeatable Read，可重复读）隔离级别的实现。

##### “快照”在MVCC里是怎么工作的？
<p>在可重复读隔离级别下，事务在启动的时候就“拍了个快照”。注意，这个快照是基于整库的。
 <p>  InnoDB利用了“所有数据都有多个版本”的这个特性，实现了“秒级创建快照”的能力。
<p>     接下来，我们继续看一下图1中的三个事务，分析下事务A的语句返回的结果，为什么是k=1。
 <p>    这里，我们不妨做如下假设：
  <li>   事务A开始前，系统里面只有一个活跃事务ID是99；
  <li>      事务A、B、C的版本号分别是100、101、102，且当前系统里只有这四个事务；
  <li>      三个事务开始前，(1,1）这一行数据的row trx_id是90。
  <p>    这样，事务A的视图数组就是[99,100], 事务B的视图数组是[99,100,101], 事务C的视图数组是[99,100,101,102]。
   <p>   为了简化分析，我先把其他干扰语句去掉，只画出跟事务A查询逻辑有关的操作
  <img src="https://static001.geekbang.org/resource/image/94/49/9416c310e406519b7460437cb0c5c149.png"/>
 <p>  从图中可以看到，第一个有效更新是事务C，把数据从(1,1)改成了(1,2)。这时候，这个数据的最新版本的row trx_id是102，而90这个版本已经成为了历史版本。
 <p>  第二个有效更新是事务B，把数据从(1,2)改成了(1,3)。这时候，这个数据的最新版本（即row trx_id）是101，而102又成为了历史版本。
  <p> 你可能注意到了，在事务A查询的时候，其实事务B还没有提交，但是它生成的(1,3)这个版本已经变成当前版本了。但这个版本对事务A必须是不可见的，否则就变成脏读了。
  <p> 好，现在事务A要来读数据了，它的视图数组是[99,100]。当然了，读数据都是从当前版本读起的。所以，事务A查询语句的读数据流程是这样的：
   <li> 找到(1,3)的时候，判断出row trx_id=101，比高水位大，处于红色区域，不可见；
  <li>  接着，找到上一个历史版本，一看row trx_id=102，比高水位大，处于红色区域，不可见；
   <li> 再往前找，终于找到了（1,1)，它的row trx_id=90，比低水位小，处于绿色区域，可见。
 <p>  这样执行下来，虽然期间这一行数据被修改过，但是事务A不论在什么时候查询，看到这行数据的结果都是一致的，所以我们称之为一致性读。

 <p>一个数据版本，对于一个事务视图来说，除了自己的更新总是可见以外，有三种情况：
<li>版本未提交，不可见；
<li>版本已提交，但是是在视图创建后提交的，不可见；
<li>版本已提交，而且是在视图创建前提交的，可见

 <p>现在，我们用这个规则来判断图4中的查询结果，事务A的查询语句的视图数组是在事务A启动的时候生成的，这时候：
 <img src="https://static001.geekbang.org/resource/image/ed/6e/ed4b8d03287df67ecca53b5b4830ee6e.png">
<li>(1,3)还没提交，属于情况1，不可见；
<li>(1,2)虽然提交了，但是是在视图数组创建之后提交的，属于情况2，不可见；
<li>(1,1)是在视图数组创建之前提交的，可见。

#### 更新逻辑
<p> 在上面一题中 事务B的update语句，如果按照一致性读，好像结果不对
<p> 如果事务B在更新之前查询一次数据，这个查询返回的k的值确实是1。
    
<p>    但是，当它要去更新数据的时候，就不能再在历史版本上更新了，否则事务C的更新就丢失了。因此，事务B此时的set k=k+1是在（1,2）的基础上进行的操作。
    
<p>    所以，这里就用到了这样一条规则：更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读”（current read）。
    
<p>    因此，在更新的时候，当前读拿到的数据是(1,2)，更新后生成了新版本的数据(1,3)，这个新版本的row trx_id是101。
    
<p>    所以，在执行事务B查询语句的时候，一看自己的版本号是101，最新数据的版本号也是101，是自己的更新，可以直接使用，所以查询得到的k的值是3。
    
<p>    这里我们提到了一个概念，叫作当前读。其实，除了update语句外，select语句如果加锁，也是当前读。 

<p>如果把事务A的查询语句select * from t where id=1修改一下，加上lock in share mode 或 for update，也都可以读到版本号是101的数据，返回的k的值是3。下面这两个select语句，就是分别加了读锁（S锁，共享锁）和写锁（X锁，排他锁）。
 <pre><code>
mysql> select k from t where id=1 lock in share mode;
mysql> select k from t where id=1 for update; 
</code></pre>  

<p> 如果是这样呢
<img src="https://static001.geekbang.org/resource/image/cd/6e/cda2a0d7decb61e59dddc83ac51efb6e.png"/>

<p> 在事物B中  因为“两阶段锁协议”。事务C’没提交，也就是说(1,2)这个版本上的写锁还没释放。而事务B是当前读，必须要读最新版本，而且必须加锁，因此就被锁住了，必须等到事务C’释放这个锁，才能继续它的当前读。
<p> 在事物A中  
<li>(1,3)还没提交，属于情况1，不可见；
<li>(1,2)提交了，属于情况3，可见。
<p>所以，这时候事务A查询语句返回的是k=2。 B中拿到3


#### 事务的可重复读的能力是怎么实现的？

<p>可重复读的核心就是一致性读（consistent read）；而事务更新数据的时候，只能用当前读。如果当前的记录的行锁被其他事务占用的话，就需要进入锁等待。

<p>而读提交的逻辑和可重复读的逻辑类似，它们最主要的区别是：

<li>在可重复读隔离级别下，只需要在事务开始的时候创建一致性视图，之后事务里的其他查询都共用这个一致性视图；
<li>在读提交隔离级别下，每一个语句执行前都会重新算出一个新的视图。
<p>这里需要说明一下，“start transaction with consistent snapshot; ”的意思是从这个语句开始，创建一个持续整个事务的一致性快照。所以，在读提交隔离级别下，这个用法就没意义了，等效于普通的start transaction。

 <p> 小结
<p>  InnoDB的行数据有多个版本，每个数据版本有自己的row trx_id，每个事务或者语句有自己的一致性视图。普通查询语句是一致性读，一致性读会根据row trx_id和一致性视图确定数据版本的可见性。
  
<li>  对于可重复读，查询只承认在事务启动前就已经提交完成的数据；
<li>  对于读提交，查询只承认在语句启动前就已经提交完成的数据
<p> 而当前读，总是读取已经提交完成的最新版本

<p> ps: 本章重点 
<li>1 两阶段锁协议 事物启动  在执行时  拿到行锁 提交事物时 才释放锁
<li>2 当前读   更新数据都是先读后写的  这个读如果被锁wait住  在拿到锁  它会去拿最新数据( 就是上一个锁修改的数据)

###  9 普通索引和唯一索引
<p> 执行差别：
<li>对于普通索引来说，查找到满足条件的第一个记录(5,500)后，需要查找下一个记录，直到碰到第一个不满足k=5条件的记录。
<li>对于唯一索引来说，由于索引定义了唯一性，查找到第一个满足条件的记录后，就会停止继续检索。

####  查询过程
<p> 索引树上查找的过程，先是通过B+树从树根开始，按层搜索到叶子节点，也就是图中右下角的这个数据页，然后可以认为数据页内部通过二分法来定位记录
<p> InnoDB的数据是按数据页为单位来读写的。也就是说，当需要读一条记录的时候，并不是将这个记录本身从磁盘读出来，而是以页为单位，将其整体读入内存。在InnoDB中，每个数据页的大小默认是16KB。
<p> 这个记录有可能在下一页 但一个数据页可以放近千个key，因此出现这种情况的概率会很低。

#### 更新过程
##### change buffer 
<p> 更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，
<p> InooDB会将这些更新操作缓存在change buffer中，这样就不需要从磁盘中读入这个数据页了。在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行change buffer中与这个页有关的操作。通过这种方式就能保证这个数据逻辑的正确性。

<p> change buffer，实际上它是可以持久化的数据。也就是说，change buffer在内存中有拷贝，也会被写入到磁盘上
<p>  将change buffer中的操作应用到原数据页，得到最新结果的过程称为merge。除了访问这个数据页会触发merge外，系统有后台线程会定期merge。在数据库正常关闭（shutdown）的过程中，也会执行merge操作
<p> 更新操作先记录在change buffer，减少读磁盘，语句的执行速度会得到明显的提升。而且，数据读入内存是需要占用buffer pool的，所以这种方式还能够避免占用内存，提高内存利用率

##### 什么条件下可以使用change buffer
<p> 1 唯一索引来说，所有的更新操作都要先判断这个操作是否违反唯一性约束。比如，要插入(4,400)这个记录，就要先判断现在表中是否已经存在k=4的记录，而这必须要将数据页读入内存才能判断。如果都已经读入到内存了，那直接更新内存会更快，就没必要使用change buffer了。
<p> 因此，唯一索引的更新就不能使用change buffer，实际上也只有普通索引可以使用
<p>change buffer用的是buffer pool里的内存，因此不能无限增大。change buffer的大小，可以通过参数innodb_change_buffer_max_size来动态设置。这个参数设置为50的时候，表示change buffer的大小最多只能占用buffer pool的50%。

<p>现在，你已经理解了change buffer的机制，那么我们再一起来看看如果要在这张表中插入一个新记录(4,400)的话，InnoDB的处理流程是怎样的。

<p>第一种情况是，这个记录要更新的目标页在内存中。这时，InnoDB的处理流程如下：

<li>对于唯一索引来说，找到3和5之间的位置，判断到没有冲突，插入这个值，语句执行结束；
<li>对于普通索引来说，找到3和5之间的位置，插入这个值，语句执行结束。
<p>这样看来，普通索引和唯一索引对更新语句性能影响的差别，只是一个判断，只会耗费微小的CPU时间。

<p>但，这不是我们关注的重点。

<p>第二种情况是，这个记录要更新的目标页不在内存中。这时，InnoDB的处理流程如下：

<li>对于唯一索引来说，需要将数据页读入内存，判断到没有冲突，插入这个值，语句执行结束；
<li>对于普通索引来说，则是将更新记录在change buffer，语句执行就结束了。
<p>将数据从磁盘读入内存涉及随机IO的访问，是数据库里面成本最高的操作之一。change buffer因为减少了随机磁盘访问，所以对更新性能的提升是会很明显的。

##### change buffer的使用场景
<p> 适用于 更新后不会马上查询的操作  写多读少

##### change buffer 和 redo log
<p>现在，我们要在表上执行这个插入语句：
  <pre><code>
mysql> insert into t(id,k) values(id1,k1),(id2,k2);
</code></pre>
<p>我们假设当前k索引树的状态，查找到位置后，k1所在的数据页在内存(InnoDB buffer pool)中，k2所在的数据页不在内存中。如图2所示是带change buffer的更新状态图
<img src="https://static001.geekbang.org/resource/image/98/a3/980a2b786f0ea7adabef2e64fb4c4ca3.png"/>
<p>分析这条更新语句，你会发现它涉及了四个部分：内存、redo log（ib_log_fileX）、 数据表空间（t.ibd）、系统表空间（ibdata1）。

<p>这条更新语句做了如下的操作（按照图中的数字顺序）：

<p>Page 1在内存中，直接更新内存；

<p>Page 2没有在内存中，就在内存的change buffer区域，记录下“我要往Page 2插入一行”这个信息

<p>将上述两个动作记入redo log中（图中3和4）。

<p>做完上面这些，事务就可以完成了。所以，你会看到，执行这条更新语句的成本很低，就是写了两处内存，然后写了一处磁盘（两次操作合在一起写了一次磁盘），而且还是顺序写的。

<p>同时，图中的两个虚线箭头，是后台操作，不影响更新的响应时间。

<p>这之后的读请求，要怎么处理呢?
<p>要执行 select * from t where k in (k1, k2)。这里，我画了这两个读请求的流程图。

<p>如果读语句发生在更新语句后不久，内存中的数据都还在，那么此时的这两个读操作就与系统表空间（ibdata1）和 redo log（ib_log_fileX）无关了。所以，我在图中就没画出这两部分
<img src="https://static001.geekbang.org/resource/image/6d/8e/6dc743577af1dbcbb8550bddbfc5f98e.png"/>

<p>从图中可以看到：

<li>读Page 1的时候，直接从内存返回。有几位同学在前面文章的评论中问到，WAL之后如果读数据，是不是一定要读盘，是不是一定要从redo log里面把数据更新以后才可以返回？其实是不用的。你可以看一下图3的这个状态，虽然磁盘上还是之前的数据，但是这里直接从内存返回结果，结果是正确的。

<li>要读Page 2的时候，需要把Page 2从磁盘读入内存中，然后应用change buffer里面的操作日志，生成一个正确的版本并返回结果。

<p>可以看到，直到需要读Page 2的时候，这个数据页才会被读入内存。

<p>所以，如果要简单地对比这两个机制在提升更新性能上的收益的话，redo log 主要节省的是随机写磁盘的IO消耗（转成顺序写），而change buffer主要节省的则是随机读磁盘的IO消耗。


### 10 MySQL为什么有时候会选错索引
<p>MySQL中一张表其实是可以支持多个索引的。但是，你写SQL语句的时候，并没有主动指定使用哪个索引。也就是说，使用哪个索引是由MySQL来确定的
<p> 查询效率问题： 可以set long_query_time=0; 开启慢查询  和explain 查看执行计划

####  索引的选择都是优化器决定的  选择方式:
<p> 优化器选择索引的目的，是找到一个最优的执行方案，并用最小的代价去执行语句。在数据库里面，扫描行数是影响执行代价的因素之一。扫描的行数越少，意味着访问磁盘数据的次数越少，消耗的CPU资源越少。
 <p>    当然，扫描行数并不是唯一的判断标准，优化器还会结合是否使用临时表、是否排序等因素进行综合判断
 
 #### 扫描行数是怎么判断的
 <p>MySQL在真正开始执行语句之前，并不能精确地知道满足这个条件的记录有多少条，而只能根据统计信息来估算记录数
 <p> 采样统计的时候，InnoDB默认会选择N个数据页，统计这些页面上的不同值，得到一个平均值，然后乘以这个索引的页面数，就得到了这个索引的基数。
     
 <p>     而数据表是会持续更新的，索引统计信息也不会固定不变。所以，当变更的数据行数超过1/M的时候，会自动触发重新做一次索引统计。
 <p>     在MySQL中，有两种存储索引统计的方式，可以通过设置参数innodb_stats_persistent的值来选择：
     
<li>     设置为on的时候，表示统计信息会持久化存储。这时，默认的N是20，M是10。
<li>     设置为off的时候，表示统计信息只存储在内存中。这时，默认的N是8，M是16。
<p>  基数统计是不精确的

<p> ps: 优化器在统计行数 不止统计查询行数 还会加上回表消耗  选择它认为好的
<p> analyze table t 命令，可以用来重新统计索引信息   解决索引统计信息不准确导致的问题
<p> 解决办法:
<li> 1 force index () 会强制走这个索引
<li> 2 我们可以考虑修改语句，引导MySQL使用我们期望的索引 比如“order by b limit 1” 改成 “order by b,a limit 1”
<li> 3 在有些场景下，我们可以新建一个更合适的索引，来提供给优化器做选择，或删掉误用的索引。

### 11  怎么给字符串字段加索引
<p> 几乎所有的系统都支持邮箱登录，如何在邮箱这样的字段上建立合理的索引
<pre><code>
   mysql> alter table SUser add index index1(email);
   或
   mysql> alter table SUser add index index2(email(6));
</code></pre>

<p>第一个语句创建的index1索引里面，包含了每个记录的整个字符串；而第二个语句创建的index2索引里面，对于每个记录都是只取前6个字节 
<p>如果使用的是index1（即email整个字符串的索引结构），执行顺序是这样的：

<li>从index1索引树找到满足索引值是’zhangssxyz@xxx.com’的这条记录，取得ID2的值；

<li>到主键上查到主键值是ID2的行，判断email的值是正确的，将这行记录加入结果集；

<li>取index1索引树上刚刚查到的位置的下一条记录，发现已经不满足email='zhangssxyz@xxx.com’的条件了，循环结束。

<li>这个过程中，只需要回主键索引取一次数据，所以系统认为只扫描了一行。

<p>如果使用的是index2（即email(6)索引结构），执行顺序是这样的：

<li>从index2索引树找到满足索引值是’zhangs’的记录，找到的第一个是ID1；
<li>到主键上查到主键值是ID1的行，判断出email的值不是’zhangssxyz@xxx.com’，这行记录丢弃；

<li>取index2上刚刚查到的位置的下一条记录，发现仍然是’zhangs’，取出ID2，再到ID索引上取整行然后判断，这次值对了，将这行记录加入结果集；

<li>重复上一步，直到在idxe2上取到的值不是’zhangs’时，循环结束。

<p>在这个过程中，要回主键索引取4次数据，也就是扫描了4行。

<p> 这就是前缀索引

<p> 前缀索引除了扫描有影响 还有覆盖索引
<pre><code>
     select id,name,email from SUser where email='zhangssxyz@xxx.com';
</code></pre>
<p> 如果id是主键 email是前缀索引
<p> 即使你将index2的定义修改为email(18)的前缀索引，这时候虽然index2已经包含了所有的信息，但InnoDB还是要回到id索引再查一下，因为系统并不确定前缀索引的定义是否截断了完整信息。

#### 其他方式
<p>1 使用倒序存储。如果你存储身份证号的时候把它倒过来存，每次查询的时候，你可以这么写：
    <pre><code> 
     mysql> select field_list from t where id_card = reverse('input_id_card_string');
     </code></pre>
     
 <p> 2 每次插入新记录的时候，都同时用crc32()这个函数得到校验码填到这个新字段。由于校验码可能存在冲突，也就是说两个不同的身份证号通过crc32()函数得到的结果可能是相同的，所以你的查询语句where部分要判断id_card的值是否精确相同。
      <pre><code> 
       mysql> select field_list from t where id_card_crc=crc32('input_id_card_string') and id_card='input_id_card_string'
        </code></pre>
        

#### 区别，主要体现在以下三个方面：
<li>     从占用的额外空间来看，倒序存储方式在主键索引上，不会消耗额外的存储空间，而hash字段方法需要增加一个字段。当然，倒序存储方式使用4个字节的前缀长度应该是不够的，如果再长一点，这个消耗跟额外这个hash字段也差不多抵消了。
<li>     在CPU消耗方面，倒序方式每次写和读的时候，都需要额外调用一次reverse函数，而hash字段的方式需要额外调用一次crc32()函数。如果只从这两个函数的计算复杂度来看的话，reverse函数额外消耗的CPU资源会更小些。
<li>     从查询效率上看，使用hash字段方式的查询性能相对更稳定一些。因为crc32算出来的值虽然有冲突的概率，但是概率非常小，可以认为每次查询的平均扫描行数接近1。而倒序存储方式毕竟还是用的前缀索引的方式，也就是说还是会增加扫描行数。

<p> 总结:
<li> 直接创建完整索引，这样可能比较占用空间；
<li> 创建前缀索引，节省空间，但会增加查询扫描次数，并且不能使用覆盖索引；
<li> 倒序存储，再创建前缀索引，用于绕过字符串本身前缀的区分度不够的问题；
<li> 创建hash字段索引，查询性能稳定，有额外的存储和计算消耗，跟第三种方式一样，都不支持范围扫描。 

### 12 | 为什么我的MySQL会“抖”一下？
<p> InnoDB在处理更新语句的时候，只做了写日志这一个磁盘操作。这个日志叫作redo log（重做日志），也就是《孔乙己》里咸亨酒店掌柜用来记账的粉板，在更新内存写完redo log后，就返回给客户端，本次更新成功
<p> 把内存里的数据写入磁盘的过程，术语就是flush。
<p> 当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页”。

<p> 什么时候回去刷脏页
<li> 1 redo 内存空间满了 不得不把日志写入磁盘 （redo 日志 类似双指针循环利用数组的方式写入和写出）   系统会停止所有更新操作，把checkpoint往前推进，redo log留出空间可以继续写
<li> 2 系统内存不足 会扔掉一些内存页 如果扔掉的有脏页 就会把脏页写到磁盘 
<p>第二种情况 保证了数据的状态
<li>一种是内存里存在，内存里就肯定是正确的结果，直接返回；
<li>另一种是内存里没有数据，就可以肯定数据文件上是正确的结果，读入内存后返回。
<p>这样的效率最高。
<li>3 系统空闲的时候 回去刷脏页
<li> 4 mysql 正常关闭的时候 会全部写到磁盘 

#### 四种场景对性能的影响
<p>第一种是“redo log写满了，要flush脏页”，这种情况是InnoDB要尽量避免的。因为出现这种情况的时候，整个系统就不能再接受更新了，所有的更新都必须堵住。如果你从监控上看，这时候更新数会跌为0。

<p>第二种是“内存不够用了，要先将脏页写到磁盘”，这种情况其实是常态。InnoDB用缓冲池（buffer pool）管理内存，缓冲池中的内存页有三种状态：

<li>第一种是，还没有使用的；
<li>第二种是，使用了并且是干净页；
<li>第三种是，使用了并且是脏页。
<p>刷脏页虽然是常态，但是出现以下这两种情况，都是会明显影响性能的：

<li>一个查询要淘汰的脏页个数太多，会导致查询的响应时间明显变长；

<li>日志写满，更新全部堵住，写性能跌为0，这种情况对敏感业务来说，是不能接受的。

<p>所以，InnoDB需要有控制脏页比例的机制，来尽量避免上面的这两种情况。

#### InnoDB刷脏页的控制策略
<p> innodb_io_capacity这个参数建议你设置成磁盘的IOPS。磁盘的IOPS可以通过fio这个工具来测试，下面的语句是我用来测试磁盘随机读写的命令：
 <pre><code>
 fio -filename=$filename -direct=1 -iodepth 1 -thread -rw=randrw -ioengine=psync -bs=16k -size=500M -numjobs=10
 </code></pre>
<p> 参数innodb_max_dirty_pages_pct是脏页比例上限  默认值是75%        平时要多关注脏页比例，不要让它经常接近75%。
<p> 在innodb中刷一个脏页 他相邻的数据页也是脏页会一起刷下去 具有传递性   innodb_flush_neighbors的值设置成0可关闭 在8中默认关闭


### 13 | 为什么表数据删掉一半，表文件大小不变？
<p> 参数innodb_file_per_table
<p>    表数据既可以存在共享表空间里，也可以是单独的文件。这个行为是由参数innodb_file_per_table控制的：
    
<li>    这个参数设置为OFF表示的是，表的数据放在系统共享表空间，也就是跟数据字典放在一起；
    
 <li>    这个参数设置为ON表示的是，每个InnoDB表数据存储在一个以 .ibd为后缀的文件中。
    
 <p>   从MySQL 5.6.6版本开始，它的默认值就是ON了。  将innodb_file_per_table设置为ON，是推荐做法
 
 #### 数据删除流程
 <p> 记录的复用，只限于符合范围条件的数据。 删除一条数据 ，把他标记为已删除， 在插入一条范围和他符合的，可以直接复用这个空间
 <p> 数据页的复用  如果当前页所有数据清除 或者页合并 都会 有一个页可复用  不管符不符合范围都可以复用
 <p>不止是删除数据会造成空洞，插入数据也会。
 
 #### 重建表
 <p>1  你可以使用alter table A engine=InnoDB命令来重建表
 <p> 流程：
  <p>    新建一个与表A结构相同的表B，然后按照主键ID递增的顺序，把数据一行一行地从表A里读出来再插入到表B中。
     
 <p>     由于表B是新建的表，所以表A主键索引上的空洞，在表B中就都不存在了。显然地，表B的主键索引更紧凑，数据页的利用率也更高。
 <p>  如果我们把表B作为临时表，数据从表A导入表B的操作完成后，用表B替换A，从效果上看，就起到了收缩表A空间的作用
 <p> 这种方式是不online的 有新数据写入 会有数据丢失
 
 <p>2 Online DDL之后，重建表的流程：
 <li>    建立一个临时文件，扫描表A主键的所有数据页；
 <li>    用数据页中表A的记录生成B+树，存储到临时文件中；
 <li>    生成临时文件的过程中，将所有对A的操作记录在一个日志文件（row log）中，对应的是图中state2的状态；
 <li>    临时文件生成后，将日志文件中的操作应用到临时文件，得到一个逻辑数据上与表A相同的数据文件，对应的就是图中state3的状态；
 <li>    用临时文件替换表A的数据文件。
 
 <img src="https://static001.geekbang.org/resource/image/2d/f0/2d1cfbbeb013b851a56390d38b5321f0.png"/>
 <p> alter语句在启动的时候需要获取MDL写锁，但是这个写锁在真正拷贝数据之前就退化成读锁了。
 
 <p> 为什么要退化呢？为了实现Online，MDL读锁不会阻塞增删改操作。
 
 <p> 那为什么不干脆直接解锁呢？为了保护自己，禁止其他线程对这个表同时做DDL。
 
 <p> 而对于一个大表来说，Online DDL最耗时的过程就是拷贝数据到临时表的过程，这个步骤的执行期间可以接受增删改操作。所以，相对于整个DDL过程来说，锁的时间非常短。对业务来说，就可以认为是Online的。
 
 <p> 需要补充说明的是，上述的这些重建方法都会扫描原表数据和构建临时文件。对于很大的表来说，这个操作是很消耗IO和CPU资源的。因此，如果是线上服务，你要很小心地控制操作时间。如果想要比较安全的操作的话，我推荐你使用GitHub开源的gh-ost来做。
 
 #### Online 和 inplace
 
 <p> 在上图中，根据表A重建出来的数据是放在“tmp_file”里的，这个临时文件是InnoDB在内部创建出来的。整个DDL过程都在InnoDB内部完成。对于server层来说，没有把数据挪动到临时表，是一个“原地”操作，这就是“inplace”名称的来源
 <p> 逻辑关系：
  <li>DDL过程如果是Online的，就一定是inplace的；
 <li> 反过来未必，也就是说inplace的DDL，有可能不是Online的。截止到MySQL 8.0，添加全文索引（FULLTEXT index）和空间索引(SPATIAL index)就属于这种情况。
 <p> inplace，可能但会阻塞增删改操作，是非Online
 
 <p> 三种方式重建表的区别。
 
  <li>从MySQL 5.6版本开始，alter table t engine = InnoDB（也就是recreate）默认的就是上面图4的流程了；
  <li>analyze table t 其实不是重建表，只是对表的索引信息做重新统计，没有修改数据，这个过程中加了MDL读锁；
  <li>optimize table t 等于recreate+analyze。
 <p> ps：重建表的时候，InnoDB不会把整张表占满，每个页留了1/16给后续的更新用。也就是说，其实重建表之后不是“最”紧凑的
 
  
### 14 | count(*)这么慢，我该怎么办？

#### count(*)的实现方式
 <p>你首先要明确的是，在不同的MySQL引擎中，count(*)有不同的实现方式。

<li>MyISAM引擎把一个表的总行数存在了磁盘上，因此执行count(*)的时候会直接返回这个数，效率很高；
<li>而InnoDB引擎就麻烦了，它执行count(*)的时候，需要把数据一行一行地从引擎里面读出来，然后累积计数
<p> myisam 如果有where 也不会直接返回

####  其他方式
<li>MyISAM表虽然count(*)很快，但是不支持事务；
<li>show table status命令虽然返回很快，但是不准确；
<li>InnoDB表直接count(*)会遍历全表，虽然结果准确，但会导致性能问题。

#### 不同的count用法
<li>count(主键id)，InnoDB引擎会遍历整张表，把每一行的id值都取出来，返回给server层。server层拿到id后，判断是不可能为空的，就按行累加
<li>count(1)，InnoDB引擎遍历整张表，但不取值。server层对于返回的每一行，放一个数字“1”进去，判断是不可能为空的，按行累加
<li>count(字段)：
<p>如果这个“字段”是定义为not null的话，一行行地从记录里面读出这个字段，判断不能为null，按行累加；
<p>如果这个“字段”定义允许为null，那么执行的时候，判断到有可能是null，还要把值取出来再判断一下，不是null才累加。
<li>但是count(*)是例外，并不会把全部字段取出来，而是专门做了优化，不取值。count(*)肯定不是null，按行累加
<p> 结论是：按照效率排序的话，count(字段)<count(主键id)<count(1)≈count(*)，所以我建议你，尽量使用count(*)


<h3><a href="https://www.cnblogs.com/a-phper/p/10313905.html">15 | 答疑文章（一）：日志和索引相关问题  </a>

### 16 | “order by”是怎么工作的？

#### 全字段排序
<p> explain命令来看看这个语句的执行情况。
 <img src="https://static001.geekbang.org/resource/image/82/03/826579b63225def812330ef6c344a303.png"/>   
 <p>   Extra这个字段中的“Using filesort”表示的就是需要排序，MySQL会给每个线程分配一块内存用于排序，称为sort_buffer
 <p> 流程如下所示 ：
<li> 初始化sort_buffer，确定放入name、city、age这三个字段；
<li> 从索引city找到第一个满足city='杭州’条件的主键id，也就是图中的ID_X；
<li> 到主键id索引取出整行，取name、city、age三个字段的值，存入sort_buffer中；
<li> 从索引city取下一个记录的主键id；
<li> 重复步骤3、4直到city的值不满足查询条件为止，对应的主键id也就是图中的ID_Y；
<li> 对sort_buffer中的数据按照字段name做快速排序；
<li> 按照排序结果取前1000行返回给客户端。
<img src="https://static001.geekbang.org/resource/image/6c/72/6c821828cddf46670f9d56e126e3e772.jpg"/>

<p>可能在内存中完成，也可能需要使用外部排序，这取决于排序所需的内存和参数sort_buffer_size。
   
<p>   sort_buffer_size，就是MySQL为排序开辟的内存（sort_buffer）的大小。如果要排序的数据量小于sort_buffer_size，排序就在内存中完成。但如果排序数据量太大，内存放不下，则不得不利用磁盘临时文件辅助排序。
   
<p>   你可以用下面介绍的方法，来确定一个排序语句是否使用了临时文件。
 <pre><code>  
   /* 打开optimizer_trace，只对本线程有效 */
   SET optimizer_trace='enabled=on'; 
   /* @a保存Innodb_rows_read的初始值 */
   select VARIABLE_VALUE into @a from  performance_schema.session_status where variable_name = 'Innodb_rows_read';
   /* 执行语句 */
   select city, name,age from t where city='杭州' order by name limit 1000; 
   /* 查看 OPTIMIZER_TRACE 输出 */
   SELECT * FROM `information_schema`.`OPTIMIZER_TRACE`\G
   /* @b保存Innodb_rows_read的当前值 */
   select VARIABLE_VALUE into @b from performance_schema.session_status where variable_name = 'Innodb_rows_read';
   /* 计算Innodb_rows_read差值 */
   select @b-@a;
</code></pre>
<p>   这个方法是通过查看 OPTIMIZER_TRACE 的结果来确认的，你可以从 number_of_tmp_files中看到是否使用了临时文件。
<img src="https://static001.geekbang.org/resource/image/89/95/89baf99cdeefe90a22370e1d6f5e6495.png">
<p> number_of_tmp_files表示的是，排序过程中使用的临时文件数。你一定奇怪，为什么需要12个文件？内存放不下时，就需要使用外部排序，外部排序一般使用归并排序算法。可以这么简单理解，MySQL将需要排序的数据分成12份，每一份单独排序后存在这些临时文件中。然后把这12个有序文件再合并成一个有序的大文件

#### rowid排序
<p> 修改一个参数，让MySQL采用另外一种算法。
   <pre><code>
    SET max_length_for_sort_data = 16;
    </code></pre>
<p>     max_length_for_sort_data，是MySQL中专门控制用于排序的行数据的长度的一个参数。它的意思是，如果单行的长度超过这个值，MySQL就认为单行太大，要换一个算法。
    
<p>     city、name、age 这三个字段的定义总长度是36，我把max_length_for_sort_data设置为16，我们再来看看计算过程有什么改变。
    
<p>     新的算法放入sort_buffer的字段，只有要排序的列（即name字段）和主键id。
<p> 流程就变成如下所示的样子：
    
<li>   初始化sort_buffer，确定放入两个字段，即name和id；
    
<li>    从索引city找到第一个满足city='杭州’条件的主键id，也就是图中的ID_X；
    
<li>    到主键id索引取出整行，取name、id这两个字段，存入sort_buffer中；
    
<li>    从索引city取下一个记录的主键id；
    
<li>    重复步骤3、4直到不满足city='杭州’条件为止，也就是图中的ID_Y；
    
<li>    对sort_buffer中的数据按照字段name进行排序；
    
<li>    遍历排序结果，取前1000行，并按照id的值回到原表中取出city、name和age三个字段返回给客户端。
    
<p>    这个执行流程的示意图如下，我把它称为rowid排序
<p> 这时候除了排序过程外，在排序完成后，还要根据id去原表取值。由于语句是limit 1000，因此会多读1000行
<img src="https://static001.geekbang.org/resource/image/27/9b/27f164804d1a4689718291be5d10f89b.png" >
<p>从OPTIMIZER_TRACE的结果中，你还能看到另外两个信息也变了。

<li>sort_mode变成了<sort_key, rowid>，表示参与排序的只有name和id这两个字段。
<li>number_of_tmp_files变成10了，是因为这时候参与排序的行数虽然仍然是4000行，但是每一行都变小了，因此需要排序的总数据量就变小了，需要的临时文件也相应地变少了。

<p>ps：覆盖索引 ,因为索引是有序的 所以并不会重新排序

### 17 | 如何正确地显示随机消息？
<p> 主要在缓存表上排序
<p> 内存临时表
<p>    首先，你会想到用order by rand()来实现这个逻辑。
<pre><code>    
    mysql> select word from words order by rand() limit 3;
</code></pre>
<p>explain命令来看看这个语句的执行情况。
<img src="https://static001.geekbang.org/resource/image/59/50/59a4fb0165b7ce1184e41f2d061ce350.png"/>
<p>Extra字段显示Using temporary，表示的是需要使用临时表；Using filesort，表示的是需要执行排序操作。

<p>因此这个Extra的意思就是，需要临时表，并且需要在临时表上排序

<p> 在innodb中 对于内存表，回表过程只是简单地根据数据行的位置，直接访问内存得到数据，根本不会导致多访问磁盘。优化器没有了这一层顾虑，那么它会优先考虑的，就是用于排序的行越少越好了，所以，MySQL这时就会选择rowid排序
<p>  流程是这样的：
     
<li>     创建一个临时表。这个临时表使用的是memory引擎，表里有两个字段，第一个字段是double类型，为了后面描述方便，记为字段R，第二个字段是varchar(64)类型，记为字段W。并且，这个表没有建索引。
     
<li>      从words表中，按主键顺序取出所有的word值。对于每一个word值，调用rand()函数生成一个大于0小于1的随机小数，并把这个随机小数和word分别存入临时表的R和W字段中，到此，扫描行数是10000。
     
<li>      现在临时表有10000行数据了，接下来你要在这个没有索引的内存临时表上，按照字段R排序。
     
<li>      初始化 sort_buffer。sort_buffer中有两个字段，一个是double类型，另一个是整型。
     
<li>      从内存临时表中一行一行地取出R值和位置信息（我后面会和你解释这里为什么是“位置信息”），分别存入sort_buffer中的两个字段里。这个过程要对内存临时表做全表扫描，此时扫描行数增加10000，变成了20000。
     
<li>      在sort_buffer中根据R的值进行排序。注意，这个过程没有涉及到表操作，所以不会增加扫描行数。
     
<li>      排序完成后，取出前三个结果的位置信息，依次到内存临时表中取出word值，返回给客户端。这个过程中，访问了表的三行数据，总扫描行数变成了20003。

<p>慢查询日志（slow log）来验证一下我们分析得到的扫描行数是否正确。
 <pre><code>  
   # Query_time: 0.900376  Lock_time: 0.000347 Rows_sent: 3 Rows_examined: 20003
   SET timestamp=1541402277;
   select word from words order by rand() limit 3;</code></pre>
<p>   其中，Rows_examined：20003就表示这个语句执行过程中扫描了20003行，也就验证了我们分析得出的结论。

<img src="https://static001.geekbang.org/resource/image/2a/fc/2abe849faa7dcad0189b61238b849ffc.png">
<p><b>order by rand()使用了内存临时表，内存临时表排序的时候使用了rowid排序方法。</b>

#### 磁盘临时表
<p>tmp_table_size这个配置限制了内存临时表的大小，默认值是16M。如果临时表大小超过了tmp_table_size，那么内存临时表就会转成磁盘临时表。
   
<p>   磁盘临时表使用的引擎默认是InnoDB，是由参数internal_tmp_disk_storage_engine控制的。
   
<p>   当使用磁盘临时表的时候，对应的就是一个没有显式索引的InnoDB表的排序过程

<p>把tmp_table_size设置成1024，把sort_buffer_size设置成 32768, 把 max_length_for_sort_data 设置成16。
 <pre><code>  
   set tmp_table_size=1024;
   set sort_buffer_size=32768;
   set max_length_for_sort_data=16;
   /* 打开 optimizer_trace，只对本线程有效 */
   SET optimizer_trace='enabled=on'; 
   /* 执行语句 */
   select word from words order by rand() limit 3;
   /* 查看 OPTIMIZER_TRACE 输出 */
   SELECT * FROM `information_schema`.`OPTIMIZER_TRACE`\G
   </code></pre>
   
   <img src="https://static001.geekbang.org/resource/image/78/ab/78d2db9a4fdba81feadccf6e878b4aab.png">
<p>  因为将max_length_for_sort_data设置成16，小于word字段的长度定义，所以我们看到sort_mode里面显示的是rowid排序，这个是符合预期的，参与排序的是随机值R字段和rowid字段组成的行。
   
<p>    这时候你可能心算了一下，发现不对。R字段存放的随机值就8个字节，rowid是6个字节（至于为什么是6字节，就留给你课后思考吧），数据总行数是10000，这样算出来就有140000字节，超过了sort_buffer_size 定义的 32768字节了。但是，number_of_tmp_files的值居然是0，难道不需要用临时文件吗？
   
<p>    这个SQL语句的排序确实没有用到临时文件，采用是MySQL 5.6版本引入的一个新的排序算法，即：优先队列排序算法。接下来，我们就看看为什么没有使用临时文件的算法，也就是归并排序算法，而是采用了优先队列排序算法。
   
<p>    其实，我们现在的SQL语句，只需要取R值最小的3个rowid。但是，如果使用归并排序算法的话，虽然最终也能得到前3个值，但是这个算法结束后，已经将10000行数据都排好序了。
   
<p>    也就是说，后面的9997行也是有序的了。但，我们的查询并不需要这些数据是有序的。所以，想一下就明白了，这浪费了非常多的计算量。
   
<p>    而优先队列算法， 就是堆排序(三个元素的堆 ,向里面放，节省了空间  时间O(N)) 取出来前几条
<p> 为什么limit 1000 没用优先队列算法
<p> 堆的大小就是1000行的(name,rowid)，超过了我设置的sort_buffer_size大小，所以只能使用归并排序算法

#### 随机排序方法
<p> 思路: 把随机不放在sql里 ，1 取出符合的总条数 2 1-总条数的随机值 取对应数据


### 18 | 为什么这些SQL语句逻辑相同，性能却差异巨大？
<p> 哪些影响索引效能的查询
<p> 1 条件字段函数操作
<p> 对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能。 
<p> 放弃树搜索 仍然可以选择遍历主键索引，也可以选择遍历索引

<p> 2 隐式类型转换
<p>问题：
<li>数据类型转换的规则是什么？
<li>为什么有数据类型转换，就需要走全索引扫描？

<p>  select “10” > 9的结果：
<li>    如果规则是“将字符串转成数字”，那么就是做数字比较，结果应该是1；
<li>    如果规则是“将数字转成字符串”，那么就是做字符串比较，结果应该是0。
<p> 于字符比较相反
<p> 有转换时 会变成 where CAST(tradid AS signed int) = 110717; 变成函数操作

<p> 3   隐式字符编码转换
<p> 在一个字符编码是utf8 一个是utf8mb4时 比较 这个设定很好理解，
<p>字符集utf8mb4是utf8的超集，所以当这两个类型的字符串在做比较的时候，MySQL内部的操作是，先把utf8字符串转成utf8mb4字符集，再做比较
<p>utf8mb4是utf8的超集。类似地，在程序设计语言里面，做自动类型转换的时候，为了避免数据在转换过程中由于截断导致数据错误，也都是“按数据长度增加的方向”进行转换的。
<p> 变成 where CONVERT(traideid USING utf8mb4)="asc"

<p> 2,3  最直接就是把两边格式改成一样 不然就把函数操作放在后面


### 19 | 为什么我只查一行的语句，也执行这么慢？

#### 第一类：查询长时间不返回
<p> 大概率是表t被锁住了
<p> 比如 lock table write 锁表未释放 或者其他DMLsuo
<p> 使用show processlist命令查看
<p>各字段的含义：
<pre><code>
1.id 该进程的标识；
2.user 显示当前用户
3.host 显示来源IP和端口
4.db 显示当前连接的数据库
5.command 显示当前连接的执行的命令，休眠 sleep ，查询 query ，连接 connect 
6.time 此这个状态持续的时间，单位是秒
7.state列 显示使用当前连接的sql语句的状态，很重要的列，详见下面state列的含义
8.info 显示sql语句，长sql可能显示不全
 
state列的含义：
1.analyzing 比如进行analyze table时 
2.checking table 线程正在执行表检查操作 
3.cleaning up 正准备释放内存 
4.closing tables 应该是一个快速的操作，如果不是这样的话，则应该检查硬盘空间是否已满或者磁盘io是否达到瓶颈 
5.copy to tmp table 线程正在处理一个alter table语句 
6.copying to tmp table 线程将数据写入内存中的临时表 
7.copying to tmp table on disk 线程正在将数据写入磁盘中的临时表。与tmp_table_size参数有关系 
8.creating sort index 线程正在使用内部临时表处理一个select操作 
9.fulltext initialization  服务器正准备进行自然语言全文索引 
10.sending data 线程正在读取和处理一条select语句的行，并且将数据发送至客户端，在此期间会执行大量的磁盘访问 
11.sorting index 线程正在对索引页进行排序 
12.updating 线程寻找更新匹配的行进行更新 
13.waiting for lock_type lock 等待各个种类的表锁 
  </code></pre>
<p>当state列为waiting for lock_type lock时，表示某个SQL正在query导致别的SQL等待锁，需要根据id杀进程。
<img src="https://static001.geekbang.org/resource/image/50/28/5008d7e9e22be88a9c80916df4f4b328.png">
<p>performance_schema和sys系统库以后，就方便多了。（MySQL启动时需要设置performance_schema=on)
其他有用命令

<p>查看被锁的表
<li>mysql> show open tables where in_use > 0;

<p>查看当前的事务
<li>mysql> select * from information_schema.innodb_trx;

<p>查看被锁的事务
mysql> select * from information_schema.innodb_locks;

<p>查看等锁的事务
<li>mysql> select * from information_schema.innodb_lock_waits;

#### 等flush 
<img src="https://static001.geekbang.org/resource/image/2d/24/2d8250398bc7f8f7dce8b6b1923c3724.png">

<p> flush 操作一般两个
<li>flush tables t with read lock;
  
<li>  flush tables with read lock;

<p>指定表t的话，代表的是只关闭表t；如果没有指定具体的表名，则表示关闭MySQL里所有打开的表
<p>复现步骤如图所示
<img src="https://static001.geekbang.org/resource/image/2b/9c/2bbc77cfdb118b0d9ef3fdd679d0a69c.png">

<p> 找到哪个锁表  把他kill

#### 等行锁
<p>来到引擎里了。
<li>mysql> select * from t where id=1 lock in share mode;
<img src="https://static001.geekbang.org/resource/image/3e/75/3e68326b967701c59770612183277475.png">

<p>  事物A 也会一直锁表 不提交 需要关掉他
<p>如果你用的是MySQL 5.7版本，可以通过sys.innodb_lock_waits 表查到。
<p>查询方法是：
<li>mysql> select * from t sys.innodb_lock_waits where locked_table=`'test'.'t'`\G

<p> 第二类：查询慢
 <img src="https://static001.geekbang.org/resource/image/84/ff/84667a3449dc846e393142600ee7a2ff.png">
 <p> session B更新完100万次，生成了100万个回滚日志(undo log)。
     
 <p>带lock in share mode的SQL语句，是当前读，因此会直接读到1000001这个结果，所以速度很快；而select * from t where id=1这个语句，是一致性读，因此需要从1000001开始，依次执行undo log，执行了100万次以后，才将1这个结果返回
 
 
### 20 | 幻读是什么，幻读有什么问题？
 <img src="https://static001.geekbang.org/resource/image/5b/8b/5bc506e5884d21844126d26bbe6fa68b.png">
<p> “幻读”：
 
<li> 在可重复读隔离级别下，普通的查询是快照读，是不会看到别的事务插入的数据的。因此，幻读在“当前读”下才会出现。
 
<li>  上面session B的修改结果，被session A之后的select语句用“当前读”看到，不能称为幻读。幻读仅专指“新插入的行”

#### 幻读有什么问题？
<img src="https://static001.geekbang.org/resource/image/7a/07/7a9ffa90ac3cc78db6a51ff9b9075607.png">

<li>首先是语义上的。session A在T1时刻就声明了，“我要把所有d=5的行锁住，不准别的事务进行读写操作”。而实际上，这个语义被破坏了。
<li> 数据一致性的问题。   我们知道，锁的设计是为了保证数据的一致性。而这个一致性，不止是数据库内部数据状态在此刻的一致性，还包含了数据和日志在逻辑上的一致性

<img src="https://static001.geekbang.org/resource/image/dc/92/dcea7845ff0bdbee2622bf3c67d31d92.png">

<p>执行完成后，数据库里会是什么结果。

<li>经过T1时刻，id=5这一行变成 (5,5,100)，当然这个结果最终是在T6时刻正式提交的;

<li>经过T2时刻，id=0这一行变成(0,5,5);

<li>经过T4时刻，表里面多了一行(1,5,5);

<p>其他行跟这个执行序列无关，保持不变。

<li>这样看，这些数据也没啥问题，但是我们再来看看这时候binlog里面的内容。

<li>T2时刻，session B事务提交，写入了两条语句；

<li>T4时刻，session C事务提交，写入了两条语句；

<li>T6时刻，session A事务提交，写入了update t set d=100 where d=5 这条语句。

<p> 日志数据和实际不一致了
<p>  把扫描的行都加上锁
<img src="https://static001.geekbang.org/resource/image/34/47/34ad6478281709da833856084a1e3447.png">
<p>在binlog里面，执行序列是这样的：
  <pre><code>
insert into t values(1,1,5); /*(1,1,5)*/
update t set c=5 where id=1; /*(1,5,5)*/
update t set d=100 where d=5;/*所有d=5的行，d改成100*/
update t set d=5 where id=0; /*(0,0,5)*/
update t set c=5 where id=0; /*(0,5,5)*/
</code></pre>
<p>所有的记录都加上锁，还是阻止不了新插入的记录 这就是幻读

####  如何解决幻读？
<p>新插入记录这个动作，要更新的是记录之间的“间隙”。因此，为了解决幻读问题，InnoDB只好引入新的锁，也就是间隙锁(Gap Lock)。
<p>间隙锁和 读锁 写锁不一样 间隙锁不一样，跟间隙锁存在冲突关系的，是“往这个间隙中插入一个记录”这个操作
<p>间隙锁和行锁合称next-key lock，每个next-key lock是前开后闭区间  索引默认有不存在的最大值 没有最小

<p> 间隙锁和next-key lock的引入，帮我们解决了幻读的问题，但同时也带来了一些“困扰”。
<img sec="https://static001.geekbang.org/resource/image/df/be/df37bf0bb9f85ea59f0540e24eb6bcbe.png">
<p> 两个session进入互相等待状态，形成死锁。当然，InnoDB的死锁检测马上就发现了这对死锁关系，让session A的insert语句报错返回了。
    
 <p>你现在知道了，间隙锁的引入，可能会导致同样的语句锁住更大的范围，这其实是影响了并发度的
 
 <p> 所以很多公司就使用的是读提交隔离级别加binlog_format=row的组合
 

### 21 | 为什么我只改一行的语句，锁这么多？
<p> 主要next-key lock 临健锁 的上锁详情
<p><a href="https://www.cnblogs.com/a-phper/p/10313940.html"> 为什么我只改一行的语句，锁这么多？ </a>
<p> 主要规则:    包含了两个“原则”、两个“优化”和一个“bug”。
             
<li>   原则1：加锁的基本单位是next-key lock。希望你还记得，next-key lock是前开后闭区间。
<li>   原则2：查找过程中访问到的对象才会加锁。
<li>   优化1：索引上的等值查询，给唯一索引加锁的时候，next-key lock退化为行锁。
<li>   优化2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock退化为间隙锁。
<li>   一个bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止。

<p> 根据实例总结:
<li> 加锁单位是next-key lock 左闭右开
<li> 覆盖索引 没有实际访问对象 只会有一个间隙锁
<li> 主键上的等值 会变成行锁 ，如果有范围 会走到不满足的行 加上next-key
<li> 非主键 不会优化 还是next-key，有范围 还是走到不满足 加上next-key
<li> 如果索引上有等值的  他们之间也有间隙
<li> 索引上只有等值 没有范围条件 ，next-key会退化成间隙锁
<li> limit 范围会加上一个next-key 后面不加锁
<li> 两个事物相互加 next-key ，会死锁 mysql 会让一个回滚

<p> ps: 加next-key 都是在可重复读隔离级别(repeatable-read)下的
<p> 添加<a href="/src/main/resources/note/sql/Mysql常用命令.MD">Mysql常用命令.MD</a>

###    22 | MySQL有哪些“饮鸩止渴”提高性能的方法？
<p> 第一种方法：先处理掉那些占着连接但是不工作的线程。
<p> 第二种方法：减少连接过程的消耗。
<p> 慢查询处理：1 索引没有设计好 2 语句不正确 3 MySQL选错了索引

###  23 | MySQL是怎么保证数据不丢的？
<p> MySQL写入binlog和redo log的流程


####  1 binlog的写入机制
<p> 事务执行过程中，先把日志写到binlog cache，事务提交的时候，再把binlog cache写到binlog文件中。

<img src="https://static001.geekbang.org/resource/image/9e/3e/9ed86644d5f39efb0efec595abb92e3e.png">
<p>线程有自己binlog cache，但是共用同一份binlog文件。

<li>图中的write，指的就是指把日志写入到文件系统的page cache，并没有把数据持久化到磁盘，所以速度比较快。
<li>图中的fsync，才是将数据持久化到磁盘的操作。一般情况下，我们认为fsync才占磁盘的IOPS。
<p>write 和fsync的时机，是由参数sync_binlog控制的：

<li>sync_binlog=0的时候，表示每次提交事务都只write，不fsync；

<li>sync_binlog=1的时候，表示每次提交事务都会执行fsync；

<li>sync_binlog=N(N>1)的时候，表示每次提交事务都write，但累积N个事务后才fsync。

<p>因此，在出现IO瓶颈的场景里，将sync_binlog设置成一个比较大的值，可以提升性能。在实际的业务场景中，考虑到丢失日志量的可控性，一般不建议将这个参数设成0，比较常见的是将其设置为100~1000中的某个数值。

<p>但是，将sync_binlog设置为N，对应的风险是：如果主机发生异常重启，会丢失最近N个事务的binlog日志。

#### redo log的写入机制
<p>状态分别是：

<li>存在redo log buffer中，物理上是在MySQL进程内存中，就是图中的红色部分；

<li>写到磁盘(write)，但是没有持久化（fsync)，物理上是在文件系统的page cache里面，也就是图中的黄色部分；

<li>持久化到磁盘，对应的是hard disk，也就是图中的绿色部分。

<p>日志写到redo log buffer是很快的，wirte到page cache也差不多，但是持久化到磁盘的速度就慢多了。

<p>为了控制redo log的写入策略，InnoDB提供了innodb_flush_log_at_trx_commit参数，它有三种可能取值：

<li>设置为0的时候，表示每次事务提交时都只是把redo log留在redo log buffer中;

<li>设置为1的时候，表示每次事务提交时都将redo log直接持久化到磁盘；

<li>设置为2的时候，表示每次事务提交时都只是把redo log写到page cache。

<p>InnoDB有一个后台线程，每隔1秒，就会把redo log buffer中的日志，调用write写到文件系统的page cache，然后调用fsync持久化到磁盘。

<p>实际上，除了后台线程每秒一次的轮询操作外，还有两种场景会让一个没有提交的事务的redo log写入到磁盘中。
   
<li>   一种是，redo log buffer占用的空间即将达到 innodb_log_buffer_size一半的时候，后台线程会主动写盘。注意，由于这个事务并没有提交，所以这个写盘动作只是write，而没有调用fsync，也就是只留在了文件系统的page cache。
   
<li>   另一种是，并行的事务提交的时候，顺带将这个事务的redo log buffer持久化到磁盘。假设一个事务A执行到一半，已经写了一些redo log到buffer中，这时候有另外一个线程的事务B提交，如果innodb_flush_log_at_trx_commit设置的是1，那么按照这个参数的逻辑，事务B要把redo log buffer里的日志全部持久化到磁盘。这时候，就会带上事务A在redo log buffer里的日志一起持久化到磁盘

#### redo log 的组提交
<p> 主要就是拖时间 多个一起提交 节约磁盘IOPS
<img src="https://static001.geekbang.org/resource/image/93/cc/933fdc052c6339de2aa3bf3f65b188cc.png">
<p>从图中可以看到，

<li>trx1是第一个到达的，会被选为这组的 leader；

<li>等trx1要开始写盘的时候，这个组里面已经有了三个事务，这时候LSN也变成了160；

<li>trx1去写盘的时候，带的就是LSN=160，因此等trx1返回时，所有LSN小于等于160的redo log，都已经被持久化到磁盘；

<li>这时候trx2和trx3就可以直接返回了。

<p>所以，一次组提交里面，组员越多，节约磁盘IOPS的效果越好。但如果只有单线程压测，那就只能老老实实地一个事务对应一次持久化操作了。

#### bin_log 的组提交
<p>设置 binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no_delay_count来实现。

<li>binlog_group_commit_sync_delay参数，表示延迟多少微秒后才调用fsync;

<li>binlog_group_commit_sync_no_delay_count参数，表示累积多少次以后才调用fsync。

<p>这两个条件是或的关系，也就是说只要有一个满足条件就会调用fsync。

<p>所以，当binlog_group_commit_sync_delay设置为0的时候，binlog_group_commit_sync_no_delay_count也无效了

#### 日志的持久化
<img sec="https://static001.geekbang.org/resource/image/5a/28/5ae7d074c34bc5bd55c82781de670c28.png">

#### 针对日志提升性能  可以考虑以下三种方法：

<li>设置 binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no_delay_count参数，减少binlog的写盘次数。这个方法是基于“额外的故意等待”来实现的，因此可能会增加语句的响应时间，但没有丢失数据的风险。

<li>将sync_binlog 设置为大于1的值（比较常见是100~1000）。这样做的风险是，主机掉电时会丢binlog日志。

<li>将innodb_flush_log_at_trx_commit设置为2。这样做的风险是，主机掉电的时候会丢数据。


###  24 | MySQL是怎么保证主备一致的？
<p> 主从之间,binlog的使用

#### MySQL主备的基本原理
<img src="https://static001.geekbang.org/resource/image/fd/10/fd75a2b37ae6ca709b7f16fe060c2c10.png">

<p>客户端的读写都直接访问节点A，而节点B是A的备库，只是将A的更新都同步过来，到本地执行。这样可以保持节点B和A的数据是相同的。

<p>当需要切换的时候，就切成状态2。这时候客户端读写访问的都是节点B，而节点A是B的备库。

<p>在状态1中，虽然节点B没有被直接访问，但是我依然建议你把节点B（也就是备库）设置成只读（readonly）模式。这样做，有以下几个考虑：

<li>有时候一些运营类的查询语句会被放到备库上去查，设置为只读可以防止误操作；

<li>防止切换逻辑有bug，比如切换过程中出现双写，造成主备不一致；

<li>可以用readonly状态，来判断节点的角色


<p>节点A到B这条线的内部流程
<img src="https://static001.geekbang.org/resource/image/a6/a3/a66c154c1bc51e071dd2cc8c1d6ca6a3.png">
<p>一个事务日志同步的完整过程是这样的：
<li>在备库B上通过change master命令，设置主库A的IP、端口、用户名、密码，以及要从哪个位置开始请求binlog，这个位置包含文件名和日志偏移量。
<li>在备库B上执行start slave命令，这时候备库会启动两个线程，就是图中的io_thread和sql_thread。其中io_thread负责与主库建立连接。
<li>主库A校验完用户名、密码后，开始按照备库B传过来的位置，从本地读取binlog，发给B。
<li>备库B拿到binlog后，写到本地文件，称为中转日志（relay log）。
<li>sql_thread读取中转日志，解析出日志里的命令，并执行。  

#### binlog的三种格式对比

<p> statement格式
<p> 优点
<li> 占用空间小 快
<p> 缺点
<li> 主从之间 可能选用索引不一样  数据不一致
<li> 确定的函数（如uuid(),now()）会出现主从数据不一致问题
<p> ROW 格式
<p> 数据一致性有保证 但占用空间大

<p>Mixed格
<p> mysql 自己选用哪种格式

#### 循环复制问题
<p> binlog的特性确保了在备库执行相同的binlog，可以得到与主库相同的状态 但上面是M-S模式 但实际生产上使用比较多的是双M结构
<img src="https://static001.geekbang.org/resource/image/20/56/20ad4e163115198dc6cf372d5116c956.png">

<p>双M结构还有一个问题需要解决。

<p>业务逻辑在节点A上更新了一条语句，然后再把生成的binlog 发给节点B，节点B执行完这条更新语句后也会生成binlog。
<p>（我建议你把参数log_slave_updates设置为on，表示备库执行relay log后生成binlog）

<p>MySQL在binlog中记录了这个命令第一次执行时所在实例的server id。因此，我们可以用下面的逻辑，来解决两个节点间的循环复制的问题：

<p>规定两个库的server id必须不同，如果相同，则它们之间不能设定为主备关系；

<p>一个备库接到binlog并在重放的过程中，生成与原binlog的server id相同的新的binlog；

<p>每个库在收到从自己的主库发过来的日志后，先判断server id，如果跟自己的相同，表示这个日志是自己生成的，就直接丢弃这个日志

<p> ps:如果是server-b 产生的log  在A和A'之间主从 还是会循环 2 如果set global server-id 也可能错

### 25 | MySQL是怎么保证高可用的？
<p> 主从之间的切换 是保证mysql高可用的基础

#### 主备延迟
<p> 数据同步有关的时间点主要包括以下三个：
<li>    主库A执行完成一个事务，写入binlog，我们把这个时刻记为T1;
<li>     之后传给备库B，我们把备库B接收完这个binlog的时刻记为T2;
<li>     备库B执行完成这个事务，我们把这个时刻记为T3。
<li>     所谓主备延迟，就是同一个事务，在备库执行完成的时间和主库执行完成的时间之间的差值，也就是T3-T1

<p>备库上执行show slave status命令，它的返回结果里面会显示seconds_behind_master，用于表示当前备库延迟了多少秒 

#### 主备延迟的来源
<li> 1 有些部署条件下，备库所在机器的性能要比主库所在的机器性能差。
<li> 2 备库的压力大
<p>处理：
<li>一主多从。除了备库外，可以多接几个从库，让这些从库来分担读的压力。
<li>通过binlog输出到外部系统，比如Hadoop这类系统，让外部系统提供统计类查询的能力。
<li> 3 即大事务

#### 可靠性优先策略
<p>双M结构下，从状态1到状态2切换的详细过程是这样的：

<li>判断备库B现在的seconds_behind_master，如果小于某个值（比如5秒）继续下一步，否则持续重试这一步；

<li>把主库A改成只读状态，即把readonly设置为true；

<li>判断备库B的seconds_behind_master的值，直到这个值变成0为止；

<li>把备库B改成可读写状态，也就是把readonly 设置为false；

<li>把业务请求切到备库B。

<p>这个切换流程，一般是由专门的HA系统来完成的，我们暂时称之为可靠性优先流程。
 <img src="https://static001.geekbang.org/resource/image/54/4a/54f4c7c31e6f0f807c2ab77f78c8844a.png">
 
 <p>如果我强行把步骤4、5调整到最开始执行，也就是说不等主备数据同步，直接把连接切到备库B，并且让备库B可以读写，那么系统几乎就没有不可用时间了。
    
 <p>    我们把这个切换流程，暂时称作可用性优先流程。这个切换流程的代价，就是可能出现数据不一致的情况

 <p>用可用性优先策略，但设置binlog_format=row
 <p> 数据不一致  两边的主备同步的应用线程会报错duplicate key error并停止
 
 <p>结论：
    
<li>    使用row格式的binlog时，数据不一致的问题更容易被发现。而使用mixed或者statement格式的binlog时，数据很可能悄悄地就不一致了。如果你过了很久才发现数据不一致的问题，很可能这时的数据不一致已经不可查，或者连带造成了更多的数据逻辑不一致。
    
<li>    主备切换的可用性优先策略会导致数据不一致。因此，大多数情况下，我都建议你使用可靠性优先策略。毕竟对数据服务来说的话，数据的可靠性一般还是要优于可用性的。

<p> 在异常情况下 可靠性优先切换
<p>假设，主库A和备库B间的主备延迟是30分钟，这时候主库A掉电了，HA系统要切换B作为主库。我们在主动切换的时候，可以等到主备延迟小于5秒的时候再启动切换，但这时候已经别无选择了
<p>采用可靠性优先策略的话，你就必须得等到备库B的seconds_behind_master=0之后，才能切换。但现在的情况比刚刚更严重，并不是系统只读、不可写的问题了，而是系统处于完全不可用的状态。因为，主库A掉电后，我们的连接还没有切到备库B
<p> 在满足数据可靠性的前提下，MySQL高可用系统的可用性，是依赖于主备延迟的。延迟的时间越小，在主库故障的时候，服务恢复需要的时间就越短，可用性就越高


###   26 | 备库为什么会延迟好几个小时？
<p> 主题:多线程备库 同步

<p> 主备同步流程
<img src="https://static001.geekbang.org/resource/image/1a/ef/1a85a3bac30a32438bfd8862e5a34eef.png">
<p>5.6版本之前，MySQL只支持单线程复制，由此在主库并发高、TPS高时就会出现严重的主备延迟问题

<img src="https://static001.geekbang.org/resource/image/bc/45/bcf75aa3b0f496699fd7885426bc6245.png">
<p> 多线程 复制线程模型

<p>coordinator在分发的时候，需要满足以下这两个基本要求：

<li>不能造成更新覆盖。这就要求更新同一行的两个事务，必须被分发到同一个worker中。
<li>同一个事务不能被拆开，必须放到同一个worker中。

 #### 按表分发策略
<p> 思路是，如果两个事务更新不同的表，它们就可以并行。因为数据是存储在表里的，所以按表分发，可以保证两个worker不会更新同一行

<img src="https://static001.geekbang.org/resource/image/8b/76/8b6976fedd6e644022d4026581fb8d76.png">
<p>图中，hash_table_1表示，现在worker_1的“待执行事务队列”里，有4个事务涉及到db1.t1表，有1个事务涉及到db2.t2表；hash_table_2表示，现在worker_2中有一个事务会更新到表t3的数据。

<p>假设在图中的情况下，coordinator从中转日志中读入一个新事务T，这个事务修改的行涉及到表t1和t3。

<p>现在我们用事务T的分配流程，来看一下分配规则。

<li>由于事务T中涉及修改表t1，而worker_1队列中有事务在修改表t1，事务T和队列中的某个事务要修改同一个表的数据，这种情况我们说事务T和worker_1是冲突的。

<li>按照这个逻辑，顺序判断事务T和每个worker队列的冲突关系，会发现事务T跟worker_2也冲突。

<li>事务T跟多于一个worker冲突，coordinator线程就进入等待。

<li>每个worker继续执行，同时修改hash_table。假设hash_table_2里面涉及到修改表t3的事务先执行完成，就会从hash_table_2中把db1.t3这一项去掉。

<li>这样coordinator会发现跟事务T冲突的worker只有worker_1了，因此就把它分配给worker_1。

<li>coordinator继续读下一个中转日志，继续分配事务。
<p>每个事务在分发的时候，跟所有worker的冲突关系包括以下三种情况：

<li>如果跟所有worker都不冲突，coordinator线程就会把这个事务分配给最空闲的woker;

<li>如果跟多于一个worker冲突，coordinator线程就进入等待状态，直到和这个事务存在冲突关系的worker只剩下1个；

<li>如果只跟一个worker冲突，coordinator线程就会把这个事务分配给这个存在冲突关系的worker。

<p>这个按表分发的方案，在多个表负载均匀的场景里应用效果很好。但是，如果碰到热点表，比如所有的更新事务都会涉及到某一个表的时候，所有事务都会被分配到同一个worker中，就变成单线程复制了。

####  按行分发策略
<p>热点表的并行复制问题，就需要一个按行并行复制的方案。按行复制的核心思路是：如果两个事务没有更新相同的行，它们在备库上可以并行执行。显然，这个模式要求binlog格式必须是row。
<p>这时候，我们判断一个事务T和worker是否冲突，用的就规则就不是“修改同一个表”，而是“修改同一行”。

<p>按行复制和按表复制的数据结构差不多，也是为每个worker，分配一个hash表。只是要实现按行分发，这时候的key，就必须是“库名+表名+唯一键的值”。
<p> 相比于按表并行分发策略，按行并行策略在决定线程分发的时候，需要消耗更多的计算资源


<p>按行分发的策略有两个问题：
   
<li>   耗费内存。比如一个语句要删除100万行数据，这时候hash表就要记录100万个项。
<li>  耗费CPU。解析binlog，然后计算hash值，对于大事务，这个成本还是很高的。

#### 这两个方案其实都有一些约束条件：
     
<li>     要能够从binlog里面解析出表名、主键值和唯一索引的值。也就是说，主库的binlog格式必须是row；
<li>     表必须有主键；
<li>     不能有外键。表上如果有外键，级联更新的行不会记录在binlog中，这样冲突检测就不准确。 

<p>实现这个策略的时候会设置一个阈值，单个事务如果超过设置的行数阈值（比如，如果单个事务更新的行数超过10万行），就暂时退化为单线程模式，退化过程的逻辑大概是这样的：
<li>coordinator暂时先hold住这个事务；
<li>等待所有worker都执行完成，变成空队列；
<li>coordinator直接执行这个事务；
<li>恢复并行模式。

#### MySQL 5.6版本的并行复制策略
<p>支持了并行复制，只是支持的粒度是按库并行。理解了上面介绍的按表分发策略和按行分发策略，你就理解了，用于决定分发策略的hash表里，key就是数据库名。

<p>这个策略的并行效果，取决于压力模型。如果在主库上有多个DB，并且各个DB的压力均衡，使用这个策略的效果会很好。

<p>相比于按表和按行分发，这个策略有两个优势：

<li>构造hash值的时候很快，只需要库名；而且一个实例上DB数也不会很多，不会出现需要构造100万个项这种情况。

<li>不要求binlog的格式。因为statement格式的binlog也可以很容易拿到库名。

<p>但是，如果你的主库上的表都放在同一个DB里面，这个策略就没有效果了；或者如果不同DB的热点不同，比如一个是业务逻辑库，一个是系统配置库，那也起不到并行的效果。

<p>理论上你可以创建不同的DB，把相同热度的表均匀分到这些不同的DB中，强行使用这个策略。不过据我所知，由于需要特地移动数据，这个策略用得并不多

#### MariaDB的并行复制策略
<p>redo log组提交(group commit)优化， 而MariaDB的并行复制策略利用的就是这个特性：

<p>能够在同一组里提交的事务，一定不会修改同一行；
<p>主库上可以并行执行的事务，备库上也一定是可以并行执行的。
<p>在实现上，MariaDB是这么做的：
<p>在一组里面一起提交的事务，有一个相同的commit_id，下一组就是commit_id+1；
<p>commit_id直接写到binlog里面；
<p>传到备库应用的时候，相同commit_id的事务分发到多个worker执行；
<p>这一组全部执行完成后，coordinator再去取下一批。
<p>当时，这个策略出来的时候是相当惊艳的。因为，之前业界的思路都是在“分析binlog，并拆分到worker”上。而MariaDB的这个策略，目标是“模拟主库的并行模式”。
<p>但是，这个策略有一个问题，它并没有实现“真正的模拟主库并发度”这个目标。在主库上，一组事务在commit的时候，下一组事务是同时处于“执行中”状态的。
<p> ps:对这个问题理解 ,组提交依赖于组内成员都完成 但如果1,3都完成 2未完成， 2会同时阻塞1,3和后面的事物 ，只有一个work在工作 ，资源浪费
 <p> 类似java中的future

#### MySQL 5.7的并行复制策略

 <p> 在MariaDB并行复制实现之后，官方的MySQL5.7版本也提供了类似的功能，由参数slave-parallel-type来控制并行复制策略：

 <li> 配置为DATABASE，表示使用MySQL 5.6版本的按库并行策略；

 <li> 配置为 LOGICAL_CLOCK，表示的就是类似MariaDB的策略。不过，MySQL 5.7这个策略，针对并行度做了优化。
 <p> 优化思路:
 <p> 同时处于“执行状态”的所有事务，是不可以并行的  ----因为执行状态 不确定两个事物之间是否会锁冲突 分配到不同work 数据就不一致了
 <p> 但在两段式提交中 不用等到commit阶段，只要能够到达redo log prepare阶段，就表示事务已经通过锁冲突的检验了
  <p>因此，MySQL 5.7并行复制策略的思想是：
  <li>    同时处于prepare状态的事务，在备库执行时是可以并行的；
 <li>     处于prepare状态的事务，与处于commit状态的事务之间，在备库执行时也是可以并行的。
     
 <p>     我在第23篇文章，讲binlog的组提交的时候，介绍过两个参数：
     
<li>     binlog_group_commit_sync_delay参数，表示延迟多少微秒后才调用fsync;
<li>     binlog_group_commit_sync_no_delay_count参数，表示累积多少次以后才调用fsync。
 <p>     这两个参数是用于故意拉长binlog从write到fsync的时间，以此减少binlog的写盘次数。在MySQL 5.7的并行复制策略里，它们可以用来制造更多的“同时处于prepare阶段的事务”。这样就增加了备库复制的并行度。
 
#### MySQL 5.7.22的并行复制策略 
 <p>  在2018年4月份发布的MySQL 5.7.22版本里，MySQL增加了一个新的并行复制策略，基于WRITESET的并行复制。
 
 <p>  相应地，新增了一个参数binlog-transaction-dependency-tracking，用来控制是否启用这个新策略。这个参数的可选值有以下三种。
 
 <li> COMMIT_ORDER，表示的就是前面介绍的，根据同时进入prepare和commit来判断是否可以并行的策略。
  <li> WRITESET，表示的是对于事务涉及更新的每一行，计算出这一行的hash值，组成集合writeset。如果两个事务没有操作相同的行，也就是说它们的writeset没有交集，就可以并行。
 <li> WRITESET_SESSION，是在WRITESET的基础上多了一个约束，即在主库上同一个线程先后执行的两个事务，在备库执行的时候，要保证相同的先后顺序。
 
 
 ### 27 | 主库出问题了，从库怎么办？
 <p> 主题: 一主多从 
 <img src="https://static001.geekbang.org/resource/image/aa/79/aadb3b956d1ffc13ac46515a7d619e79.png">
<p> 虚线箭头表示的是主备关系，也就是A和A’互为主备， 从库B、C、D指向的是主库A。一主多从的设置，一般用于读写分离，主库负责所有的写入和一部分读，其他的读请求则由从库分担。

 <p> 如果主库A 出现了异常
 
#### 基于位点的主备切换
 把节点B设置成节点A’的从库的时候，需要执行一条change master命令：
<pre><code>
 CHANGE MASTER TO 
 MASTER_HOST=$host_name 
 MASTER_PORT=$port 
 MASTER_USER=$user_name 
 MASTER_PASSWORD=$password 
 MASTER_LOG_FILE=$master_log_name 
 MASTER_LOG_POS=$master_log_pos  
 </code></pre>
 这条命令有这么6个参数：
 
 MASTER_HOST、MASTER_PORT、MASTER_USER和MASTER_PASSWORD四个参数，分别代表了主库A’的IP、端口、用户名和密码。
 最后两个参数MASTER_LOG_FILE和MASTER_LOG_POS表示，要从主库的master_log_name文件的master_log_pos这个位置的日志继续同步。而这个位置就是我们所说的同步位点，也就是主库对应的文件名和日志偏移量。
 
 那么，这里就有一个问题了，节点B要设置成A’的从库，就要执行change master命令，就不可避免地要设置位点的这两个参数
 
 <p>取同步位点的方法是这样的：
 
 <li>等待新主库A’把中转日志（relay log）全部同步完成；
 
 <li> 在A’上执行show master status命令，得到当前A’上最新的File 和 Position；
 
 <li> 取原主库A故障的时刻T；
 
 <li> 用mysqlbinlog工具解析A’的File，得到T时刻的位点。
 <pre><code>
 mysqlbinlog File --stop-datetime=T --start-datetime=T     </code></pre>
 
 
<p> 这个值并不精确。为什么呢？
 
<p>  你可以设想有这么一种情况，假设在T这个时刻，主库A已经执行完成了一个insert 语句插入了一行数据R，并且已经将binlog传给了A’和B，然后在传完的瞬间主库A的主机就掉电了。
 
<p>  那么，这时候系统的状态是这样的：
 
<p>  在从库B上，由于同步了binlog， R这一行已经存在；
 
<p>  在新主库A’上， R这一行也已经存在，日志是写在123这个位置之后的；
 
<p>  我们在从库B上执行change master命令，指向A’的File文件的123位置，就会把插入R这一行数据的binlog又同步到从库B去执行。
<p>   通常情况下，我们在切换任务的时候，要先主动跳过这些错误，有两种常用的方法。
  
<p>   一种做法是，主动跳过一个事务。跳过命令的写法是：
<pre><code>  
  set global sql_slave_skip_counter=1;
  start slave;  </code></pre>
<p>   因为切换过程中，可能会不止重复执行一个事务，所以我们需要在从库B刚开始接到新主库A’时，持续观察，每次碰到这些错误就停下来，执行一次跳过命令，直到不再出现停下来的情况，以此来跳过可能涉及的所有事务。
  
<p>   另外一种方式是，通过设置slave_skip_errors参数，直接设置跳过指定的错误。
  
<p>   在执行主备切换时，有这么两类错误，是经常会遇到的：
  
<li>   1062错误是插入数据时唯一键冲突；
<li>   1032错误是删除数据时找不到行。
<p>   因此，我们可以把slave_skip_errors 设置为 “1032,1062”，这样中间碰到这两个错误时就直接跳过。
  
<p>   这里需要注意的是，这种直接跳过指定错误的方法，针对的是主备切换时，由于找不到精确的同步位点，所以只能采用这种方法来创建从库和新主库的主备关系。

 #### GTID
<p> GTID的全称是Global Transaction Identifier，也就是全局事务ID，是一个事务在提交的时候生成的，是这个事务的唯一标识。它由两部分组成，格式是：
 
> GTID=server_uuid:gno
 <p>其中：
 
<p> server_uuid是一个实例第一次启动时自动生成的，是一个全局唯一的值；
<p> gno是一个整数，初始值是1，每次提交事务的时候分配给这个事务，并加1。
<p> 这里我需要和你说明一下，在MySQL的官方文档里，GTID格式是这么定义的：

> GTID=source_id:transaction_id

<p>在GTID模式下，每个事务都会跟一个GTID一一对应。这个GTID有两种生成方式，而使用哪种方式取决于session变量gtid_next的值。

<li>如果gtid_next=automatic，代表使用默认值。这时，MySQL就会把server_uuid:gno分配给这个事务。
a. 记录binlog的时候，先记录一行 SET @@SESSION.GTID_NEXT=‘server_uuid:gno’;
b. 把这个GTID加入本实例的GTID集合。

<li>如果gtid_next是一个指定的GTID的值，比如通过set gtid_next='current_gtid’指定为current_gtid，那么就有两种可能：
a. 如果current_gtid已经存在于实例的GTID集合中，接下来执行的这个事务会直接被系统忽略；
b. 如果current_gtid没有存在于实例的GTID集合中，就将这个current_gtid分配给接下来要执行的事务，也就是说系统不需要给这个事务生成新的GTID，因此gno也不用加1。

<p>注意，一个current_gtid只能给一个事务使用。这个事务提交后，如果要执行下一个事务，就要执行set 命令，把gtid_next设置成另外一个gtid或者automatic。

<pre><code>
set gtid_next='aaaaaaaa-cccc-dddd-eeee-ffffffffffff:10';
begin;
commit;
set gtid_next=automatic;
start slave;
</code></pre>
 
#### 基于GTID的主备切换  
<p>在GTID模式下，备库B要设置为新主库A’的从库的语法如下：
  <pre><code>
CHANGE MASTER TO 
MASTER_HOST=$host_name 
MASTER_PORT=$port 
MASTER_USER=$user_name 
MASTER_PASSWORD=$password 
master_auto_position=1   </code></pre>
<p>其中，master_auto_position=1就表示这个主备关系使用的是GTID协议。可以看到，前面让我们头疼不已的MASTER_LOG_FILE和MASTER_LOG_POS参数，已经不需要指定了
<p>B上执行start slave命令，取binlog的逻辑是这样的：

<p>实例B指定主库A’，基于主备协议建立连接。

<p>实例B把set_b发给主库A’。

<p>实例A’算出set_a与set_b的差集，也就是所有存在于set_a，但是不存在于set_b的GITD的集合，判断A’本地是否包含了这个差集需要的所有binlog事务。
<p>a. 如果不包含，表示A’已经把实例B需要的binlog给删掉了，直接返回错误；
<p>b. 如果确认全部包含，A’从自己的binlog文件里面，找出第一个不在set_b的事务，发给B；

<p>之后就从这个事务开始，往后读文件，按顺序取binlog发给B去执行。
<p>其实，这个逻辑里面包含了一个设计思想：在基于GTID的主备关系里，系统认为只要建立主备关系，就必须保证主库发给备库的日志是完整的。因此，如果实例B需要的日志已经不存在，A’就拒绝把日志发给B。

#### GTID和在线DDL
<p>1 双M结构下，备库执行的DDL语句也会传给主库，为了避免传回后对主库造成影响，要通过set sql_log_bin=off关掉binlog
<p>2 这两个互为主备关系的库还是实例X和实例Y，且当前主库是X，并且都打开了GTID模式。这时的主备切换流程可以变成下面这样：
 
<li> 在实例X上执行stop slave。
 
<li> 在实例Y上执行DDL语句。注意，这里并不需要关闭binlog。
 
<li> 执行完成后，查出这个DDL语句对应的GTID，并记为 server_uuid_of_Y:gno。
 
<li> 到实例X上执行以下语句序列：
  <pre><code>
   set GTID_NEXT="server_uuid_of_Y:gno";
   begin;
   commit;
   set gtid_next=automatic;
   start slave;</code></pre>

<p>这样做的目的在于，既可以让实例Y的更新有binlog记录，同时也可以确保不会在实例X上执行这条更新。
 
<p> 接下来，执行完主备切换，然后照着上述流程再执行一遍即可。
  

### 28 | 读写分离有哪些坑？
<p> 一主多从架构的应用场景：读写分离，以及怎么处理主备延迟导致的读写分离问题。

<img src="https://static001.geekbang.org/resource/image/13/aa/1334b9c08b8fd837832fdb2d82e6b0aa.png">
<p>读写分离的主要目标就是分摊主库的压力。图1中的结构是客户端（client）主动做负载均衡，这种模式下一般会把数据库的连接信息放在客户端的连接层。也就是说，由客户端来选择后端数据库进行查询。

<p>还有一种架构是，在MySQL和客户端之间有一个中间代理层proxy，客户端只连接proxy， 由proxy根据请求类型和上下文决定请求的分发路由。
<img src="https://static001.geekbang.org/resource/image/06/18/065ef246c59019effc8384967d774318.png">

<p>客户端直连和带proxy的读写分离架构，各有哪些特点。

<li>客户端直连方案，因为少了一层proxy转发，所以查询性能稍微好一点儿，并且整体架构简单，排查问题更方便。但是这种方案，由于要了解后端部署细节，所以在出现主备切换、库迁移等操作的时候，客户端都会感知到，并且需要调整数据库连接信息。
你可能会觉得这样客户端也太麻烦了，信息大量冗余，架构很丑。其实也未必，一般采用这样的架构，一定会伴随一个负责管理后端的组件，比如Zookeeper，尽量让业务端只专注于业务逻辑开发。

<li>带proxy的架构，对客户端比较友好。客户端不需要关注后端细节，连接维护、后端信息维护等工作，都是由proxy完成的。但这样的话，对后端维护团队的要求会更高。而且，proxy也需要有高可用架构。因此，带proxy架构的整体就相对比较复杂。

<p>不论使用哪种架构，你都会碰到我们今天要讨论的问题：由于主从可能存在延迟，客户端执行完一个更新事务后马上发起查询，如果查询选择的是从库的话，就有可能读到刚刚的事务更新之前的状态。
 
<p> 这种“在从库上会读到系统的一个过期状态”的现象，在这篇文章里，我们暂且称之为“过期读”。

<p> 解决方案包括：
      
<li> 强制走主库方案；
<li> sleep方案；
<li> 判断主备无延迟方案；
<li> 配合semi-sync方案；
<li> 等主库位点方案；
<li> 等GTID方案。

#### 强制走主库方案
<p>可以将查询请求分为这么两类：
   
<li>   对于必须要拿到最新结果的请求，强制将其发到主库上。比如，在一个交易平台上，卖家发布商品以后，马上要返回主页面，看商品是否发布成功。那么，这个请求需要拿到最新的结果，就必须走主库。
<li>   对于可以读到旧数据的请求，才将其发到从库上。在这个交易平台上，买家来逛商铺页面，就算晚几秒看到最新发布的商品，也是可以接受的。那么，这类请求就可以走从库。
<p>   你可能会说，这个方案是不是有点畏难和取巧的意思，但其实这个方案是用得最多的

#### Sleep 方案
<p> sleep方案确实解决了类似场景下的过期读问题。但，从严格意义上来说，这个方案存在的问题就是不精确。这个不精确包含了两层意思：

<li>如果这个查询请求本来0.5秒就可以在从库上拿到正确结果，也会等1秒；
<li>如果延迟超过1秒，还是会出现过期读。

####  判断主备无延迟方案
<p> 要确保备库无延迟，通常有三种做法。

<p> 第一种确保主备无延迟的方法是，每次从库执行查询请求前，先判断seconds_behind_master是否已经等于0。如果还不等于0 ，那就必须等到这个参数变为0才能执行查询请求。
     
<p>      seconds_behind_master的单位是秒，如果你觉得精度不够的话，还可以采用对比位点和GTID的方法来确保主备无延迟

<p>第二种方法，对比位点确保主备无延迟：

<li>Master_Log_File和Read_Master_Log_Pos，表示的是读到的主库的最新位点；
<li>Relay_Master_Log_File和Exec_Master_Log_Pos，表示的是备库执行的最新位点。
<p>如果Master_Log_File和Relay_Master_Log_File、Read_Master_Log_Pos和Exec_Master_Log_Pos这两组值完全相同，就表示接收到的日志已经同步完成。

<p>第三种方法，对比GTID集合确保主备无延迟：
   
 <li>  Auto_Position=1 ，表示这对主备关系使用了GTID协议。
<li>   Retrieved_Gtid_Set，是备库收到的所有日志的GTID集合；
<li>   Executed_Gtid_Set，是备库所有已经执行完成的GTID集合。
<li>   如果这两个集合相同，也表示备库接收到的日志都已经同步完成。

#### 配合semi-sync

<p>问题
<p> 主库上执行完成了三个事务trx1、trx2和trx3，其中：
<li>    trx1和trx2已经传到从库，并且已经执行完成了；
<li>     trx3在主库执行完成，并且已经回复给客户端，但是还没有传到从库中。
<p>    如果这时候你在从库B上执行查询请求，按照我们上面的逻辑，从库认为已经没有同步延迟，但还是查不到trx3的。严格地说，就是出现了过期读

<p>要解决这个问题，就要引入半同步复制，也就是semi-sync replication。

<p>semi-sync做了这样的设计：

<li>事务提交的时候，主库把binlog发给从库；

<li>从库收到binlog以后，发回给主库一个ack，表示收到了；

<li>主库收到这个ack以后，才能给客户端返回“事务完成”的确认。

<p>也就是说，如果启用了semi-sync，就表示所有给客户端发送过确认的事务，都确保了备库已经收到了这个日志。

<p>但是，semi-sync+位点判断的方案，只对一主一备的场景是成立的。在一主多从场景中，主库只要等到一个从库的ack，就开始给客户端返回确认。这时，在从库上执行查询请求，就有两种情况：

<li>如果查询是落在这个响应了ack的从库上，是能够确保读到最新数据；

<li>但如果是查询落到其他从库上，它们可能还没有收到最新的日志，就会产生过期读的问题。
<p>semi-sync配合判断主备无延迟的方案，存在两个问题：

<li>一主多从的时候，在某些从库执行查询请求会存在过期读的现象；

<li>在持续延迟的情况下，可能出现过度等待的问题。


#### 等主库位点方案
<p>要理解等主库位点方案，我需要先和你介绍一条命令：

>select master_pos_wait(file, pos[, timeout]);

这条命令的逻辑如下：

<li>它是在从库执行的；

<li>参数file和pos指的是主库上的文件名和位置；

<li>timeout可选，设置为正整数N表示这个函数最多等待N秒。

<li>这个命令正常返回的结果是一个正整数M，表示从命令开始执行，到应用完file和pos表示的binlog位置，执行了多少事务。

<li>当然，除了正常返回一个正整数M外，这条命令还会返回一些其他结果，包括：

<li>如果执行期间，备库同步线程发生异常，则返回NULL；

<li>如果等待超过N秒，就返回-1；

<li>如果刚开始执行的时候，就发现已经执行过这个位置了，则返回0。

<p>逻辑：
   
<li>   trx1事务更新完成后，马上执行show master status得到当前主库执行到的File和Position；
   
<li>   选定一个从库执行查询语句；
   
<li>   在从库上执行select master_pos_wait(File, Position, 1)；
   
<li>   如果返回值是>=0的正整数，则在这个从库执行查询语句；
   
<li>   否则，到主库执行查询语句。


####  GTID方案

<p>如果你的数据库开启了GTID模式，对应的也有等待GTID的方案。

<p>MySQL中同样提供了一个类似的命令：

> select wait_for_executed_gtid_set(gtid_set, 1);

<p>这条命令的逻辑是：

<li>等待，直到这个库执行的事务中包含传入的gtid_set，返回0；

<li>超时返回1。

<p>在前面等位点的方案中，我们执行完事务后，还要主动去主库执行show master status。而MySQL 5.7.6版本开始，允许在执行完更新类事务后，把这个事务的GTID返回给客户端，这样等GTID的方案就可以减少一次查询。

<p>这时，等GTID的执行流程就变成了：

<li>trx1事务更新完成后，从返回包直接获取这个事务的GTID，记为gtid1；

<li>选定一个从库执行查询语句；

<li>在从库上执行 select wait_for_executed_gtid_set(gtid1, 1)；

<li>如果返回值是0，则在这个从库执行查询语句；

<li>否则，到主库执行查询语句。
<p> 流程和上一个一样


### 29 | 如何判断一个数据库是不是出问题了？

#### select 1判断
<p> 能查询进程状态 不能确认库的状态
<p> innodb_thread_concurrency   这个参数的默认值是0，表示不限制并发线程数量。但是，不限制并发线程数肯定是不行的 通常设置成64-128
<p> 并发连接和并发查询
<li> 在show processlist的结果里，看到的几千个连接，指的就是并发连接。而“当前正在执行”的语句，才是我们所说的并发查询
<p> 在线程进入锁等待以后，并发线程的计数会减一，也就是说等行锁（也包括间隙锁）的线程是不算在128里面的。
    
<li>    MySQL这样设计是非常有意义的。因为，进入锁等待的线程已经不吃CPU了；更重要的是，必须这么设计，才能避免整个系统锁死。
<li>    为什么呢？假设处于锁等待的线程也占并发线程的计数，你可以设想一下这个场景：
<li>    线程1执行begin; update t set c=c+1 where id=1, 启动了事务trx1， 然后保持这个状态。这时候，线程处于空闲状态，不算在并发线程里面。
<li>    线程2到线程129都执行 update t set c=c+1 where id=1; 由于等行锁，进入等待状态。这样就有128个线程处于等待状态；
<li>    如果处于锁等待状态的线程计数不减一，InnoDB就会认为线程数用满了，会阻止其他语句进入引擎执行，这样线程1不能提交事务。而另外的128个线程又处于锁等待状态，整个系统就堵住了。

    
#### 查表判断
<p>在系统库（mysql库）里创建一个表，比如命名为health_check，里面只放一行数据，然后定期执行：
<p> 这种方法能检测并发线程过多导致的数据库不可用的情况。 空间满了以后，这种方法又会变得不好使。
<p> 如 空间满了 要写入bin_log  但写不进去  返回结果却是对的

#### 更新判断
<p>用更新，放个有意义的字段，常见做法是放一个timestamp字段，用来表示最后一次执行检测的时间
<p> 因为这儿如果有主从 update now() 有可能数据不一致 所以要加个字段 一般用server-id 主从之间一定不一致
<pre><code>
mysql> CREATE TABLE `health_check` (
  `id` int(11) NOT NULL,
  `t_modified` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB;
/* 检测命令 */
insert into mysql.health_check(id, t_modified) values (@@server_id, now()) on duplicate key update t_modified=now();
</code></pre>

<p>更新语句，如果失败或者超时，就可以发起主备切换了，为什么还会有判定慢的问题呢
<p> 设想一个日志盘的IO利用率已经是100%的场景。这时候，整个系统响应非常慢，已经需要做主备切换了。
<p>    但是你要知道，IO利用率100%表示系统的IO是在工作的，每个请求都有机会获得IO资源，执行自己的任务。而我们的检测使用的update命令，需要的资源很少，所以可能在拿到IO资源的时候就可以提交成功，并且在超时时间N秒未到达之前就返回给了检测系统。
<p>    检测系统一看，update命令没有超时，于是就得到了“系统正常”的结论。

<p>所有外部检测都会有随机性 毕竟是轮询

#### 内部统计
MySQL 5.6版本以后提供的performance_schema库，就在file_summary_by_event_name表里统计了每次IO请求的时间。

file_summary_by_event_name表里有很多行数据，我们先来看看event_name='wait/io/file/innodb/innodb_log_file’这一行。

<img src="https://static001.geekbang.org/resource/image/75/dd/752ccfe43b4eab155be17401838c62dd.png">


 performance_schema.file_summary_by_event_name的一行
图中这一行表示统计的是redo log的写入时间，第一列EVENT_NAME 表示统计的类型。

接下来的三组数据，显示的是redo log操作的时间统计。

第一组五列，是所有IO类型的统计。其中，COUNT_STAR是所有IO的总次数，接下来四列是具体的统计项， 单位是皮秒；前缀SUM、MIN、AVG、MAX，顾名思义指的就是总和、最小值、平均值和最大值。

第二组六列，是读操作的统计。最后一列SUM_NUMBER_OF_BYTES_READ统计的是，总共从redo log里读了多少个字节。

第三组六列，统计的是写操作。

最后的第四组数据，是对其他类型数据的统计。在redo log里，你可以认为它们就是对fsync的统计。

在performance_schema库的file_summary_by_event_name表里，binlog对应的是event_name = "wait/io/file/sql/binlog"这一行。各个字段的统计逻辑，与redo log的各个字段完全相同。这里，我就不再赘述了。

因为我们每一次操作数据库，performance_schema都需要额外地统计这些信息，所以我们打开这个统计功能是有性能损耗的。

我的测试结果是，如果打开所有的performance_schema项，性能大概会下降10%左右。所以，我建议你只打开自己需要的项进行统计。你可以通过下面的方法打开或者关闭某个具体项的统计。

如果要打开redo log的时间监控，你可以执行这个语句：
>mysql> update setup_instruments set ENABLED='YES', Timed='YES' where name like '%wait/io/file/innodb/innodb_log_file%';

假设，现在你已经开启了redo log和binlog这两个统计信息，那要怎么把这个信息用在实例状态诊断上呢？

很简单，你可以通过MAX_TIMER的值来判断数据库是否出问题了。比如，你可以设定阈值，单次IO请求时间超过200毫秒属于异常，然后使用类似下面这条语句作为检测逻辑。
>mysql> select event_name,MAX_TIMER_WAIT  FROM performance_schema.file_summary_by_event_name where event_name in ('wait/io/file/innodb/innodb_log_file','wait/io/file/sql/binlog') and MAX_TIMER_WAIT>200*1000000000;

发现异常后，取到你需要的信息，再通过下面这条语句：

>mysql> truncate table performance_schema.file_summary_by_event_name;

把之前的统计信息清空。这样如果后面的监控中，再次出现这个异常，就可以加入监控累积值了。
    
  
 ### <a href="https://www.cnblogs.com/a-phper/p/10313974.html">30 | 答疑文章（二）：用动态的观点看加锁</a>
 
 
### 31 | 误删数据后除了跑路，还能怎么办？

#### 误删行
<p> Flashback恢复数据的原理，是修改binlog的内容，拿回原库重放。而能够使用这个方案的前提是，需要确保binlog_format=row 和 binlog_row_image=FULL。
    
<p>    具体恢复数据时，对单个事务做如下处理：
    
<li>    对于insert语句，对应的binlog event类型是Write_rows event，把它改成Delete_rows event即可；
    
<li>     同理，对于delete语句，也是将Delete_rows event改为Write_rows event；
    
<li>     而如果是Update_rows的话，binlog里面记录了数据行修改前和修改后的值，对调这两行的位置即可。
    
<p>    如果误操作不是一个，而是多个，会怎么样呢？比如下面三个事务：
<pre><code>    
    (A)delete ...
    (B)insert ...
    (C)update ...
    </code></pre>
<p>    现在要把数据库恢复回这三个事务操作之前的状态，用Flashback工具解析binlog后，写回主库的命令是：
<pre><code>    
    (reverse C)update ...
    (reverse B)delete ...
    (reverse A)insert ...  
    </code></pre>
    
 <p> 恢复数据比较安全的做法，是恢复出一个备份，或者找一个从库作为临时库，在这个临时库上执行这些操作，然后再将确认过的临时库的数据，恢复回主库。
 
 <p>不止要说误删数据的事后处理办法，更重要是要做到事前预防。我有以下两个建议：
    
<li>    把sql_safe_updates参数设置为on。这样一来，如果我们忘记在delete或者update语句中写where条件，或者where条件里面没有包含索引字段的话，这条语句的执行就会报错。
    
<li>    代码上线前，必须经过SQL审计。
    
   
#### 误删库/表
<p>恢复数据，就需要使用全量备份，加增量日志的方式了。这个方案要求线上有定期的全量备份，并且实时备份binlog。
   
<p>   在这两个条件都具备的情况下，假如有人中午12点误删了一个库，恢复数据的流程如下：
   
<li>   取最近一次全量备份，假设这个库是一天一备，上次备份是当天0点；
   
<li>   用备份恢复出一个临时库；
   
<li>   从日志备份里面，取出凌晨0点之后的日志；
   
<li>   把这些日志，除了误删除数据的语句外，全部应用到临时库 


####  延迟复制备库
<p>延迟复制的备库是一种特殊的备库，通过 CHANGE MASTER TO MASTER_DELAY = N命令，可以指定这个备库持续保持跟主库有N秒的延迟。

<p>比如你把N设置为3600，这就代表了如果主库上有数据被误删了，并且在1小时内发现了这个误操作命令，这个命令就还没有在这个延迟复制的备库执行。这时候到这个备库上执行stop slave，再通过之前介绍的方法，跳过误操作命令，就可以恢复出需要的数据。

<p>这样的话，你就随时可以得到一个，只需要最多再追1小时，就可以恢复出数据的临时实例，也就缩短了整个数据恢复需要的时间。

#### 预防误删库/表的方法

<p>账号分离。这样做的目的是，避免写错命令。比如：

<li>我们只给业务开发同学DML权限，而不给truncate/drop权限。而如果业务开发人员有DDL需求的话，也可以通过开发管理系统得到支持。
<li>即使是DBA团队成员，日常也都规定只使用只读账号，必要的时候才使用有更新权限的账号。
<p>第二条建议是，制定操作规范。这样做的目的，是避免写错要删除的表名。比如：

<li>在删除数据表之前，必须先对表做改名操作。然后，观察一段时间，确保对业务无影响以后再删除这张表。
<li>改表名的时候，要求给表名加固定的后缀（比如加_to_be_deleted)，然后删除表的动作必须通过管理系统执行。并且，管理系删除表的时候，只能删除固定后缀的表。


#### rm删除数据
<p>对于一个有高可用机制的MySQL集群来说，最不怕的就是rm删除数据了。只要不是恶意地把整个集群删除，而只是删掉了其中某一个节点的数据的话，HA系统就会开始工作，选出一个新的主库，从而保证整个集群的正常工作。

<p>这时，你要做的就是在这个节点上把数据恢复回来，再接入整个集群。

<p>当然了，现在不止是DBA有自动化系统，SA（系统管理员）也有自动化系统，所以也许一个批量下线机器的操作，会让你整个MySQL集群的所有节点都全军覆没。


### 32 | 为什么还有kill不掉的语句？
<p> 两个kill命令：一个是kill query +线程id，表示终止这个线程中正在执行的语句；一个是kill connection +线程id，这里connection可缺省，表示断开这个线程的连接，当然如果这个线程有语句正在执行，也是要先停止正在执行的语句的
<p> kill 命令是给信号  而不是强制关闭
<li>线程没有执行到判断线程状态的逻辑  ,有阻塞 慢 会影响
<li>终止逻辑耗时较长   ,有回滚或者其他大事物 会影响
 
 ### 33 | 我查这么多数据，会不会把数据库内存打爆？
 <p> 主要是 查询大量数据处理和优化
 <p> 1 server层  边读边写  取数据和发数据的流程是这样的：
 <li>获取一行，写到net_buffer中。这块内存的大小是由参数net_buffer_length定义的，默认是16k。
 <li> 重复获取行，直到net_buffer写满，调用网络接口发出去。
  <li>如果发送成功，就清空net_buffer，然后继续取下一行，并写入net_buffer。
 <li> 如果发送函数返回EAGAIN或WSAEWOULDBLOCK，就表示本地网络栈（socket send buffer）写满了，进入等待。直到网络栈重新可写，再继续发送
 
 <p> show processlist 中"Sending to client”，就表示服务器端的网络栈写满
 
 <p>“Sending data” 不一定是指“正在发送数据”，而可能是处于执行器过程中的任意阶段。比如，你可以构造一个锁等待的场景，就能看到Sending data状态。
 
 <p> 2 全表扫描对InnoDB的影响
 <p>innodb_buffer_pool_size小于磁盘的数据量是很常见的。如果一个 Buffer Pool满了，而又要从磁盘读入一个数据页，那肯定是要淘汰一个旧数据页的。
    
<p>InnoDB内存管理用的是最近最少使用 (Least Recently Used, LRU)算法，这个算法的核心就是淘汰最久未使用的数据。 但是是优化的LRU
<p>在InnoDB实现上，按照5:3的比例把整个LRU链表分成了young区域和old区域。图中LRU_old指向的就是old区域的第一个位置，是整个链表的5/8处。也就是说，靠近链表头部的5/8是young区域，靠近链表尾部的3/8是old区域。

<p>改进后的LRU算法执行流程变成了下面这样。

<li>图中状态1，要访问数据页P3，由于P3在young区域，因此和优化前的LRU算法一样，将其移到链表头部，变成状态2。

<li>之后要访问一个新的不存在于当前链表的数据页，这时候依然是淘汰掉数据页Pm，但是新插入的数据页Px，是放在LRU_old处。

<li>处于old区域的数据页，每次被访问的时候都要做下面这个判断：
<ul>    若这个数据页在LRU链表中存在的时间超过了1秒，就把它移动到链表头部；
<li>    如果这个数据页在LRU链表中存在的时间短于1秒，位置保持不变。1秒这个时间，是由参数innodb_old_blocks_time控制的。其默认值是1000，单位毫秒。

<p>这个策略，就是为了处理类似全表扫描的操作量身定制的。还是以刚刚的扫描200G的历史数据表为例，我们看看改进后的LRU算法的操作逻辑：

<li>扫描过程中，需要新插入的数据页，都被放到old区域;

<li>一个数据页里面有多条记录，这个数据页会被多次访问到，但由于是顺序扫描，这个数据页第一次被访问和最后一次被访问的时间间隔不会超过1秒，因此还是会被保留在old区域；

<li>再继续扫描后续的数据，之前的这个数据页之后也不会再被访问到，于是始终没有机会移到链表头部（也就是young区域），很快就会被淘汰出去。

<p> 改进了全表扫描时 LRU对刚进来的数据页的处理 默认放在old 1秒内操作 位置不变


### 34 | 到底可不可以使用join？

#### Index Nested-Loop Join
<p> 在有用到被驱动表的索引的情况下
<p> 被驱动表t2的字段a上有索引，join过程用上了这个索引，因此这个语句的执行流程是这样的：
<li>    从表t1中读入一行数据 R；
<li>    从数据行R中，取出a字段到表t2里去查找；
<li>    取出表t2中满足条件的行，跟R组成一行，作为结果集的一部分；
<li>    重复执行步骤1到3，直到表t1的末尾循环结束

<p> 先遍历表t1，然后根据从表t1中取出的每行数据中的a值，去表t2中查找满足条件的记录。在形式上，这个过程就跟我们写程序时的嵌套查询类似，并且可以用上被驱动表的索引，所以我们称之为“Index Nested-Loop Join”，简称NLJ

<p> 两个结论：
    
<li>   使用join语句，性能比强行拆成多个单表执行SQL语句的性能要好；
<li>     如果使用join语句的话，需要让小表做驱动表。

#### Simple Nested-Loop Join
<p> 不能用到被驱动表的情况 , 去被驱动表全表扫描  扫描行数=驱动表结果数*被驱动全表数
<p> MySQL也没有使用这个Simple Nested-Loop Join算法，而是使用了另一个叫作“Block Nested-Loop Join”的算法，简称BNL

#### Block Nested-Loop Join
<p>流程是这样的：

<li>把表t1的数据读入线程内存join_buffer中，由于我们这个语句中写的是select *，因此是把整个表t1放入了内存；

<li>扫描表t2，把表t2中的每一行取出来，跟join_buffer中的数据做对比，满足join条件的，作为结果集的一部分返回。

<p> 但论时间复杂度是一样的 ,但他是在内存里执行比较的
<p> 在内存比较太多会分段 join_buffer_size分段大小。join_buffer_size越大，一次可以放入的行越多，分成的段数也就越少，对被驱动表的全表扫描次数就越少。


<p>在决定哪个表做驱动表的时候，应该是两个表按照各自的条件过滤，过滤完成之后，计算参与join的各个字段的总数据量，数据量小的那个表，就是“小表”，应该作为驱动表。

####小结
<p>这两种算法是由能否使用被驱动表的索引决定的。而能否用上被驱动表的索引，对join语句的性能影响很大。

<p>通过对Index Nested-Loop Join和Block Nested-Loop Join两个算法执行过程的分析，我们也得到了文章开头两个问题的答案：
<p>如果可以使用被驱动表的索引，join语句还是有其优势的；

<p>不能使用被驱动表的索引，只能使用Block Nested-Loop Join算法，这样的语句就尽量不要使用；

<p>在使用join的时候，应该让小表做驱动表。


### 35 | join语句怎么优化？

#### Multi-Range Read优化
<p>大多数的数据都是按照主键递增顺序插入得到的，所以我们可以认为，如果按照主键的递增顺序查询的话，对磁盘的读比较接近顺序读，能够提升读性能

<p>MRR优化的设计思路。此时，语句的执行流程变成了这样：
   
<li>   根据索引a，定位到满足条件的记录，将id值放入read_rnd_buffer中;
   
<li>   将read_rnd_buffer中的id进行递增排序；
   
<li>   排序后的id数组，依次到主键id索引中查记录，并作为结果返回。
   
<p>   这里，read_rnd_buffer的大小是由read_rnd_buffer_size参数控制的。如果步骤1中，read_rnd_buffer放满了，就会先执行完步骤2和3，然后清空read_rnd_buffer。之后继续找索引a的下个记录，并继续循环。
   
<p>   另外需要说明的是，如果你想要稳定地使用MRR优化的话，需要设置set optimizer_switch="mrr_cost_based=off"。（官方文档的说法，是现在的优化器策略，判断消耗的时候，会更倾向于不使用MRR，把mrr_cost_based设置为off，就是固定使用MRR了。）
 
 <p> MRR能够提升性能的核心在于，这条查询语句在索引a上做的是一个范围查询（也就是说，这是一个多值查询），可以得到足够多的主键id。这样通过排序以后，再去主键索引查数据，才能体现出“顺序性”的优势
 
 #### Batched Key Access
 <p>  在Index Nested-Loop Join (NLJ )的基础上改进的  在驱动表不用单个id去查 而是批量
 <p>在join_buffer中放入的数据是P1~P100，表示的是只会取查询需要的字段。当然，如果join buffer放不下P1~P100的所有数据，就会把这100行数据分成多段执行上图的流程。
 
 <p>那么，这个BKA算法到底要怎么启用呢？
 
 <p>如果要使用BKA优化算法的话，你需要在执行SQL语句之前，先设置
 >set optimizer_switch='mrr=on,mrr_cost_based=off,batched_key_access=on';
 
 <p>其中，前两个参数的作用是要启用MRR。这么做的原因是，BKA算法的优化要依赖于MRR
 
 ### BNL算法的性能问题 
 大表join操作虽然对IO有影响，但是在语句执行结束后，对IO的影响也就结束了。但是，对Buffer Pool的影响就是持续性的，需要依靠后续的查询请求慢慢恢复内存命中率。
 
 为了减少这种影响，你可以考虑增大join_buffer_size的值，减少对被驱动表的扫描次数。
 
 也就是说，BNL算法对系统的影响主要包括三个方面：
 
 可能会多次扫描被驱动表，占用磁盘IO资源；
 
 判断join条件需要执行M*N次对比（M、N分别是两张表的行数），如果是大表就会占用非常多的CPU资源；
 
 可能会导致Buffer Pool的热数据被淘汰，影响内存命中率。
 
####  BNL转BKA
流程是这样的：

<li>把表t1的所有字段取出来，存入join_buffer中。这个表只有1000行，join_buffer_size默认值是256k，可以完全存入。

<li>扫描表t2，取出每一行数据跟join_buffer中的数据进行对比，

<ul>如果不满足t1.b=t2.b，则跳过；
<li>如果满足t1.b=t2.b, 再判断其他条件，也就是是否满足t2.b处于[1,2000]的条件，如果是，就作为结果集的一部分返回，否则跳过。

<p> 其他方法
<li>临时表的大致思路是：

<li>把表t2中满足条件的数据放在临时表tmp_t中；

<li>为了让join使用BKA算法，给临时表tmp_t的字段b加上索引；

<li>让表t1和tmp_t做join操作。
<p>对应的SQL语句的写法如下：
 <pre><code>
create temporary table temp_t(id int primary key, a int, b int, index(b))engine=innodb;
insert into temp_t select * from t2 where b>=1 and b<=2000;
select * from t1 join temp_t on (t1.b=temp_t.b);   </code></pre>


#### 小结
<p>Index Nested-Loop Join（NLJ）和Block Nested-Loop Join（BNL）的优化方法。

<p>在这些优化方法中：
<li>BKA优化是MySQL已经内置支持的，建议你默认使用；
<li>BNL算法效率低，建议你都尽量转成BKA算法。优化的方向就是给被驱动表的关联字段加上索引；
<li>基于临时表的改进方案，对于能够提前过滤出小数据的join语句来说，效果还是很好的；
<li>MySQL目前的版本还不支持hash join，但你可以配合应用端自己模拟出来，理论上效果要好于临时表的方案。

### 36 | 为什么临时表可以重名？

<p>临时表和内存表。这两个概念是完全不同的。

<p>内存表，指的是使用Memory引擎的表，建表语法是create table … engine=memory。这种表的数据都保存在内存里，系统重启的时候会被清空，但是表结构还在。除了这两个特性看上去比较“奇怪”外，从其他的特征上看，它就是一个正常的表。

<p>而临时表，可以使用各种引擎类型 。如果是使用InnoDB引擎或者MyISAM引擎的临时表，写数据的时候是写到磁盘上的。当然，临时表也可以使用Memory引擎。

#### 临时表的应用
<p>各个分库拿到的数据，汇总到一个MySQL实例的一个表中，然后在这个汇总实例上做逻辑操作。


#### 为什么临时表可以重名？
>create temporary table temp_t(id int primary key)engine=innodb;

<p>这个语句的时候，MySQL要给这个InnoDB表创建一个frm文件保存表结构定义，还要有地方保存表数据。

<p>这个frm文件放在临时文件目录下，文件名的后缀是.frm，前缀是“#sql{进程id}_{线程id}_序列号”。你可以使用select @@tmpdir命令，来显示实例的临时文件目录。

<p>而关于表中数据的存放方式，在不同的MySQL版本中有着不同的处理方式：

<li>在5.6以及之前的版本里，MySQL会在临时文件目录下创建一个相同前缀、以.ibd为后缀的文件，用来存放数据文件；
<li>而从 5.7版本开始，MySQL引入了一个临时文件表空间，专门用来存放临时文件的数据。因此，我们就不需要再创建ibd文件了。
 
#### 临时表和主备复制
<p> 1 表的删除
<p>MySQL在记录binlog的时候，不论是create table还是alter table语句，都是原样记录，甚至于连空格都不变。但是如果执行drop table t_normal，系统记录binlog就会写成：

>DROP TABLE `t_normal` /* generated by server */

<p>drop table命令是可以一次删除多个表的。比如，在上面的例子中，设置binlog_format=row，如果主库上执行 "drop table t_normal, temp_t"这个命令，那么binlog中就只能记录：

>DROP TABLE `t_normal` /* generated by server */

<p>因为备库上并没有表temp_t，将这个命令重写后再传到备库执行，才不会导致备库同步线程停止。

<p>所以，drop table命令记录binlog的时候，就必须对语句做改写。“/* generated by server */”说明了这是一个被服务端改写过的命令。

<p> 2 备库怎么处理不同线程的临时表的
<p>MySQL在记录binlog的时候，会把主库执行这个语句的线程id写到binlog中。这样，在备库的应用线程就能够知道执行每个语句的主库线程id，并利用这个线程id来构造临时表的table_def_key：

<li>session A的临时表t1，在备库的table_def_key就是：库名+t1+“M的serverid”+“session A的thread_id”;

<li>session B的临时表t1，在备库的table_def_key就是 ：库名+t1+“M的serverid”+“session B的thread_id”。

<p>由于table_def_key不同，所以这两个表在备库的应用线程里面是不会冲突的。

<p>小结
<p>临时表一般用于处理比较复杂的计算逻辑。由于临时表是每个线程自己可见的，所以不需要考虑多个线程执行同一个处理逻辑时，临时表的重名问题。在线程退出的时候，临时表也能自动删除，省去了收尾和异常处理的工作。
<p> 在binlog_format='row’的时候，临时表的操作不记录到binlog中，也省去了不少麻烦，这也可以成为你选择binlog_format时的一个考虑因素。

### 37 | 什么时候会使用内部临时表？
<p> sort buffer、内存临时表和join buffer。这三个数据结构都是用来存放语句执行过程中的中间数据，以辅助SQL语句的执行的。其中，我们在排序的时候用到了sort buffer，在使用join语句的时候用到了join buffer

<p>1  union
 <p> 执行下面语句
 <pre><code>
 (select 1000 as f) union (select id from t1 order by id desc limit 2);
 </code></pre>
 <p>执行流程是这样的：
    
<li>    创建一个内存临时表，这个临时表只有一个整型字段f，并且f是主键字段。
    
<li>    执行第一个子查询，得到1000这个值，并存入临时表中。
    
<li>    执行第二个子查询：
    
<ul>    拿到第一行id=1000，试图插入临时表中。但由于1000这个值已经存在于临时表了，违反了唯一性约束，所以插入失败，然后继续执行；
<li>    取到第二行id=999，插入临时表成功。
<li>    从临时表中按行取出数据，返回结果，并删除临时表，结果中包含两行数据分别是1000和999。


<p> group by 执行流程
<p>  另外一个常见的使用临时表的例子是group by，我们来看一下这个语句：
 <pre><code>   
    select id%10 as m, count(*) as c from t1 group by m;</code></pre>
    
<img src="https://static001.geekbang.org/resource/image/3d/98/3d1cb94589b6b3c4bb57b0bdfa385d98.png">
<p>在Extra字段里面，我们可以看到三个信息：
<li>Using index，表示这个语句使用了覆盖索引，选择了索引a，不需要回表；
<li>Using temporary，表示使用了临时表；
<li>Using filesort，表示需要排序。

<p>这个语句的执行流程是这样的：

<li>创建内存临时表，表里有两个字段m和c，主键是m；

<li>扫描表t1的索引a，依次取出叶子节点上的id值，计算id%10的结果，记为x；
<li>如果临时表中没有主键为x的行，就插入一个记录(x,1);
<li>如果表中有主键为x的行，就将x这一行的c值加1；
<li>遍历完成后，再根据字段m做排序，得到结果集返回给客户端。
<img src="https://static001.geekbang.org/resource/image/b5/68/b5168d201f5a89de3b424ede2ebf3d68.jpg">
<p> 这排序直接是放在临时表的

<p>如果你的需求并不需要对结果进行排序，那你可以在SQL语句末尾增加order by null，也就是改成：
 <pre><code>
select id%10 as m, count(*) as c from t1 group by m order by null;  </code></pre>

<p> 内存临时表是有限制的 tmp_table_size 默认是16M
<pre><code>set tmp_table_size=1024;</code></pre>
<p>手动设置成2014字节
<p>这时候就会把内存临时表转成磁盘临时表，磁盘临时表默认使用的引擎是InnoDB。

<p>3 group by 优化方法 --索引
<p>在MySQL 5.7版本支持了generated column机制，用来实现列数据的关联更新。你可以用下面的方法创建一个列z，然后在z列上创建一个索引（如果是MySQL 5.6及之前的版本，你也可以创建普通列和索引，来解决这个问题）。
<pre><code>
alter table t1 add column z int generated always as(id % 100), add index(z);</code></pre>
<p>这样，索引z上的数据就是类似图10这样有序的了。上面的group by语句就可以改成：
 <pre><code>
select z, count(*) as c from t1 group by z;</code></pre>

<p>4 group by优化方法 --直接排序

<p>在group by语句中加入SQL_BIG_RESULT这个提示（hint），就可以告诉优化器：这个语句涉及的数据量很大，请直接用磁盘临时表。

<p>MySQL的优化器一看，磁盘临时表是B+树存储，存储效率不如数组来得高。所以，既然你告诉我数据量很大，那从磁盘空间考虑，还是直接用数组来存吧。

<p>因此，下面这个语句
<pre><code>
select SQL_BIG_RESULT id%100 as m, count(*) as c from t1 group by m;</code></pre>

<p>执行流程就是这样的：
<li>初始化sort_buffer，确定放入一个整型字段，记为m；
<li>扫描表t1的索引a，依次取出里面的id值, 将 id%100的值存入sort_buffer中；
<li>扫描完成后，对sort_buffer的字段m做排序（如果sort_buffer内存不够用，就会利用磁盘临时文件辅助排序）；
<li>排序完成后，就得到了一个有序数组。

<img src="https://static001.geekbang.org/resource/image/83/ec/83b6cd6b3e37dfbf9699cf0ccc0f1bec.png">

#### 小结
<p>MySQL什么时候会使用内部临时表？

<li>如果语句执行过程可以一边读数据，一边直接得到结果，是不需要额外内存的，否则就需要额外的内存，来保存中间结果；

<li>join_buffer是无序数组，sort_buffer是有序数组，临时表是二维表结构；

<li>如果执行逻辑需要用到二维表特性，就会优先考虑使用临时表。比如我们的例子中，union需要用到唯一索引约束， group by还需要用到另外一个字段来存累积计数。


<p>group by的几种实现算法，从中可以总结一些使用的指导原则：

<li>如果对group by语句的结果没有排序要求，要在语句后面加 order by null；

<li>尽量让group by过程用上表的索引，确认方法是explain结果里没有Using temporary 和 Using filesort；

<li>如果group by需要统计的数据量不大，尽量只使用内存临时表；也可以通过适当调大tmp_table_size参数，来避免用到磁盘临时表；

<li>如果数据量实在太大，使用SQL_BIG_RESULT这个提示，来告诉优化器直接使用排序算法得到group by的结果。
 
 
 ###    38 | 都说InnoDB好，那还要不要使用Memory引擎？
 <p> 主体 memory 的特性
 <p>  内存表的数据部分以数组的方式单独存放，而主键id索引里，存的是每个数据的位置。主键id是hash索引，可以看到索引上的key并不是有序的
 <p>  InnoDB和Memory引擎的数据组织方式是不同的：
      
 <li>     InnoDB引擎把数据放在主键索引上，其他索引上保存的是主键id。这种方式，我们称之为索引组织表（Index Organizied Table）。
  <li>      而Memory引擎采用的是把数据单独存放，索引上保存数据位置的数据组织形式，我们称之为堆组织表（Heap Organizied Table）。
 <p>       从中我们可以看出，这两个引擎的一些典型不同：
      
<li>      InnoDB表的数据总是有序存放的，而内存表的数据就是按照写入顺序存放的；
      
<li>      当数据文件有空洞的时候，InnoDB表在插入新数据的时候，为了保证数据有序性，只能在固定的位置写入新值，而内存表找到空位就可以插入新值；
      
<li>      数据位置发生变化的时候，InnoDB表只需要修改主键索引，而内存表需要修改所有索引；
      
<li>      InnoDB表用主键索引查询时需要走一次索引查找，用普通索引查询的时候，需要走两次索引查找。而内存表没有这个区别，所有索引的“地位”都是相同的。
      
<li>      InnoDB支持变长数据类型，不同记录的长度可能不同；内存表不支持Blob 和 Text字段，并且即使定义了varchar(N)，实际也当作char(N)，也就是固定长度字符串来存储，因此内存表的每行数据长度相同。


#### hash索引和B-Tree索引
<p>内存表也是支B-Tree索引的。在id列上创建一个B-Tree索引，SQL语句可以这么写：
 <pre>
alter table t1 add index a_btree_index using btree (id); </pre>

<img src="https://static001.geekbang.org/resource/image/17/e3/1788deca56cb83c114d8353c92e3bde3.jpg">
<p> 执行select * from t1 where id<5的时候，优化器会选择B-Tree索引，所以返回结果是0到4。 使用force index强行使用主键id这个索引，id=0这一行就在结果集的最末尾了

#### Memory 的问题
<p>1 内存表的锁
<p> 只有表锁 表锁对并发访问的支持不够好。所以，内存表的锁粒度问题，决定了它在处理并发事务的时候，性能也不会太好

<p>2 数据持久性问题
<p> 内存表的数据 crash 会丢掉数据

<p>在数据量可控，不会耗费过多内存的情况下，你可以考虑使用内存表。
<li>   内存临时表刚好可以无视内存表的两个不足，主要是下面的三个原因：
<li>   临时表不会被其他线程访问，没有并发性的问题；
<li>   临时表重启后也是需要删除的，清空数据这个问题不存在；
<li>   备库的临时表也不会影响主库的用户线程。

### 39 | 自增主键为什么不是连续的？

#### 自增值保存
<p>表的结构定义存放在后缀名为.frm的文件中，但是并不会保存自增值。

<p>不同的引擎对于自增值的保存策略不同。

<li>MyISAM引擎的自增值保存在数据文件中。
<li>InnoDB引擎的自增值，其实是保存在了内存里，并且到了MySQL 8.0版本后，才有了“自增值持久化”的能力，也就是才实现了“如果发生重启，表的自增值可以恢复为MySQL重启前的值”，具体情况是：
<li>在MySQL 5.7及之前的版本，自增值保存在内存里，并没有持久化。每次重启后，第一次打开表的时候，都会去找自增值的最大值max(id)，然后将max(id)+1作为这个表当前的自增值。﻿
<ul>举例来说，如果一个表当前数据行里最大的id是10，AUTO_INCREMENT=11。这时候，我们删除id=10的行，AUTO_INCREMENT还是11。但如果马上重启实例，重启后这个表的AUTO_INCREMENT就会变成10。﻿
<li>也就是说，MySQL重启可能会修改一个表的AUTO_INCREMENT的值。
<li>在MySQL 8.0版本，将自增值的变更记录在了redo log中，重启的时候依靠redo log恢复重启之前的值。

#### 自增值修改机制
<p>如果字段id被定义为AUTO_INCREMENT，在插入一行数据的时候，自增值的行为如下：

<p>如果插入数据时id字段指定为0、null 或未指定值，那么就把这个表当前的 AUTO_INCREMENT值填到自增字段；

<p>如果插入数据时id字段指定了具体的值，就直接使用语句里指定的值。

<p>根据要插入的值和当前自增值的大小关系，自增值的变更结果也会有所不同。假设，某次要插入的值是X，当前的自增值是Y。

<li>如果X<Y，那么这个表的自增值不变；

<li>如果X≥Y，就需要把当前自增值修改为新的自增值。

<p>新的自增值生成算法是：从auto_increment_offset开始，以auto_increment_increment为步长，持续叠加，直到找到第一个大于X的值，作为新的自增值。

<p>其中，auto_increment_offset 和 auto_increment_increment是两个系统参数，分别用来表示自增的初始值和步长，默认值都是1。

<p>ps：在一些场景下，使用的就不全是默认值。比如，双M的主备结构里要求双写的时候，我们就可能会设置成auto_increment_increment=2，让一个库的自增id都是奇数，另一个库的自增id都是偶数，避免两个库生成的主键发生冲突

####  不连续的情况
<p>唯一键冲突是导致自增主键id不连续的第一种原因。
<p> 同样地，事务回滚也会产生类似的现象，这就是第二种原因
<p> MySQL 5.1.22版本引入了一个新策略，新增参数innodb_autoinc_lock_mode，默认值是1。
    
<p> 这个参数的值被设置为0时，表示采用之前MySQL 5.0版本的策略，即语句执行结束后才释放锁；
 <p>   这个参数的值被设置为1时：
<p>    普通insert语句，自增锁在申请之后就马上释放；
<p>    类似insert … select这样的批量插入数据的语句，自增锁还是要等语句结束后才被释放；
<p>    这个参数的值被设置为2时，所有的申请自增主键的动作都是申请后就释放锁

<p>在 binlog_format=statement  中  如果多个事物操作自增值 ,很有可能不连续,从库拿到日志执行就会出错( 事物B 不连续是因为A占用了一个 如果B的日志先写 B的自增值就和主库的不一样 执行不出来)
<p>解决这个问题，有两种思路：

<li>一种思路是，让原库的批量插入数据语句，固定生成连续的id值。所以，自增锁直到语句执行结束才释放，就是为了达到这个目的。

<li>另一种思路是，在binlog里面把插入数据的操作都如实记录进来，到备库执行的时候，不再依赖于自增主键去生成。这种情况，其实就是innodb_autoinc_lock_mode设置为2，同时binlog_format设置为row。

<p>尤其是有insert … select这种批量插入数据的场景时，从并发插入数据性能的角度考虑，我建议你这样设置：innodb_autoinc_lock_mode=2 ，并且 binlog_format=row.这样做，既能提升并发性，又不会出现数据一致性问题。
   
<p>   需要注意的是，我这里说的批量插入数据，包含的语句类型是insert … select、replace … select和load data语句。


### 40 | insert语句的锁为什么这么多？
<p>几种特殊情况下的insert语句。

<li>insert … select 是很常见的在两个表之间拷贝数据的方法。你需要注意，在可重复读隔离级别下，这个语句会给select的表里扫描到的记录和间隙加读锁。
<li>而如果insert和select的对象是同一个表，则有可能会造成循环写入。这种情况下，我们需要引入用户临时表来做优化。
<li>insert 语句如果出现唯一键冲突，会在冲突的唯一值上加共享的next-key lock(S锁)。因此，碰到由于唯一键约束导致报错后，要尽快提交或回滚事务，避免加锁时间过长。

<p>insert into … on duplicate key update
<p>   上面这个例子是主键冲突后直接报错，如果是改写成
 <pre>  
   insert into t values(11,10,10) on duplicate key update d=100;  </pre>
<p>   的话，就会给索引c上(5,10] 加一个排他的next-key lock（写锁）。
<p>   insert into … on duplicate key update 这个语义的逻辑是，插入一行数据，如果碰到唯一键约束，就执行后面的更新语句。
<p>   注意，如果有多个列违反了唯一性约束，就会按照索引的顺序，修改跟第一个索引冲突的行。


###  41 | 怎么最快地复制一张表？

<p>三种将一个表的数据导入到另外一个表中的方法。

<p>我们来对比一下这三种方法的优缺点。

<li>用mysqldump生成包含INSERT语句文件的方法，可以在where参数增加过滤条件，来实现只导出部分数据。这个方式的不足之一是，不能使用join这种比较复杂的where条件写法。

<li>用select … into outfile的方法是最灵活的，支持所有的SQL写法。但，这个方法的缺点之一就是，每次只能导出一张表的数据，而且表结构也需要另外的语句单独备份。

<li>物理拷贝的方式速度最快，尤其对于大表拷贝来说是最快的方法。如果出现误删表的情况，用备份恢复出误删之前的临时库，然后再把临时库中的表拷贝到生产库上，是恢复数据最快的方法。但是，这种方法的使用也有一定的局限性：

<ul>必须是全表拷贝，不能只拷贝部分数据；
<li>需要到服务器上拷贝数据，在用户无法登录数据库主机的场景下无法使用；
<li>由于是通过拷贝物理文件实现的，源表和目标表都是使用InnoDB引擎时才能使用。
 </li>

<p>后两种方式都是逻辑备份方式，是可以跨引擎使用的。

### 42 | grant之后要跟着flush privileges吗？
<p> grant语句是用来给用户赋权的  flush privileges 是刷新内存的
<p>创建一个用户：
<pre>   
   create user 'ua'@'%' identified by 'pa'; </pre>
<p>这条命令做了两个动作：
   
<li>   磁盘上，往mysql.user表里插入一行，由于没有指定权限，所以这行数据上所有表示权限的字段的值都是N；
   
<li>  内存里，往数组acl_users里插入一个acl_user对象，这个对象的access字段值为0。

<p>全局权限
<pre>grant all privileges on *.* to 'ua'@'%' with grant option;</pre>
<p>这个grant命令做了两个动作：

<li>磁盘上，将mysql.user表里，用户’ua’@’%'这一行的所有表示权限的字段的值都修改为‘Y’；

<li>内存里，从数组acl_users中找到这个用户对应的对象，将access值（权限位）修改为二进制的“全1”。

<p>db权限
<pre> grant all privileges on db1.* to 'ua'@'%' with grant option;   </pre>
<p>如下两个动作：

<li>磁盘上，往mysql.db表中插入了一行记录，所有权限位字段设置为“Y”；

<li>内存里，增加一个对象到数组acl_dbs中，这个对象的权限位为“全1”

<p> 表权限和列权限
<pre>create table db1.t1(id int, a int);
grant all privileges on db1.t1 to 'ua'@'%' with grant option;
GRANT SELECT(id), INSERT (id,a) ON mydb.mytbl TO 'ua'@'%' with grant option;</pre>

<p> 正常情况下，grant命令之后，没有必要跟着执行flush privileges命令。
<p>flush privileges语句本身会用数据表的数据重建一份内存权限数据，所以在权限数据可能存在不一致的情况下再使用。而这种不一致往往是由于直接用DML语句操作系统权限表导致的，所以我们尽量不要使用这类语句

<p>使用grant语句赋权时，你可能还会看到这样的写法：

<pre>grant super on *.* to 'ua'@'%' identified by 'pa';</pre>
<p>这条命令加了identified by ‘密码’， 语句的逻辑里面除了赋权外，还包含了：
<p>如果用户’ua’@’%'不存在，就创建这个用户，密码是pa；
<p>如果用户ua已经存在，就将密码修改成pa。
<p>这也是一种不建议的写法，因为这种写法很容易就会不慎把密码给改了。

### 43 | 要不要使用分区表？
<p>这个表包含了一个.frm文件和4个.ibd文件，每个分区对应一个.ibd文件。也就是说：
   
<li>   对于引擎层来说，这是4个表；
<li>   对于Server层来说，这是1个表。
<p> 意思就是 引擎层的范围锁 并不会跨分区表去锁住其他表的数据 而MDL会锁住全部
<p>小结：
   
<li>   MySQL在第一次打开分区表的时候，需要访问所有的分区；
   
<li>   在server层，认为这是同一张表，因此所有分区共用同一个MDL锁；
   
<li>   在引擎层，认为这是不同的表，因此MDL锁之后的执行过程，会根据分区表规则，只访问必要的分区。

<p> 实际使用时，分区表跟用户分表比起来，有两个绕不开的问题：一个是第一次访问的时候需要访问所有分区，另一个是共用MDL锁。

<h3><a href="https://www.cnblogs.com/gaosf/p/11189119.html">44 | 答疑文章（三）：说一说这些好问题</a>

###  45 | 自增id用完怎么办？
<p> 表定义自增值id
<p> 无符号整型(unsigned int)是4个字节，上限就是232-1，应该创建成8个字节的bigint unsigned。

<p>InnoDB系统自增row_id
<p>如果你创建的InnoDB表没有指定主键，那么InnoDB会给你创建一个不可见的，长度为6个字节的row_id
<p>248-1这个值本身已经很大了，但是如果一个MySQL实例跑得足够久的话，还是可能达到这个上限的。在InnoDB逻辑里，申请到row_id=N后，就将这行数据写入表中；如果表中已经存在row_id=N的行，新写入的行就会覆盖原有的行

<p> Xid
<p>MySQL内部维护了一个全局变量global_query_id，每次执行语句的时候将它赋值给Query_id，然后给这个变量加1。如果当前语句是这个事务执行的第一条语句，那么MySQL还会同时把Query_id赋值给这个事务的Xid。

<p>而global_query_id是一个纯内存变量，重启之后就清零了。所以你就知道了，在同一个数据库实例中，不同事务的Xid也是有可能相同的。

<p>但是MySQL重启之后会重新生成新的binlog文件，这就保证了，同一个binlog文件里，Xid一定是惟一的。

<p> Innodb trx_id
<p>Xid和InnoDB的trx_id是两个容易混淆的概念。
   
<p> Xid是由server层维护的。InnoDB内部使用Xid，就是为了能够在InnoDB事务和server之间做关联。但是，InnoDB自己的trx_id，是另外维护的。


<p> thread_id
<p>线程id（thread_id）。其实，线程id才是MySQL中最常见的一种自增id。平时我们在查各种现场的时候，show processlist里面的第一列，就是thread_id。

<p>thread_id的逻辑很好理解：系统保存了一个全局变量thread_id_counter，每新建一个连接，就将thread_id_counter赋值给这个新连接的线程变量。

<p>  thread_id_counter定义的大小是4个字节，因此达到232-1后，它就会重置为0，然后继续增加。但是，你不会在show processlist里看到两个相同的thread_id
   
   
    