###   Mysql  学习记录
#### Server层和存储引擎层

<img src="https://s2.ax1x.com/2019/12/05/QGhBNV.png" alt="QGhBNV.png" border="0" />
<p>Server层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖MySQL的大多数核心服务功能，以及所有的内置函数（如日期、时间、
<p>数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。
<p>而存储引擎层负责数据的存储和提取。其架构模式是插件式的，支持InnoDB、MyISAM、Memory等多个存储引擎。现在最常用的存储引擎是
<p>InnoDB，它从MySQL 5.5.5版本开始成为了默认存储引擎。
<p>也就是说，你执行create table建表的时候，如果不指定引擎类型，默认使用的就是InnoDB。不过，你也可以通过指定存储引擎的类型来
<p>选择别的引擎，比如在create table语句中使用engine=memory, 来指定使用内存引擎创建表。不同存储引擎的表数据存取方式不同，
<p>支持的功能也不同，在后面的文章中，我们会讨论到引擎的选择。
<p>不同的存储引擎共用一个Server层，也就是从连接器到执行器的部分
<p> 1 连接器 第一步，你会先连接到这个数据库上，这时候接待你的就是连接器。连接器负责跟客户端建立连接、获取权限、维持和管理连接
<p> ps:客户端如果太长时间没动静，连接器就会自动将它断开。这个时间是由参数wait_timeout控制的，默认值是8小时
<p>解决这个问题呢？你可以考虑以下两种方案。
<p> 1 定期断开长连接。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连。
<p> 2 如果你用的是MySQL 5.7或更新版本，可以在每次执行一个比较大的操作后，通过执行 mysql_reset_connection来重新初始化连接资源。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。

<p> 2 查询缓存 
<p> MySQL拿到一个查询请求后，会先到查询缓存看看，之前是不是执行过这条语句。之前执行过的语句及其结果可能会以key-value对的形式，被直接缓存在内存中。key是查询的语句，value是查询的结果。如果你的查询能够直接在这个缓存中找到key，那么这个value就会被直接返回给客户端
<p> ps： 每次操作后 整个表缓存会失效  (不推荐用本身的缓存) and 数据会在8之后 取消了缓存   

<p> 3 分析器
<p>     如果没有命中查询缓存，就要开始真正执行语句了。首先，MySQL需要知道你要做什么，因此需要对SQL语句做解析
<p> ps: 这一步会检查语法错误 “You have an error in your SQL syntax”的错误提醒

<p> 4 优化器
<p> MySQL就知道你要做什么了。在开始执行之前，还要先经过优化器的处理。
<p>   优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序
<p> 1、选择最合适的索引；
 <p>2、选择表扫还是走索引；
<p> 3、选择表关联顺序；
<p> 4、优化 where 子句；
<p> 5、排除管理中无用表；
<p> 6、决定 order by 和 group by 是否走索引；
<p> 7、尝试使用 inner join 替换 outer join；
<p> 8、简化子查询，决定结果缓存；
<p> 9、合并试图；

<p> 5  执行器
<p> 进入了执行器阶段，开始执行语句 会判断是否有执行的权限 
<pre><code>
select * from T where ID=10;
</code></pre>
<p>如果有权限，就打开表继续执行。打开表的时候，执行器就会根据表的引擎定义，去使用这个引擎提供的接口。
<p>比如我们这个例子中的表T中，ID字段没有索引，那么执行器的执行流程是这样的：
<p>调用InnoDB引擎接口取这个表的第一行，判断ID值是不是10，如果不是则跳过，如果是则将这行存在结果集中；
<p>调用引擎接口取“下一行”，重复相同的判断逻辑，直到取到这个表的最后一行。
<p>执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端。
<p>至此，这个语句就执行完成了  

<p>对于有索引的表，执行的逻辑也差不多。第一次调用的是“取满足条件的第一行”这个接口，
<p>之后循环取“满足条件的下一行”这个接口，这些接口都是引擎中已经定义好的。
<p>你会在数据库的慢查询日志中看到一个rows_examined的字段，表示这个语句执行过程中扫描了多少行。
<p>这个值就是在执行器每次调用引擎获取数据行的时候累加的。


### redo log（重做日志）和 binlog（归档日志）
#### 重要的日志模块：redo log
<p>1 就是MySQL里经常说到的WAL技术，WAL的全称是Write-Ahead Logging，它的关键点就是先写日志，再写磁盘
<p>2 具体来说，当有一条记录需要更新的时候，InnoDB引擎就会先把记录写到redo log（粉板）里面，并更新内存，这个时候更新就算完成了。
<p>同时，InnoDB引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做
<p> 如果日志满了  会把一部分记录写到磁盘 腾出空间 让后面日志可以继续写
<p> InnoDB的redo log是固定大小的，比如可以配置为一组4个文件，每个文件的大小是1GB，总共就可以记录4GB的操作
<p>3  crash-safe
 <p>write pos是当前记录的位置，一边写一边后移，写到第3号文件末尾后就回到0号文件开头。checkpoint是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。  
<p>write pos和checkpoint之间的是“粉板”上还空着的部分，可以用来记录新的操作。如果write pos追上checkpoint，表示“粉板”满了，这时候不能再执行新的更新，得停下来先擦掉一些记录，把checkpoint推进一下。
<p>有了redo log，InnoDB就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为crash-safe

#### 重要的日志模块：binlog
<p>MySQL整体来看，其实就有两块：一块是Server层，它主要做的是MySQL功能层面的事情；还有一块是引擎层，负责存储相关的具体事宜。
<p>上面我们聊到的粉板redo log是InnoDB引擎特有的日志，而Server层也有自己的日志，称为binlog（归档日志）
<p>这两种日志有以下三点不同。

<p>redo log是InnoDB引擎特有的；binlog是MySQL的Server层实现的，所有引擎都可以使用。

<p>redo log是物理日志，记录的是“在某个数据页上做了什么修改”；binlog是逻辑日志，记录的是这个语句的原始逻辑，比如“给ID=2这一行的c字段加1 ”。

<p>redo log是循环写的，空间固定会用完；binlog是可以追加写入的。“追加写”是指binlog文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。

<p>有了对这两个日志的概念性理解，我们再来看执行器和InnoDB引擎在执行这个简单的update语句时的内部流程。

<p>执行器先找引擎取ID=2这一行。ID是主键，引擎直接用树搜索找到这一行。如果ID=2这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。

<p>执行器拿到引擎给的行数据，把这个值加上1，比如原来是N，现在就是N+1，得到新的一行数据，再调用引擎接口写入这行新数据。

<p>引擎将这行新数据更新到内存中，同时将这个更新操作记录到redo log里面，此时redo log处于prepare状态。然后告知执行器执行完成了，随时可以提交事务。

<p>执行器生成这个操作的binlog，并把binlog写入磁盘。

<p>执行器调用引擎的提交事务接口，引擎把刚刚写入的redo log改成提交（commit）状态，更新完成。

#### 两阶段提交
<p>由于redo log和binlog是两个独立的逻辑，如果不用两阶段提交，要么就是先写完redo log再写binlog，或者采用反过来的顺序。我们看看这两种方式会有什么问题。

<p>仍然用前面的update语句来做例子。假设当前ID=2的行，字段c的值是0，再假设执行update语句过程中在写完第一个日志后，第二个日志还没有写完期间发生了crash，会出现什么情况呢？

<p>先写redo log后写binlog。假设在redo log写完，binlog还没有写完的时候，MySQL进程异常重启。由于我们前面说过的，redo log写完之后，系统即使崩溃，仍然能够把数据恢复回来，所以恢复后这一行c的值是1。
<p>但是由于binlog没写完就crash了，这时候binlog里面就没有记录这个语句。因此，之后备份日志的时候，存起来的binlog里面就没有这条语句。
<p>然后你会发现，如果需要用这个binlog来恢复临时库的话，由于这个语句的binlog丢失，这个临时库就会少了这一次更新，恢复出来的这一行c的值就是0，与原库的值不同。

<p>先写binlog后写redo log。如果在binlog写完之后crash，由于redo log还没写，崩溃恢复以后这个事务无效，所以这一行c的值是0。但是binlog里面已经记录了“把c从0改成1”这个日志。所以，在之后用binlog来恢复的时候就多了一个事务出来，恢复出来的这一行c的值就是1，与原库的值不同。

<p>可以看到，如果不使用“两阶段提交”，那么数据库的状态就有可能和用它的日志恢复出来的库的状态不一致。


### 事物
#### 隔离性与隔离级别
<p>提到事务，你肯定会想到ACID（Atomicity、Consistency、Isolation、Durability，即原子性、一致性、隔离性、持久性），
今天我们就来说说其中I，也就是“隔离性”。

<p>当数据库上有多个事务同时执行的时候，就可能出现脏读（dirty read）、不可重复读（non-repeatable read）、幻读（phantom read）的问题，
<p>为了解决这些问题，就有了“隔离级别”的概念。

<p>在谈隔离级别之前，你首先要知道，你隔离得越严实，效率就会越低。因此很多时候，我们都要在二者之间寻找一个平衡点。SQL标准的事务隔离级别包括：
<p>读未提交（read uncommitted）、读提交（read committed）、可重复读（repeatable read）和串行化（serializable ）。下面我逐一为你解释：
    <li>读未提交是指，一个事务还没提交时，它做的变更就能被别的事务看到。
    <li>读提交是指，一个事务提交之后，它做的变更才会被其他事务看到。
    <li>可重复读是指，一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。
    <li>串行化，顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。
 <p> 现在有两个事物同时启动   
<table>
 <tr> <td>事物1</td><td>事物2</td>    </tr>
 <tr> <td>启动事物1 得到值1</td><td>启动事物2</td>    </tr>
 <tr> <td></td><td>得到值1</td>    </tr>
 <tr> <td></td><td>将1改成2</td>    </tr>
 <tr> <td>查询值V1</td><td></td>    </tr>
 <tr> <td></td><td>提交事物2</td>    </tr>
 <tr> <td>查询得到值V2</td><td></td>    </tr>
 <tr> <td>提交事物1</td><td></td>    </tr>
 <tr> <td>查询得到值V3</td><td></td>    </tr>
 </table>
 
<p> 我们来看看在不同的隔离级别下，事务A会有哪些不同的返回结果，也就是图里面V1、V2、V3的返回值分别是什么。
 
 <li>若隔离级别是“读未提交”， 则V1的值就是2。这时候事务B虽然还没有提交，但是结果已经被A看到了。因此，V2、V3也都是2。
<li> 若隔离级别是“读提交”，则V1是1，V2的值是2。事务B的更新在提交后才能被A看到。所以， V3的值也是2。
<li 若隔离级别是“可重复读”，则V1、V2是1，V3是2。之所以V2还是1，遵循的就是这个要求：事务在执行期间看到的数据前后必须是一致的。
<li> 若隔离级别是“串行化”，则在事务B执行“将1改成2”的时候，会被锁住。直到事务A提交后，事务B才可以继续执行。所以从A的角度看， V1、V2值是1，V3的值是2。
<p> 在实现上，数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。在“可重复读”隔离级别下，这个视图是在事务启动时创建的，
<p>整个事务存在期间都用这个视图。在“读提交”隔离级别下，这个视图是在每个SQL语句开始执行的时候创建的。这里需要注意的是，
<p>“读未提交”隔离级别下直接返回记录上的最新值，没有视图概念；而“串行化”隔离级别下直接用加锁的方式来避免并行访问。
 
<p> 我们可以看到在不同的隔离级别下，数据库行为是有所不同的。Oracle数据库的默认隔离级别其实就是“读提交”，因此对于一些从Oracle迁移到MySQL的应用，
<p>为保证数据库隔离级别的一致，你一定要记得将MySQL的隔离级别设置为“读提交”。
 
 <p>配置的方式是，将启动参数transaction-isolation的值设置成READ-COMMITTED。你可以用show variables来查看当前的值。
 
####  事务隔离的实现
<p>假设一个值从1被按顺序改成了2、3、4，当前值是4，但是在查询这条记录的时候，不同时刻启动的事务会有不同的read-view。
<p>如图中看到的，在视图A、B、C里面，这一个记录的值分别是1、2、4，同一条记录在系统中可以存在多个版本，就是数据库的多版本并发控制（MVCC）。
<p>对于read-view A，要得到1，就必须将当前值依次执行图中所有的回滚操作得到。
<p> 同时你会发现，即使现在有另外一个事务正在将4改成5，这个事务跟read-view A、B、C对应的事务是不会冲突的。
<p> 你一定会问，回滚日志总不能一直保留吧，什么时候删除呢？答案是，在不需要的时候才删除。也就是说，系统会判断，当没有事务再需要用到这些回滚日志时，
<p>回滚日志会被删除。
<p> 什么时候才不需要了呢？就是当系统里没有比这个回滚日志更早的read-view的时候。
 <p> ps： 少用长事物

#### MVCC 
<a href="https://www.cnblogs.com/AnXinliang/p/9955331.html">MVCC并发控制</a>
<p> 他本质就是处理数据的版本号和自己事物的版本号  来判断状态
<p>版本号
<li>系统版本号：是一个递增的数字，每开始一个新的事务，系统版本号就会自动递增。
<li>事务版本号：事务开始时的系统版本号。
<p>隐藏的列
<li>MVCC 在每行记录后面都保存着两个隐藏的列，用来存储两个版本号：

<li>创建版本号：指示创建一个数据行的快照时的系统版本号；
<li>删除版本号：如果该快照的删除版本号大于当前事务版本号表示该快照有效，否则表示该快照已经被删除了。
<p>Undo 日志
<li>VCC 使用到的快照存储在 Undo 日志中，该日志通过回滚指针把一个数据行（Record）的所有快照连接起来。
<p>实现过程
<p>以下实现过程针对可重复读隔离级别。

<p>当开始新一个事务时，该事务的版本号肯定会大于当前所有数据行快照的创建版本号，理解这一点很关键。

<p>1. SELECT

<p>多个事务必须读取到同一个数据行的快照，并且这个快照是距离现在最近的一个有效快照。但是也有例外，如果有一个事务正在修改该数据行，
<p>那么它可以读取事务本身所做的修改，而不用和其它事务的读取结果一致。
<p>把没有对一个数据行做修改的事务称为 T，T 所要读取的数据行快照的创建版本号必须小于 T 的版本号，因为如果大于或者等于 T 的版本号，
<p>那么表示该数据行快照是其它事务的最新修改，因此不能去读取它。除此之外，T 所要读取的数据行快照的删除版本号必须大于 T 的版本号，
<p>因为如果小于等于 T 的版本号，那么表示该数据行快照是已经被删除的，不应该去读取它。

<p>2. INSERT
<p>将当前系统版本号作为数据行快照的创建版本号。

<p>3. DELETE
<p>将当前系统版本号作为数据行快照的删除版本号。

<p>4. UPDATE
<p>将当前系统版本号作为更新前的数据行快照的删除版本号，并将当前系统版本号作为更新后的数据行快照的创建版本号。可以理解为先执行 DELETE 后执行 INSERT。

<p>Next-Key Locks
<p>Next-Key Locks 是 MySQL 的 InnoDB 存储引擎的一种锁实现。

<p>MVCC 不能解决幻读的问题，Next-Key Locks 就是为了解决这个问题而存在的。在可重复读（REPEATABLE READ）隔离级别下，使用 MVCC + Next-Key Locks 可以解决幻读问题。

<p>Record Locks  (记录锁)
<p>锁定一个记录上的索引，而不是记录本身。

<p>如果表没有设置索引，InnoDB 会自动在主键上创建隐藏的聚簇索引，因此 Record Locks 依然可以使用。

<p>Gap Locks (间隙锁)
<p>锁定索引之间的间隙，但是不包含索引本身。例如当一个事务执行以下语句，其它事务就不能在 t.c 中插入 15。
<pre><code>
SELECT c FROM t WHERE c BETWEEN 10 and 20 FOR UPDATE;     </code></pre>
<p>Next-Key Locks (区间锁)
<p>它是 Record Locks 和 Gap Locks 的结合，不仅锁定一个记录上的索引，也锁定索引之间的间隙。例如一个索引包含以下值：10, 11, 13, and 20，那么就需要锁定以下区间：
 <pre><code>
(negative infinity, 10]
(10, 11]
(11, 13]
(13, 20]
(20, positive infinity)   </code></pre>

### 事务的启动方式
<p>1 显式启动事务语句， begin 或 start transaction。配套的提交语句是commit，回滚语句是rollback。

<p>2 set autocommit=0，这个命令会将这个线程的自动提交关掉。意味着如果你只执行一个select语句，这个事务就启动了，而且并不会自动提交。
<p>这个事务持续存在直到你主动执行commit 或 rollback 语句，或者断开连接。

<p> ps: 推荐手动去开启 提交

### 索引
<p>索引的出现其实就是为了提高数据查询的效率，就像书的目录一样

####索引的常见模型
<p> 1 哈希表
<p>一种以键-值（key-value）存储数据的结构，我们只要输入待查找的值即key，就可以找到其对应的值即Value。哈希的思路很简单，
<p>把值放在数组里，用一个哈希函数把key换算成一个确定的位置，然后把value放在数组的这个位置。
 <p> 不可避免地，多个key值经过哈希函数的换算，会出现同一个值的情况。处理这种情况的一种方法是，拉出一个链表。
 <p> ps : 解决hash冲突: 1 开放定址（没看懂） 2 再hash  3 hashmap 所用的链表 4 公共溢出区
 <p> 哈希表这种结构适用于只有等值查询的场景，比如Memcached及其他一些NoSQL引擎。
 <p> 2 有序数组
 <p> 有序数组在等值查询和范围查询场景中的性能就都非常优秀 
 <p> 仅仅看查询效率，有序数组就是最好的数据结构了。但是，在需要更新数据的时候就麻烦了，你往中间插入一个记录就必须得挪动后面所有的记录，成本太高
 <p> 有序数组索引只适用于静态存储引擎，比如你要保存的是2017年某个城市的所有人口信息，这类不会再修改的数据
 
 <p> 3 二叉搜索树(或者多叉)
 <p> 查询复杂度是O(log(N))，你就需要保持这棵树是平衡二叉树。为了做这个保证，更新的时间复杂度也是O(log(N))
 <p>树可以有二叉，也可以有多叉。多叉树就是每个节点有多个儿子，儿子之间的大小保证从左到右递增。二叉树是搜索效率最高的，
 <p>但是实际上大多数的数据库存储却并不使用二叉树。其原因是，索引不止存在内存中，还要写到磁盘上 , 二叉树从磁盘加载到内存效率太低
 
 #### InnoDB 的索引模型
 <p> 索引类型分为主键索引和非主键索引。
 <p>     主键索引的叶子节点存的是整行数据。在InnoDB里，主键索引也被称为聚簇索引（clustered index）。
 <p>     非主键索引的叶子节点内容是主键的值。在InnoDB里，非主键索引也被称为二级索引（secondary index）。
  <p>    根据上面的索引结构说明，我们来讨论一个问题：基于主键索引和普通索引的查询有什么区别？
  <li>    如果语句是select * from T where ID=500，即主键查询方式，则只需要搜索ID这棵B+树；
  <li>   如果语句是select * from T where k=5，即普通索引查询方式，则需要先搜索k索引树，得到ID的值为500，再到ID索引树搜索一次。这个过程称为回表。
<p>   也就是说，基于非主键索引的查询需要多扫描一棵索引树。因此，我们在应用中应该尽量使用主键查询。

#### 索引维护
<p> B+树为了维护索引有序性，在插入新值的时候需要做必要的维护。如果插入新的行ID值为700，则只需要在R5的记录后面插入一个新记录。
<p>如果新插入的ID值为400，就相对麻烦了，需要逻辑上挪动后面的数据，空出位置。
 
 <p>而更糟的情况是，如果R5所在的数据页已经满了，根据B+树的算法，这时候需要申请一个新的数据页，然后挪动部分数据过去。
 <p>这个过程称为页分裂。在这种情况下，性能自然会受影响
<p> 分裂就有合并。当相邻两个页由于删除了数据，利用率很低之后，会将数据页做合并。合并的过程，可以认为是分裂过程的逆过程
<p> 1 用自增主键的插入数据模式，正符合了我们前面提到的递增插入的场景。每次插入一条新记录，都是追加操作，都不涉及到挪动其他记录，也不会触发叶子节点的分裂
<p> 2 用业务逻辑的字段做主键，则往往不容易保证有序插入，这样写数据成本相对较高。

### 
<img src="https://static001.geekbang.org/resource/image/dc/8d/dcda101051f28502bd5c4402b292e38d.png"/>
<p>  如果我执行 select * from T where k between 3 and 5，需要执行几次树的搜索操作，会扫描多少行？
<p> 这条SQL查询语句的执行流程：
<p>    在k索引树上找到k=3的记录，取得 ID = 300；
<p>    再到ID索引树查到ID=300对应的R3；
<p>    在k索引树取下一个值k=5，取得ID=500；
<p>    再回到ID索引树查到ID=500对应的R4；
<p>    在k索引树取下一个值k=6，不满足条件，循环结束。
<p>    在这个过程中，回到主键索引树搜索的过程，我们称为回表。可以看到，这个查询过程读了k索引树的3条记录（步骤1、3和5），回表了两次（步骤2和4）。
<p>    在这个例子中，由于查询结果所需要的数据只在主键索引上有，所以不得不回表。那么，有没有可能经过索引优化，避免回表过程呢？


#### 覆盖索引
<p> 如果执行的语句是select ID from T where k between 3 and 5，这时只需要查ID的值，而ID的值已经在k索引树上了，因此可以直接提供查询结果，
不需要回表。也就是说，在这个查询里面，索引k已经“覆盖了”我们的查询需求，我们称为覆盖索引。

<p> 由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段。
  
#### 最左前缀原则
<img src="https://static001.geekbang.org/resource/image/89/70/89f74c631110cfbc83298ef27dcd6370.jpg"/>
<p>如果有一个 2 列的索引 (col1, col2)，则已经对 (col1)、(col1, col2) 上建立了索引；
<p>如果有一个 3 列索引 (col1, col2, col3)，则已经对 (col1)、(col1, col2)、(col1, col2, col3) 上建立了索引；

<p>mysql 查询优化器
<p>如果建的索引是 (name, cid)。而查询的语句是 cid=1 AND name=’小红’。为什么还能利用到索引？
<p>当按照索引中所有列进行精确匹配（“=” 或 “IN”）时，索引可以被用到，并且 type 为 const。理论上索引对顺序是敏感的，但是由于 MySQL 的查询优化器会自动调整 where 子句的条件顺序以使用适合的索引，所以 MySQL 不存在 where 子句的顺序问题而造成索引失效
  
<p>  注意事项
  
<li>  范围查询
<p>  mysql 会一直向右匹配直到遇到范围查询（>、<、between、like）就停止匹配。范围列可以用到索引，但是范围列后面的列无法用到索引。即，索引最多用于一个范围列，因此如果查询条件中有两个范围列则无法全用到索引
 <li> like 语句的索引问题
<p>  如果通配符 % 不出现在开头，则可以用到索引，但根据具体情况不同可能只会用其中一个前缀
<p>  在 like “value%” 可以使用索引，但是 like “%value%” 不会使用索引，走的是全表扫描
<li>  不要在列上进行运算
<p>  如果查询条件中含有函数或表达式，将导致索引失效而进行全表扫描
 <p> 例如 select * from user where YEAR(birthday) < 1990
 <p> 可以改造成 select * from users where birthday <’1990-01-01′
<li>  索引不会包含有 NULL 值的列
<p>  只要列中包含有 NULL 值都将不会被包含在索引中，复合索引中只要有一列含有 NULL 值，那么这一列对于此复合索引就是无效的。所以在数据库设计时不要让字段的默认值为 NULL
<p>  尽量选择区分度高的列作为索引，区分度的公式是 count(distinct col)/count(*)，表示字段不重复的比例，
<p>比例越大我们扫描的记录数越少，唯一键的区分度是 1，而一些状态、性别字段可能在大数据面前区分度就是 0。一般需要 join 的字段都要求区分度 0.1 以上，即平均 1 条扫描 10 条记录
<li>  覆盖索引的好处
<p>  如果一个索引包含所有需要的查询的字段的值，我们称之为覆盖索引。覆盖索引是非常有用的工具，能够极大的提高性能。因为，只需要读取索引，而无需读表，极大减少数据访问量

#### 索引下推
<p>如果现在有一个需求：检索出表中“名字第一个字是张，而且年龄是10岁的所有男孩”。那么，SQL语句是这么写的：
<pre><code>
mysql> select * from tuser where name like '张%' and age=10 and ismale=1;
</code></pre>

<p>在MySQL 5.6之前，只能从ID3开始一个个回表。到主键索引上找出数据行，再对比字段值。

<p>而MySQL 5.6 引入的索引下推优化（index condition pushdown)， 可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。
 <img src="https://static001.geekbang.org/resource/image/b3/ac/b32aa8b1f75611e0759e52f5915539ac.jpg"/>
 <p>无下推流程
 <img src="https://static001.geekbang.org/resource/image/76/1b/76e385f3df5a694cc4238c7b65acfe1b.jpg"/>
 <p>有下推流程
 
 
 ### 锁
 <p> 数据库锁设计的初衷是处理并发问题。作为多用户共享的资源，当出现并发访问的时候，数据库需要合理地控制资源的访问规则。而锁就是用来实现这些访问规则的重要数据结构。
<p>根据加锁的范围，MySQL里面的锁大致可以分成全局锁、表级锁和行锁三类 

####  全局锁
<p>MySQL提供了一个加全局读锁的方法，命令是 Flush tables with read lock (FTWRL)。当你需要让整个库处于只读状态的时候，
<p>可以使用这个命令，之后其他线程的以下语句会被阻塞：数据更新语句（数据的增删改）、数据定义语句（包括建表、修改表结构等）和更新类事务的提交语句。

<p>全局锁的典型使用场景是，做全库逻辑备份

<p> 对主从库备份的问题
<li>如果你在主库上备份，那么在备份期间都不能执行更新，业务基本上就得停摆；
<li>如果你在从库上备份，那么备份期间从库不能执行主库同步过来的binlog，会导致主从延迟
<p> 不加锁备份的问题
<p> 如果有写操作 操作多个表 备份数据表的数据可能不一致
<p>时间顺序上是先备份账户余额表(u_account)，然后用户购买，然后备份用户课程表(u_course) 
<p> 其他方案
<p> 1   事物 
<p>官方自带的逻辑备份工具是mysqldump。当mysqldump使用参数–single-transaction的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。而由于MVCC的支持，这个过程中数据是可以正常更新的
<p> 缺点: 一致性读是好，但前提是引擎要支持这个隔离级别  MyISAM就不支持
<p> 2 set global readonly=true 方案
<li>一是，在有些系统中，readonly的值会被用来做其他逻辑，比如用来判断一个库是主库还是备库。因此，修改global变量的方式影响面更大，我不建议你使用。
<li>二是，在异常处理机制上有差异。如果执行FTWRL命令之后由于客户端发生异常断开，那么MySQL会自动释放这个全局锁整个库回到可以正常更新的状态。而将整个库设置为readonly之后，如果客户端发生异常，则数据库就会一直保持readonly状态，这样会导致整个库长时间处于不可写状态，风险较高。

#### 表级锁
<p> MySQL里面表级别的锁有两种：一种是表锁，一种是元数据锁（meta data lock，MDL)。
<p> 表锁的语法是 lock tables … read/write。与FTWRL类似，可以用unlock tables主动释放锁，也可以在客户端断开的时候自动释放。需要注意，lock tables语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。
 
<p> 举个例子, 如果在某个线程A中执行lock tables t1 read, t2 write; 这个语句，则其他线程写t1、读写t2的语句都会被阻塞。同时，线程A在执行unlock tables之前，也只能执行读t1、读写t2的操作。连写t1都不允许，自然也不能访问其他表。
 
<p> 在还没有出现更细粒度的锁的时候，表锁是最常用的处理并发的方式。而对于InnoDB这种支持行锁的引擎，一般不使用lock tables命令来控制并发，毕竟锁住整个表的影响面还是太大

<p> 另一类表级的锁是MDL（metadata lock)。MDL不需要显式使用，在访问一个表的时候会被自动加上。MDL的作用是，保证读写的正确性。你可以想象一下，如果一个查询正在遍历一个表中的数据，而执行期间另一个线程对这个表结构做变更，删了一列，那么查询线程拿到的结果跟表结构对不上，肯定是不行的。

<p> 因此，在MySQL 5.5版本中引入了MDL，当对一个表做增删改查操作的时候，加MDL读锁；当要对表做结构变更操作的时候，加MDL写锁。

<li>读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查。

<li>读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行

<img src="https://static001.geekbang.org/resource/image/7c/ce/7cf6a3bf90d72d1f0fc156ececdfb0ce.jpg"/>

#### 行锁
<p> 行锁就是针对数据表中行记录的锁。这很好理解，比如事务A更新了一行，而这时候事务B也要更新同一行，则必须等事务A的操作完成后才能进行更新

##### 两阶段锁说起
<p>在InnoDB事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议

##### 死锁和死锁检测
<p>当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为死锁
<img src="https://static001.geekbang.org/resource/image/4d/52/4d0eeec7b136371b79248a0aed005a52.jpg"/>
<p>两种策略：

<li>一种策略是，直接进入等待，直到超时。这个超时时间可以通过参数innodb_lock_wait_timeout来设置。
<li>另一种策略是，发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数innodb_deadlock_detect设置为on，表示开启这个逻辑。

<p>那如果是我们上面说到的所有事务都要更新同一行的场景呢？

<p>每个新来的被堵住的线程，都要判断会不会由于自己的加入导致了死锁，这是一个时间复杂度是O(n)的操作。假设有1000个并发线程要同时更新同一行，那么死锁检测操作就是100万这个量级的。虽然最终检测的结果是没有死锁，但是这期间要消耗大量的CPU资源。因此，你就会看到CPU利用率很高，但是每秒却执行不了几个事务。

<p>根据上面的分析，我们来讨论一下，怎么解决由这种热点行更新导致的性能问题呢？
<li> 一种头痛医头的方法，就是如果你能确保这个业务一定不会出现死锁，可以临时把死锁检测关掉。
<li> 另一个思路是控制并发度

### 8  事务到底是隔离的还是不隔离的？
<p>  如果是可重复读隔离级别，事务T启动的时候会创建一个视图read-view，之后事务T执行期间，即使有其他事务修改了数据，事务T看到的仍然跟在启动时看到的一样。也就是说，一个在可重复读隔离级别下执行的事务 不收其他事物影响
<p> 但如果update 一行 遇到了锁 情况就不一样了
<img src="https://static001.geekbang.org/resource/image/82/d6/823acf76e53c0bdba7beab45e72e90d6.png">

<p> 结论:事务B查到的k的值是3，而事务A查到的k的值是1

<p>在MySQL里，有两个“视图”的概念：
   
<li>   一个是view。它是一个用查询语句定义的虚拟表，在调用的时候执行查询语句并生成结果。创建视图的语法是create view … ，而它的查询方法与表一样。
<li>   另一个是InnoDB在实现MVCC时用到的一致性读视图，即consistent read view，用于支持RC（Read Committed，读提交）和RR（Repeatable Read，可重复读）隔离级别的实现。

##### “快照”在MVCC里是怎么工作的？
<p>在可重复读隔离级别下，事务在启动的时候就“拍了个快照”。注意，这个快照是基于整库的。
 <p>  InnoDB利用了“所有数据都有多个版本”的这个特性，实现了“秒级创建快照”的能力。
<p>     接下来，我们继续看一下图1中的三个事务，分析下事务A的语句返回的结果，为什么是k=1。
 <p>    这里，我们不妨做如下假设：
  <li>   事务A开始前，系统里面只有一个活跃事务ID是99；
  <li>      事务A、B、C的版本号分别是100、101、102，且当前系统里只有这四个事务；
  <li>      三个事务开始前，(1,1）这一行数据的row trx_id是90。
  <p>    这样，事务A的视图数组就是[99,100], 事务B的视图数组是[99,100,101], 事务C的视图数组是[99,100,101,102]。
   <p>   为了简化分析，我先把其他干扰语句去掉，只画出跟事务A查询逻辑有关的操作
  <img src="https://static001.geekbang.org/resource/image/94/49/9416c310e406519b7460437cb0c5c149.png"/>
 <p>  从图中可以看到，第一个有效更新是事务C，把数据从(1,1)改成了(1,2)。这时候，这个数据的最新版本的row trx_id是102，而90这个版本已经成为了历史版本。
 <p>  第二个有效更新是事务B，把数据从(1,2)改成了(1,3)。这时候，这个数据的最新版本（即row trx_id）是101，而102又成为了历史版本。
  <p> 你可能注意到了，在事务A查询的时候，其实事务B还没有提交，但是它生成的(1,3)这个版本已经变成当前版本了。但这个版本对事务A必须是不可见的，否则就变成脏读了。
  <p> 好，现在事务A要来读数据了，它的视图数组是[99,100]。当然了，读数据都是从当前版本读起的。所以，事务A查询语句的读数据流程是这样的：
   <li> 找到(1,3)的时候，判断出row trx_id=101，比高水位大，处于红色区域，不可见；
  <li>  接着，找到上一个历史版本，一看row trx_id=102，比高水位大，处于红色区域，不可见；
   <li> 再往前找，终于找到了（1,1)，它的row trx_id=90，比低水位小，处于绿色区域，可见。
 <p>  这样执行下来，虽然期间这一行数据被修改过，但是事务A不论在什么时候查询，看到这行数据的结果都是一致的，所以我们称之为一致性读。

 <p>一个数据版本，对于一个事务视图来说，除了自己的更新总是可见以外，有三种情况：
<li>版本未提交，不可见；
<li>版本已提交，但是是在视图创建后提交的，不可见；
<li>版本已提交，而且是在视图创建前提交的，可见

 <p>现在，我们用这个规则来判断图4中的查询结果，事务A的查询语句的视图数组是在事务A启动的时候生成的，这时候：

<li>(1,3)还没提交，属于情况1，不可见；
<li>(1,2)虽然提交了，但是是在视图数组创建之后提交的，属于情况2，不可见；
<li>(1,1)是在视图数组创建之前提交的，可见。

#### 更新逻辑
<p> 在上面一题中 事务B的update语句，如果按照一致性读，好像结果不对
<p> 如果事务B在更新之前查询一次数据，这个查询返回的k的值确实是1。
    
<p>    但是，当它要去更新数据的时候，就不能再在历史版本上更新了，否则事务C的更新就丢失了。因此，事务B此时的set k=k+1是在（1,2）的基础上进行的操作。
    
<p>    所以，这里就用到了这样一条规则：更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读”（current read）。
    
<p>    因此，在更新的时候，当前读拿到的数据是(1,2)，更新后生成了新版本的数据(1,3)，这个新版本的row trx_id是101。
    
<p>    所以，在执行事务B查询语句的时候，一看自己的版本号是101，最新数据的版本号也是101，是自己的更新，可以直接使用，所以查询得到的k的值是3。
    
<p>    这里我们提到了一个概念，叫作当前读。其实，除了update语句外，select语句如果加锁，也是当前读。 

<p>如果把事务A的查询语句select * from t where id=1修改一下，加上lock in share mode 或 for update，也都可以读到版本号是101的数据，返回的k的值是3。下面这两个select语句，就是分别加了读锁（S锁，共享锁）和写锁（X锁，排他锁）。
 <pre><code>
mysql> select k from t where id=1 lock in share mode;
mysql> select k from t where id=1 for update; 
</code></pre>  

<p> 如果是这样呢
<img src="https://static001.geekbang.org/resource/image/cd/6e/cda2a0d7decb61e59dddc83ac51efb6e.png"/>

<p> 在事物B中  因为“两阶段锁协议”。事务C’没提交，也就是说(1,2)这个版本上的写锁还没释放。而事务B是当前读，必须要读最新版本，而且必须加锁，因此就被锁住了，必须等到事务C’释放这个锁，才能继续它的当前读。
<p> 在事物A中  
<li>(1,3)还没提交，属于情况1，不可见；
<li>(1,2)提交了，属于情况3，可见。
<p>所以，这时候事务A查询语句返回的是k=2。 B中拿到3


#### 事务的可重复读的能力是怎么实现的？

<p>可重复读的核心就是一致性读（consistent read）；而事务更新数据的时候，只能用当前读。如果当前的记录的行锁被其他事务占用的话，就需要进入锁等待。

<p>而读提交的逻辑和可重复读的逻辑类似，它们最主要的区别是：

<li>在可重复读隔离级别下，只需要在事务开始的时候创建一致性视图，之后事务里的其他查询都共用这个一致性视图；
<li>在读提交隔离级别下，每一个语句执行前都会重新算出一个新的视图。
<p>这里需要说明一下，“start transaction with consistent snapshot; ”的意思是从这个语句开始，创建一个持续整个事务的一致性快照。所以，在读提交隔离级别下，这个用法就没意义了，等效于普通的start transaction。

 <p> 小结
<p>  InnoDB的行数据有多个版本，每个数据版本有自己的row trx_id，每个事务或者语句有自己的一致性视图。普通查询语句是一致性读，一致性读会根据row trx_id和一致性视图确定数据版本的可见性。
  
<li>  对于可重复读，查询只承认在事务启动前就已经提交完成的数据；
<li>  对于读提交，查询只承认在语句启动前就已经提交完成的数据
<p> 而当前读，总是读取已经提交完成的最新版本

<p> ps: 本章重点 
<li>1 两阶段锁协议  在执行时才拿到事物  拿到行锁 提交事物时 才释放锁
<li>2 当前读   更新数据都是先读后写的  这个读如果被锁wait住  在拿到锁  它会去拿最新数据( 就是上一个锁修改的数据)

###  9 普通索引和唯一索引
<p> 执行差别：
<li>对于普通索引来说，查找到满足条件的第一个记录(5,500)后，需要查找下一个记录，直到碰到第一个不满足k=5条件的记录。
<li>对于唯一索引来说，由于索引定义了唯一性，查找到第一个满足条件的记录后，就会停止继续检索。

####  查询过程
<p> 索引树上查找的过程，先是通过B+树从树根开始，按层搜索到叶子节点，也就是图中右下角的这个数据页，然后可以认为数据页内部通过二分法来定位记录
<p> InnoDB的数据是按数据页为单位来读写的。也就是说，当需要读一条记录的时候，并不是将这个记录本身从磁盘读出来，而是以页为单位，将其整体读入内存。在InnoDB中，每个数据页的大小默认是16KB。
<p> 这个记录有可能在下一页 但一个数据页可以放近千个key，因此出现这种情况的概率会很低。

#### 更新过程
##### change buffer 
<p> 更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，
<p> InooDB会将这些更新操作缓存在change buffer中，这样就不需要从磁盘中读入这个数据页了。在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行change buffer中与这个页有关的操作。通过这种方式就能保证这个数据逻辑的正确性。

<p> change buffer，实际上它是可以持久化的数据。也就是说，change buffer在内存中有拷贝，也会被写入到磁盘上
<p>  将change buffer中的操作应用到原数据页，得到最新结果的过程称为merge。除了访问这个数据页会触发merge外，系统有后台线程会定期merge。在数据库正常关闭（shutdown）的过程中，也会执行merge操作
<p> 更新操作先记录在change buffer，减少读磁盘，语句的执行速度会得到明显的提升。而且，数据读入内存是需要占用buffer pool的，所以这种方式还能够避免占用内存，提高内存利用率

##### 什么条件下可以使用change buffer
<p> 1 唯一索引来说，所有的更新操作都要先判断这个操作是否违反唯一性约束。比如，要插入(4,400)这个记录，就要先判断现在表中是否已经存在k=4的记录，而这必须要将数据页读入内存才能判断。如果都已经读入到内存了，那直接更新内存会更快，就没必要使用change buffer了。
<p> 因此，唯一索引的更新就不能使用change buffer，实际上也只有普通索引可以使用
<p>change buffer用的是buffer pool里的内存，因此不能无限增大。change buffer的大小，可以通过参数innodb_change_buffer_max_size来动态设置。这个参数设置为50的时候，表示change buffer的大小最多只能占用buffer pool的50%。

<p>现在，你已经理解了change buffer的机制，那么我们再一起来看看如果要在这张表中插入一个新记录(4,400)的话，InnoDB的处理流程是怎样的。

<p>第一种情况是，这个记录要更新的目标页在内存中。这时，InnoDB的处理流程如下：

<li>对于唯一索引来说，找到3和5之间的位置，判断到没有冲突，插入这个值，语句执行结束；
<li>对于普通索引来说，找到3和5之间的位置，插入这个值，语句执行结束。
<p>这样看来，普通索引和唯一索引对更新语句性能影响的差别，只是一个判断，只会耗费微小的CPU时间。

<p>但，这不是我们关注的重点。

<p>第二种情况是，这个记录要更新的目标页不在内存中。这时，InnoDB的处理流程如下：

<li>对于唯一索引来说，需要将数据页读入内存，判断到没有冲突，插入这个值，语句执行结束；
<li>对于普通索引来说，则是将更新记录在change buffer，语句执行就结束了。
<p>将数据从磁盘读入内存涉及随机IO的访问，是数据库里面成本最高的操作之一。change buffer因为减少了随机磁盘访问，所以对更新性能的提升是会很明显的。

##### change buffer的使用场景
<p> 适用于 更新后不会马上查询的操作  写多读少

##### change buffer 和 redo log
<p>现在，我们要在表上执行这个插入语句：
  <pre><code>
mysql> insert into t(id,k) values(id1,k1),(id2,k2);
</code></pre>
<p>我们假设当前k索引树的状态，查找到位置后，k1所在的数据页在内存(InnoDB buffer pool)中，k2所在的数据页不在内存中。如图2所示是带change buffer的更新状态图
<img src="https://static001.geekbang.org/resource/image/98/a3/980a2b786f0ea7adabef2e64fb4c4ca3.png"/>
<p>分析这条更新语句，你会发现它涉及了四个部分：内存、redo log（ib_log_fileX）、 数据表空间（t.ibd）、系统表空间（ibdata1）。

<p>这条更新语句做了如下的操作（按照图中的数字顺序）：

<p>Page 1在内存中，直接更新内存；

<p>Page 2没有在内存中，就在内存的change buffer区域，记录下“我要往Page 2插入一行”这个信息

<p>将上述两个动作记入redo log中（图中3和4）。

<p>做完上面这些，事务就可以完成了。所以，你会看到，执行这条更新语句的成本很低，就是写了两处内存，然后写了一处磁盘（两次操作合在一起写了一次磁盘），而且还是顺序写的。

<p>同时，图中的两个虚线箭头，是后台操作，不影响更新的响应时间。

<p>这之后的读请求，要怎么处理呢?
<p>要执行 select * from t where k in (k1, k2)。这里，我画了这两个读请求的流程图。

<p>如果读语句发生在更新语句后不久，内存中的数据都还在，那么此时的这两个读操作就与系统表空间（ibdata1）和 redo log（ib_log_fileX）无关了。所以，我在图中就没画出这两部分
<img src="https://static001.geekbang.org/resource/image/6d/8e/6dc743577af1dbcbb8550bddbfc5f98e.png"/>

<p>从图中可以看到：

<li>读Page 1的时候，直接从内存返回。有几位同学在前面文章的评论中问到，WAL之后如果读数据，是不是一定要读盘，是不是一定要从redo log里面把数据更新以后才可以返回？其实是不用的。你可以看一下图3的这个状态，虽然磁盘上还是之前的数据，但是这里直接从内存返回结果，结果是正确的。

<li>要读Page 2的时候，需要把Page 2从磁盘读入内存中，然后应用change buffer里面的操作日志，生成一个正确的版本并返回结果。

<p>可以看到，直到需要读Page 2的时候，这个数据页才会被读入内存。

<p>所以，如果要简单地对比这两个机制在提升更新性能上的收益的话，redo log 主要节省的是随机写磁盘的IO消耗（转成顺序写），而change buffer主要节省的则是随机读磁盘的IO消耗。

