## 设计数据密集型应用 概要阅读笔记
                        

<img src="/src/main/resources/note/ddia/img.png">

#第一部分：数据系统基础
   
## 第一章：可靠性、可伸缩性和可维护性

<img src="/src/main/resources/note/ddia/img_1.png">

系统的分类:
+ 数据密集型（data-intensive） ,更多的是数据量、数据复杂性、以及数据的变更速度
+ 计算密集型（compute-intensive）,集中在CPU的运算

数据密集系统的通用功能:
+ 存储数据，以便自己或其他应用程序之后能再次找到 （数据库，即 databases）
+ 记住开销昂贵操作的结果，加快读取速度（缓存，即 caches）
+ 允许用户按关键字搜索数据，或以各种方式对数据进行过滤（搜索索引，即 search indexes）
+ 向其他进程发送消息，进行异步处理（流处理，即 stream processing）
+ 定期处理累积的大批量数据（批处理，即 batch processing）


<img src="/src/main/resources/note/ddia/img_2.png">

流式处理：关注实时性。kafka，storm，spark streaming，flink等
批处理：关注处理性能，不太要求实时性。MapReduce，spark.

大多数软件系统中都很重要的问题：

+ 可靠性（Reliability）系统在, 困境（adversity，比如硬件故障、软件故障、人为错误）中仍可正常工作（正确完成功能，并能达到期望的性能水准）。
+ 可伸缩性（Scalability）,有合理的办法应对系统的增长（数据量、流量、复杂性）
+ 可维护性（Maintainability）许多不同的人（工程师、运维）在不同的生命周期，都能高效地在系统上工作（使系统保持现有行为，并适应新的应用场景）


###  可靠性

可靠性: 出来了故障,也可以正常工作

常见错误,如何保证可靠 :

+ 硬件故障（hardware faults）,硬件冗余
+ 软件错误,硬件故障是随机的、相互独立的 ,但软件之间的关联非常紧密，错误往往会导致连锁的一连串故障。特定值的输入(2012 年 6 月 30 日的闰秒),特定bug,失控进程导致用尽一些共享资源,级联故障
  所以，软件容错的主要目的和方法是：提供足够的冗余信息和算法程序，使系统在实际运行时能够及时发现程序设计错误，及时采取补救措施，以提高软件可靠性，保证整个计算机系统的正常运行。主要的软件容错手段有：恢复快方法，N-版本程序设计，防卫式程序设计。
+ 人为错误 最好的系统会组合使用以下几种办法：
    - 以最小化犯错机会的方式设计系统。
    - 将人们最容易犯错的地方与可能导致失效的地方 解耦（decouple）
    - 各个层次进行彻底的测试【3】，从单元测试、全系统集成测试到手动测试 (充分的测试)
    - 允许从人为错误中简单快速地恢复，以最大限度地减少失效情况带来的影响。(快速恢复)
    - 配置详细和明确的监控，比如性能指标和错误率(详细的监控)
                                                                    

### 可伸缩性

可伸缩性（Scalability） 是用来描述系统应对负载增长能力的术语。

#### 描述负载
> 每秒向 Web 服务器发出的请求、数据库中的读写比率、聊天室中同时活跃的用户数量、缓存命中率或其他东西。

推特的两个主要业务是：

+ 发布推文  用户可以向其粉丝发布新消息（平均 4.6k 请求 / 秒，峰值超过 12k 请求 / 秒）。
+ 主页时间线  用户可以查阅他们关注的人发布的推文（300k 请求 / 秒）。

大体上讲，这一对操作有两种实现方式。

+ 发布推文时，只需将新推文插入全局推文集合即可 ,推特前期使用这个 ,但系统很难跟上主页时间线查询的负载
+ 为每个用户的主页时间线维护一个缓存，就像每个用户的推文收件箱 ,缺点是，发推现在需要大量的额外工作。

推特最终是 两种模式混合,将粉丝量巨大的,粉丝去拉取, 一般的推送

#### 3.2 描述性能
         
>批处理系统，通常关心的是 吞吐量（throughput），即每秒可以处理的记录数量，或者在特定规模数据集上运行作业的总时间 
> 对于在线系统，通常更重要的是服务的 响应时间（response time） ，即客户端发送请求到接收响应之间的时间。

#### 平均数指标 VS 百分位数指标
对于响应时间，如果想要知道更典型的响应时间，平均值并不是一个合适的指标，它无法告诉有多少用户实际经历了多少延迟。比如有100个响应，其中90个都是100ms响应，其余10个是10s响应，平均下来就是1s左右，如果以此作为响应时间的衡量指标，看起来还能接受。但是用户实际体验到的是10s响应，无法满足需求。

如果用百分位数指标，比如95%分位数，则得到95分位数响应时间是10s，技术人员就知道性能出了问题，需要改进了。


> 百分位点通常用于 服务级别目标（SLO, service level objectives） 和 服务级别协议（SLA, service level agreements），即定义服务预期性能和可用性的合同。

#### 应对负载的方法

大规模的系统架构通常没有万金油,应用的问题可能是读取量、写入量、要存储的数据量、数据的复杂度、响应时间要求、访问模式或者所有问题的大杂烩。

> 纵向伸缩,垂直伸缩，即 vertical scaling，转向更强大的机器
> 横向伸缩（scaling out，也称为水平伸缩，即 horizontal scaling，将负载分布到多台小机器上

### 可维护性

众所周知，软件的大部分开销并不在最初的开发阶段，而是在持续的维护阶段，包括修复漏洞、保持系统正常运行、调查失效、适配新的平台、为新的场景进行修改、偿还技术债、添加新的功能等等

软件系统的三个设计原则：

+ 可操作性（Operability）  便于运维团队保持系统平稳运行。
+ 简单性（Simplicity）从系统中消除尽可能多的 复杂度（complexity），使新工程师也能轻松理解系统（注意这和用户接口的简单性不一样）。
+ 可演化性（evolvability）使工程师在未来能轻松地对系统进行更改，当需求变化时为新应用场景做适配。也称为 可伸缩性（extensibility）、可修改性（modifiability） 或 可塑性（plasticity）。

#### 可操作性：人生苦短，关爱运维

“良好的运维经常可以绕开垃圾（或不完整）软件的局限性，而再好的软件摊上垃圾运维也没法可靠运行”。尽管运维的某些方面可以，而且应该是自动化的，但在最初建立正确运作的自动化机制仍然取决于人。

#### 简单性：管理复杂度

复杂度（complexity） 有各种可能的症状，例如：状态空间激增、模块间紧密耦合、纠结的依赖关系、不一致的命名和术语、解决性能问题的 Hack、需要绕开的特例等等

消除 额外复杂度 的最好工具之一是 抽象（abstraction)

高级编程语言是一种抽象，隐藏了机器码、CPU 寄存器和系统调用。 SQL 也是一种抽象，隐藏了复杂的磁盘 / 内存数据结构、来自其他客户端的并发请求、崩溃后的不一致性。

#### 可演化性：拥抱变化

修改数据系统并使其适应不断变化需求的容易程度，是与 简单性 和 抽象性 密切相关的：简单易懂的系统通常比复杂系统更容易修改。

### 小结

一个应用必须满足各种需求才称得上有用。有一些 功能需求（functional requirements，即它应该做什么，比如允许以各种方式存储，检索，搜索和处理数据）以及一些 非功能性需求（nonfunctional，即通用属性，例如安全性、可靠性、合规性、可伸缩性、兼容性和可维护性）。

+ 可靠性（Reliability） 意味着即使发生故障，系统也能正常工作。故障可能发生在硬件（通常是随机的和不相关的）、软件（通常是系统性的 Bug，很难处理）和人类（不可避免地时不时出错）。 容错技术 可以对终端用户隐藏某些类型的故障。
+ 可伸缩性（Scalability） 意味着即使在负载增加的情况下也有保持性能的策略。为了讨论可伸缩性，我们首先需要定量描述负载和性能的方法。我们简要了解了推特主页时间线的例子，介绍描述负载的方法，并将响应时间百分位点作为衡量性能的一种方式。在可伸缩的系统中可以添加 处理容量（processing capacity） 以在高负载下保持可靠。
+ 可维护性（Maintainability） 有许多方面，但实质上是关于工程师和运维团队的生活质量的。良好的抽象可以帮助降低复杂度，并使系统易于修改和适应新的应用场景。良好的可操作性意味着对系统的健康状态具有良好的可见性，并拥有有效的管理手段。


##  第二章：数据模型与查询语言

###  1.数据模型
大多数应用程序是通过一层一层叠加数据模型来构建的，每一层都面临的关键问题是：如何将其用下一层来表示？例如：

> 1. 观察现实世界，通过构建对象或数据结构，以及操作这些数据结构的API来对其建模。
2. 采用通用数据模型，存储这些数据结构。
3. 数据库工程师决定用何种内存、磁盘或网络的字节格式来表示上述数据。
4. 更下层，硬件工程师考虑如何用电流、磁场、光脉冲等来表示字节。

基本思想相同：每层都通过提供一个简洁的数据模型来隐藏下层的复杂性。这种抽象机制使得不同的人群可以高效协作。

### 2.关系模型与非关系模型

NoSQL的介绍 <a href="https://www.runoob.com/mongodb/nosql.html">Nosql</a>

<table><thead><tr><th>特性比较</th><th>关系模型</th><th>文档模型</th><th>图模型</th></tr></thead>
<tbody><tr><td>数据类型</td><td>高度组织化结构化数据</td><td>JSON或XML的文档型数据</td><td>图结构数据</td></tr>
<tr><td>查询语言</td><td>结构化查询语言&#xff08;SQL&#xff09;</td><td>非结构化查询语言&#xff08;独有&#xff09;</td><td>非结构化查询语言&#xff08;Cypher等&#xff09;</td></tr>
<tr><td>模式与联结</td><td>写时模式。数据和关系都存储在单独的表中&#xff0c;支持多表联结</td><td>无模式&#xff08;或称作读时模式&#xff09;&#xff0c;不支持多表联结。联结的工作其实从数据库转移到了应用层&#xff0c;通过对数据库进行多次查询来模拟联结</td><td>无模式&#xff08;或称作读时模式&#xff09;&#xff0c;不支持多表联结。联结的工作其实从数据库转移到了应用层&#xff0c;通过对数据库进行多次查询来模拟联结</td></tr>
<tr><td>规则</td><td>ACID&#xff0c;强一致性</td><td>CAP定理&#xff0c;弱一致性</td><td>CAP定理&#xff0c;弱一致性</td></tr><tr><td>优势</td><td>简便易学的SQL&#xff0c;强一致性&#xff0c;多表联结、多对一、多对多的表达比较简洁易懂</td><td>模式灵活性易于进行模式演变&#xff0c;局部性带来较好的查询性能&#xff0c;比较适合一对多</td><td>模型最贴近真实世界&#xff0c;支持百亿甚至千亿量级规模的巨型图的高效关系运算。由于图数据库模型的每个节点都直接包含一个关系列表&#xff0c;在定义时已经预先保存了关系&#xff0c;从而使得图数据库可以提供比关系型数据库高几个数量级的性能。对于复杂连接的查询&#xff0c;可能只有图数据库能达到响应要求。</td></tr>
<tr><td>劣势</td><td>格式要求严格&#xff0c;写时模式导致可扩展性太差。多表联结虽然操作简单&#xff0c;但是实际上是通过外键约束来实现&#xff0c;这种操作是“计算密集型”的&#xff0c;并且操作次数将是表中记录的指数级别&#xff0c;需要消耗大量的资源&#xff0c;性能太差。</td><td>查询定义语言不够标准&#xff0c;并且查询性能不高</td><td>需要预先定义好属性图结构&#xff0c;可能需要对整个图做大量计算。图遍历步数不能太深&#xff0c;超过三步性能就会急剧下降&#xff0c;这显然无法满足现实需求。</td></tr></tbody></table>

### 2.2 层次模型的局限与演化

> 层次模型：一对多，每个记录只有一个父节点。层次模型支持多对多有些困难，而且不支持联结。为了解决层次模型的局限性，提出了多种解决方案，最著名的就是：关系模型和网络模型。

>网络模型:一个记录可能有多个父节点。在网络模型中，记录之间的链接不是外键，而更像是编程语言中的指针（会存储在磁盘上）。访问记录的唯一方法是选择一条始于记录的路径，并沿着相关链接依次访问。这被称为访问路径。访问路径像是遍历列表，从链表的开头，一次查看一个记录，直到找到所需的记录。由于网络模型，一个记录可能有多个父节点，则遍历非常缓慢复杂，所以性能非常差。而手动路径选择需要大量的手写数据库查询代码，更是复杂而没有灵活性，最终导致了网络模型的失败。

> 关系模型：相比之下，关系模型所做的就简单多了，它只定义了所有数据的格式：关系（表）只是元组（行）的集合。没有复杂的嵌套结构，也没有复杂的访问路径。在关系数据库中，查询优化器自动决定以何种顺序执行查询，以及使用哪些索引。这些选择实际上等价于“访问路径”，最大的区别在于他们是由查询优化器自动生成的，而不是由应用开发人员所维护，开发人员只需懂的SQL即可，不必了解底层实现，极大降低了学习成本。这也是最终SQL称霸数据库领域的原因。

文档数据库可以认为是某种方式的层次模型（一对多关系）。

>其实在表示多对一和多对多关系时，关系数据库和文档数据库并没有根本的不同：相关项都是由唯一的标识符引用，该标识符在关系模型中被称为外键，而在文档数据库中被称为文档引用。
外键标识符可以在查询时通过联结操作来解析；文档引用标识符可以在查询时通过相关后续的多次查询来解析。

### 2.3 文档数据库的模式灵活性与数据局部性
读时模式 VS 写时模式

>文档数据库有时被称为无模式，其实更准确来说应该是“读时模式”，即数据结构是隐式的，只有在读取时才解释。读时模式类似于编程语言中的动态（运行时）类型检查。

>关系数据库被称为"写时模式"，模式是显式的，数据在写入时必须严格按照数据格式要求。写时模式类似于静态（编译时）类型检查。

文档数据库因为是读时模式，具有模式灵活性，可扩展性更强。

### 数据局部性的优缺点

优势：如果应用程序需要频繁访问整个文档或文档大部分内容，则文档数据库的数据局部性相对于关系数据库的多表联结具有性能优势，只需检索一次而无需像关系型数据库一样进行多次索引来检索所有数据。

局限性：只访问一部分时则无优势很浪费。文档更新时，通常会重写整个文档，很耗费性能。通常建议文档应该尽量小且避免写入时增加文档大小，使用原地覆盖更新。

### 2.4 MapReduce查询
MapReduce是一种编程模型，用于在许多机器上批量处理海量数据。一些NoSQL存储系统（如MongoDB 和CouchDB）支持有限的MapReduce方式在大量文档上执行只读查询。

MapReduce既不是声明式查询语言，也不是一个完全命令式的查询API，而是介于两者之间：查询的逻辑用代码片段来表示，而这些代码片段可以被处理框架重复地调用。

MapReduce查询有两个限制：

+ map和reduce函数对可执行的操作有限制，必须是纯函数。不能执行额外的数据库查询，也不能有任何副作用。
+ 可用性限制。必须编写两个函数：map和reduce函数，这两个函数必须在逻辑上密切协调，这通常比编写单个查询更难。

### 3. 图模型
如果数据大多是一对多关系（树结构模型），或者记录之间没有关系，那么文档模型是最合适的。
对于多对多关系，关系模型能够处理简单的多对多关系，但是真实世界的多对多关系是想当复杂的，随着数据之间的关联越来越复杂，图模型将是更加直观和有效的方法。

图数据库是专门为处理高度连接的数据而建立的。它有三个关键优势：
>（1）扩展性高：图中可以显示一些传统关系模式难以表达的东西。并且图有利于演化，向应用程序添加功能时，图可以容易地扩展以适应数据结构的不断变化。
（2）性能好：对于密集的数据关系处理，图数据库将性能提升了几个数量级。在传统数据库中，随着关系的数量和深度的增加，关系查询将会停止。
（3）敏捷：使用图数据库开发完全符合当今灵活的，测试驱动的开发实践。

本书中讨论了图模型中的属性图模型（property graph，以Neo4j、Titan为代表）和三元存储模型（triple-store，以Datamic、AllegroGraph为代表）

### 3.1 属性图模型和Cypher查询语言
代表的就是经典的图数据库Neo4j，有兴趣的可以参考清华大学张织老师的《Neo4j权威指南》，关于Neo4j和查询语言Cypher，介绍的非常详尽。

属性图的基本概念
>一个属性图是由顶点（vertex），边（edge），标签（label），关系类型（type of relation）和属性（property）组成的有向图。
顶点也被称为节点（node），边也被称为关系（relation）。在图形中，节点和关系是最重要的实体。所有节点都是独立存在的，通过标签来分组，相同标签的节点属于一个分组（集合）；关系通过关系类型来分组，类型相同的关系属于同一个集合。
节点可有零个，一个或多个标签，但关系有且仅有一个关系类型。
关系是有向的，关系的两端是起始节点和结束节点，通过有向的箭头来标识方向，节点之间的双向关系通过两个方向相反的关系来标识。
属性是一个键值对，每个节点或关系可以有一个或多个属性；属性值可以是标量类型或者标量类型的列表。


### 3.2 三元存储模型与SPARQL查询语言
三元存储模型其实就是RDF数据模型。

RDF数据模型
>RDF的由来。
从语义网到RDF。
语义网从本质上讲来源于一个简单而合理的想法：网站通常将信息以文字和图片方式发布给人类阅读。那么，为什么不考虑将信息发布为机器可读的格式给计算机阅读呢？ ————资源描述框架（Resource Description Framework ，RDF）就是这样一种机制，它让不同网站以一致的格式发布数据，这样来自不同网站的数据自动合并成一个数据网络，一种互联网级别的包含所有数据的数据库。

RDF的格式
RDF是一个抽象的数据模型，它有很多种RDF数据序列格式：
>（1）Turtle
（2）RDF/XML
（3）N-Triples
（4）RDFa
（5）TRIG
（6）Notation3（N3），Turtle可以认为是N3的一个子集。

RDF的定义
>（1）RDF使用web标识符来标志事物，并通过属性和属性值来描述资源。
（2）三元组：主、谓、客。
资源（主体）：是可拥有URI的任何事物。
属性（谓语）：是拥有名称的资源，用来描述资源之间的关系。比如：author，homepage等，当然也可以用URI标识，这使得万维网环境下全局性的标识资源以及资源间联系成为可能。
属性值（客体）：是某个属性的值——>第一种情况；是另一个资源——>第二种情况。
（3）陈述：资源、属性和属性值的组合可形成一个陈述，对应地，它们被称为陈述的主体、谓语、客体，表达成三元组结构。RDF图就是一个由RDF三元组构成的集合，RDF三元组可以看成是“节点——边——节点”的结构。这与万维网的图结构“文档——超链接——文档”相吻合。本质上，RDF图是节点和边均带有标签的有向图结构。

RDF 与属性图的联系与区别
>三元存储模型（RDF）几乎等同于属性图模型，只是使用不同的名词描述了相同的思想。
联系（逻辑完全一致）：RDF三元组结构，属性值第一种情况：对应属性图中顶点的定义。第二种情况：对应属性图中关系的定义。
区别（表达方法不同）：RDF图和属性图定义的结构略有不同，属性图更加直观和简单。

SPARQL查询语言

SPARQL是一种采用RDF数据模型的三元存储查询语言。它比Cypher更早，并且由于Cypher的模式匹配是借用SPARQL的，两者看起来非常相似

### 3.3 一阶谓词逻辑表示法与Datalog
Datalog的数据模型类似于三元存储模式，但更加通用一些，它采用一阶谓词逻辑：“谓语（主体，客体）”的表达方式而不是三元组（主体，谓语，客体）。

一阶谓词逻辑

一阶谓词逻辑表示法是一种重要的知识表示方法，它以数理逻辑为基础，是到目前为止能够表达人类思维活动规律的一种最精准形式语言。它与人类的自然语言比较接近，又可方便存储到计算机中去，并被计算机进行精确处理。因此，它是一种最早应用于人工智能中的表示方法。

Prolog语言

Prolog语言是以一阶谓词逻辑为理论基础的逻辑程序设计语言，是人工智能程序设计语言族中应用最广泛的一种。Prolog的基本语句有三种：事实，规则，目标。

>事实：用来说明一个问题中已知的对象和它们之间的关系，如：儿子（王健林，王思聪），表明王健林的儿子是王思聪。
规则：用来描述事实之间的依赖关系，如：bird（x）：——animal（x）, has （x，feather），表示凡是动物且有羽毛的都是鸟。
目标：向Prolog询问的问题就是程序运行的目标，如：？——student（lucy）表示lucy是学生吗？

Datalog其实是Prolog的子集。


### 3.4 图数据库与网络模型的比较

<table><thead><tr><th>特性比较</th><th>图数据库</th><th>网络模型</th></tr></thead>
<tbody><tr><td>模式</td><td>无模式&#xff08;读时模式&#xff09;</td><td>写时模式</td></tr>
<tr><td>查询方法</td><td>既可以通过顶点的唯一ID直接引用&#xff0c;也可以使用索引查找</td><td>唯一方法是遍历访问路径</td></tr>
<tr><td>查询语言</td><td>声明式</td><td>命令式</td></tr><tr><td>记录方法</td><td>顶点和边不是有序的</td><td>记录是有序集合&#xff0c;数据库必须保持这种排序&#xff08;很麻烦&#xff09;</td></tr>
<tr><td>数据结构</td><td>属性图&#xff08;顶点——边——顶点&#xff09;</td><td>父节点——子节点</td></tr></tbody></table>
<p>由对比可见&#xff0c;图数据库的网络模型从数据结构就决定了其根本不同&#xff0c;两者不可混为一谈。</p>


### 第三章：存储与检索

1. OLTP 与 OLAP
>概括来讲，存储引擎分为两大类：针对事务处理（OLTP）优化的架构，以及针对分析（OLAP）优化的架构。他们典型的访问模式存在很大差异：

OLTP系统通常面向用户，这意味着它们可能收到大量的请求。为了处理负载，应用程序通常在每个查询中只涉及少量的记录。应用程序基于某种键来请求记录，而存储引擎使用索引来查找所请求键的数据。磁盘寻道时间往往是瓶颈。

OLAP系统往往并不直接面对最终用户，它们主要由业务分析师来使用。OLAP处理的查询请求数目远低于OLTP系统，但是每个查询通常要求非常苛刻，需要在短时间内扫描数百万条记录（大数据时代，随着数据量的暴增，可能要求更大）。磁盘带宽通常是瓶颈，而面向列的存储对于这种工作负载成为日益流行的解决方案。

2. OLTP系统的存储引擎
   在OLTP方面，有两个主要流派的存储引擎：

日志结构流派：它只允许追加式更新文件和删除过时的文件，但不会修改已写入的文件。BitCask、SSTables、LSM-tree、LevelDB、Cassandra、HBase、Lucene等属于此类。日志结构存储引擎是一个相对较新的存储方案，其关键思想是：系统地将磁盘上随机访问写入转为顺序写入，由于磁盘驱动器和SSD的性能特性，可以实现更高的写入吞吐量。

更新流派：将磁盘视为可以覆盖一组固定大小的页。B-tree是这一哲学的最典型代表，传统的数据库，无论是关系型还是非关系型，绝大多数都基于此。

### 2.1 键值存储与哈希索引

#### 索引
> 1. 数据库的核心是数据结构。
2. OLTP系统为了高效地查找数据库特定键的值，需要新的数据结构：索引。
3. 索引是基于原始数据库派生而来的额外数据结构，添加或删除索引不会影响数据库的内容，只会影响查询性能。
4. 索引可以加速读取查询，但是每个索引都会减慢写速度。这涉及一种权衡。

#### 哈希索引
key-value类型并不是唯一可以索引的数据，但它随处可见，是其他更复杂索引的基础构造模块。key-value存储通常采用hash-map（或者hash-table）来实现。

#### 索引策略
假设数据存储全部采用追加式文件组成，以日志文件为例，那么最简单的哈希索引策略是：

>（1）保存内存中的hash-map，把每个键一一映射到数据文件中特定的字节偏移量，这样就能很方便的找到每个值的位置。
（2）每当在文件中追加新的key-value对时，则更新hash-map来反映刚刚写入数据的偏移量（包括插入新的键和更新已有的键）
（3）当查找某个值时，使用hash-map来找到文件中的偏移量，即存储位置，然后取其内容。

这就是Bitcask所采用的核心做法。只要所有的key可以放入内存，无论value的数据量有多大，只需一次磁盘寻址，就可以将value从磁盘加载到内存，可以提供高性能的读和写。这种存储引擎非常适合没有太多不同的key，而每个键的值频繁更新的场景，因为在这种场景下，将所有key保存在内存中是可行的。

#### 设计细节
>（1）如何避免最终用尽磁盘空间？
将日志分解成一定大小的段，当文件达到一定大小时就关闭它，并将后续写入到新的段文件中。
可以执行段压缩和多个段的合并，压缩合并的段会被写入另一个新文件。在执行压缩合并的过程中，段会被冻结，在后台线程完成压缩合并操作。此时，仍然可以用旧的段文件继续正常读取和写请求。当压缩合并完成后，将读请求切换到新的合并段上，然后旧的段文件可以安全删除。

>（2）文件格式
CSV并不是最佳的格式，最快最简单最节省内存的方法是使用二进制格式。

>（3）删除记录
如果要删除键和它关联的值，则必须在数据文件中追加一个特殊的删除记录（墓碑）。当合并段时，一旦发现墓碑标记，则会丢弃这个已删除键的所有值。

>（4）崩溃恢复
如果数据库重新启动，则内存中的hash-map将丢失。原则上，可以通过从头到尾读取整个段文件，然后记录每个键的最新值的偏移量，来恢复每个段的hash-map。但是，如果分段文件很大，可能扫描需要很长时间，这将使服务器重启变的缓慢。通过将每个段的hash-map的快照存储在磁盘上，可以更快地加载到内存中，从而加快恢复速度。

>（5）部分写入的记录
数据库将记录写入到日志的过程中，随时可能出现问题，导致写入错误。使用检验值，这样可以发现损坏部分并丢弃。

>（6）并发控制
由于写入以严格的先后顺序追加到日志中，通常写线程只能有一个，而读线程是可以并发的。


#### 问题分析
哈希索引是一个简单却非常精妙的设计，但是也有其局限性：

>（1）哈希表必须全部放入内存，但如果有大量的键，或者键需要频繁增加删除，就不太适应。

>（2）区间查询效率不高。哈希索引虽然采用顺序写，但是key值并没有排序，所以不能进行区间查询，必须采用逐个查找的方式。

### 2.2 日志结构流派

日志结构流派采用追加式更新和删除过时的文件，对比原地更新，其优势在于：

>（1）顺序写，比随机写入快得多
（2）追加式更新的段文件是追加的或不可变的，并发和崩溃恢复要简单的多。
（3）合并旧段可以避免碎片化问题。

#### LSM存储引擎（LSM-tree算法）工作流程
基于合并和压缩排序文件原理的存储引擎通常都被称为LSM存储引擎，他们基于LSM-tree算法。

>（1）当写入时，将其添加到内存中的平衡树数据结构中（例如红黑树），这个内存中的树有时被称为内存表。
（2）当内存表大于某个阈值（通常为几兆字节）时，将其作为SSTable文件写入磁盘。由于树已经维护了按键排序的key-value对，写磁盘可以比较高效。新的SSTable文件成为数据库的最新部分。当SSTable写磁盘的同时，写入可以继续添加到一个新的内存表实例。
（3）当处理读请求时，首先尝试在内存表中查找键，然后是最新的磁盘段文件，接下来是次新的磁盘段文件，以此类推，直到找到目标。（可见，这个读机制，导致读性能不佳）
（4）后台周期性地执行段合并与压缩过程，以合并多个段文件，并丢弃那些已被覆盖或删除的值。（可见，写性能高，可以支持非常高的写入吞吐量）
                                                                                                               
#### SSTable技术细节
>（1）数据按键排序如何维持？
在内存中维护排序结构是非常简单的，有很多广为人知的树状数据结构，例如红黑树或AVL树。使用这些数据结构，可以按任意顺序插入键，并以排序后的顺序读取它们。

>（2）如果数据库崩溃，最近的写入（在内存表中但尚未写入磁盘）如何处理？
在磁盘上保留单独的日志，每个写入都会立即追加到该日志。这个日志文件不需要按键排序，这不重要，它的唯一目的是在崩溃后恢复内存表。每当将内存表作为SSTable文件写入磁盘后，相应的日志可以被丢弃，以节省空间。

#### SSTable与LSM-tree
LSM-Tree（Log Structured Merge Tree，日志结构的合并树），是一种分层，有序，面向磁盘的数据结构，其核心思想是：磁盘批量的顺序写要远比随机写性能高出很多。围绕这一原理进行设计和优化，以此让写性能达到最优，正如我们普通的Log的写入方式，这种结构的写入，全部都是以Append的模式追加，不存在删除和修改。当然有得就有舍，这种结构虽然大大提升了数据的写入能力，却是以牺牲部分读取性能为代价，故此这种结构通常适合于写多读少的场景。

SSTable是一种拥有持久化，有序且不可变的的键值存储结构，它的key和value都是任意的字节数组，并且了提供了按指定key查找和指定范围的key区间迭代遍历的功能。SSTable内部包含了一系列可配置大小的Block块，典型的大小是64KB，关于这些Block块的index存储在SSTable的尾部，用于帮助快速查找特定的Block。当一个SSTable被打开的时候，index会被加载到内存，然后根据key在内存index里面进行一个二分查找，查到该key对应的磁盘的offset之后，然后去磁盘把响应的块数据读取出来。当然如果内存足够大的话，可以直接把SSTable直接通过MMap的技术映射到内存中，从而提供更快的查找。

在LSM-Tree结构里面，核心的数据结构就是SSTable。SSTable有一份在内存里面，其他的多级在磁盘上

<img src="/src/main/resources/note/ddia/img_3.png">

#### LSM-tree的缺点
>（1）由于需要不断进行压缩合并，有时会干扰正在进行的读写操作，导致读取性能更差。
（2）高写入吞吐量的同时，压缩的另一个问题就出来了：磁盘的有限写入带宽需要在初始写入（记录并刷新内存表到磁盘）和后台运行的压缩线程之间共享。数据库的数据量越大，压缩所需要的磁盘带宽就越多。
（3）如果写入吞吐量很高并且压缩没有仔细配置，那么就会发生压缩无法匹配新数据写入速率的情况。

#### LSM-tree算法优化
针对读的性能优化——布隆过滤器
如果查找的键在数据库不存在时，按照LSM-tree算法查询，必须首先检查内存表，然后将一直回溯访问到最旧的段文件，这将是一个及其耗费时间的过程。为了优化这种访问，存储引擎通常使用额外的布隆过滤器。

布隆过滤器：是一种比较巧妙的概率型数据结构。特点是能够高效的插入与查询，可以用来告诉你：“某样东西一定不存在或可能存在”，其返回结构是概率型的，而非确切的。

#### 针对写的性能优化——大小分级与分层压缩
不同的LSM存储引擎，采用的针对合并压缩的优化方式可能不一样。
LevelDB和RocksDB使用分层压缩，HBase使用大小分级，Cassandra则同时支持这两种方法。

>大小分级：将SSTable进行分级，由第一级合并成第二级，第二级再合并成第三级…依次进行下去。当内存数据达到一定大小时，会将数据排序写入磁盘生成一个SSTable文件，这是第一级的SSTable文件。当第一级的SSTable文件达到m（一般为4）个时，将这m个第一级的SSTable文件合并成一个第二级的SSTable，同理，依次进行下去。

>分层压缩：将数据分层，最底层为L0，其上分别是L1，L2，L3…每一层的数据级差为10。层数越小的块，其保存的数据越少也越新。这种分层压缩的优势是同一层的块之间没有重复数据。因为层间的合并，都是将所有数据块都合并。如L0层数据每次都是与L1层数据合并，生成新的L1层。


#### 2.3 更新流派
更新流派的代表就是：B-tree。

>（1）B-tree像SSTable一样，保留按键排序的key-value对，这样可以实现高效的key-value查询和区间查询。
（2）但是在本质上，B-tree具有非常不同的设计。日志结构索引将数据库分解成可变大小的段，通常大小为几兆字节或更大，并且始终按顺序写入段。而B-tree将数据库分解成固定大小的块或页（传统上大小为4KB），页是内部读/写的最小单元。这种设计更接近底层硬件，因为硬盘也是以固定大小的块排列。

#### B-tree设计细节
#### 使用B-tree索引查找
>B-tree的基本单位是页，每个页面可以使用地址或者位置进行标识，这样可以让一个页面引用另一个页面。这类似指针，不过是指向磁盘地址，而不是内存。通过页面引用可以构造一个树状页面。
某一页被指定为B-tree的根，每当查找索引中的一个键时，总是从这里开始。该页面包含若干个键和对子页的引用。每个孩子都负责一个连续范围内的键，相邻引用之间的键可以指示这些范围之间的边界。

#### 添加新键与插入分裂
如果要添加新键，则需要找到其范围包含新键的页，并将其添加到该页。如果页中没有足够的可用空间来容纳新键，则将其分裂为两个半满的页，并且父页页需要更新以包含分裂之后的新的键范围。

这种算法是分析和理解B-tree结构的关键：B-tree始终要保持树平衡，从而使树深保持在O(log n)。因此， B-tree的读和查找效率很高，而写效率一般。

#### B-tree（更新）带来的三大问题
>（1）B-tree底层的基本写操作是使用新数据覆盖磁盘上的旧页。遵循的原则是：覆盖不会改变页的磁盘存储位置，也就是说，当页被覆盖时，对该页的所有引用保持不变。
对于SSD，由于SSD必须一次擦除并重写非常大的存储芯片块，情况会更加复杂。例如插入导致页溢出的情况，需要分裂页，从而写两个分裂的页，并且覆盖其父页以更新对两个子页的引用。这个操作非常危险，因为如果数据库在完成部分写入后发生崩溃，最终会导致索引破坏（可能产生孤儿页）。

>（2）为了使数据库能从崩溃中恢复，常见B-tree的实现需要支持磁盘上的额外数据结构：预写日志（write-ahead log，WAL），也称为重做日志。

>（3）原地更新页的另一个复杂因素是：如果多个线程要同时访问B-tree，则需要注意并发控制。否则线程可能会看到树处于不一致的状态。


#### B-tree优化措施
（1）写时复制方案：不使用覆盖页和维护WAL来进行崩溃恢复。修改的页被写入不同的位置，树中父页的新版本被创建，并指向新的位置。
（2）保存键的缩略信息，而不是完整的键。从而可以将更多的键压入到页中，让树具有更高的分支因子，从而减少层数。
（3）添加额外的指针到树中。例如，每个叶子页面可能会向左和向右引用其同级别的兄弟页，这样可以顺序扫描键，而不用跳回到父页。

### 2.4 LSM-tree与B-tree的对比
从总体性能来说，LSM-tree通常写入更快，而B-tree被认为读取更快。
<table><thead><tr><th>特性比较</th><th>LSM-tree</th><th>B-tree</th></tr></thead><tbody>
<tr><td>读取性能</td><td>读取性能不佳。因为采用追加更新&#xff0c;可能在不同段中具有相同键的多个副本&#xff0c;因此查找需要一直查下去&#xff1a;首先尝试在内存表中查找键&#xff0c;然后是最新的磁盘段文件&#xff0c;接下来是次新的磁盘段文件&#xff0c;以此类推&#xff0c;直到找到目标或为空</td><td>读取性能更好。采用原地更新&#xff0c;每个键都恰好对应索引中的某个位置。B-tree始终要保持树平衡&#xff0c;从而使树深保持在O(log n)&#xff0c;查询很快。</td></tr>
<tr><td>写入性能</td><td>更低的写放大&#xff0c;定期重写SSTable以消除碎片化&#xff0c;从而具有更高的写入性能</td><td>B-tree的原地覆盖更新&#xff0c;导致即使某个页中只有几个字节更改&#xff0c;也必须承受写整个页的开销&#xff0c;写放大很大。并且极易产生碎片&#xff0c;导致某些磁盘空间无法使用。写性能不佳。</td></tr></tbody></table>


