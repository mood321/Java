## 设计数据密集型应用 概要阅读笔记
                        

<img src="/src/main/resources/note/ddia/img.png">

#第一部分：数据系统基础
   
## 第一章：可靠性、可伸缩性和可维护性

<img src="/src/main/resources/note/ddia/img_1.png">

系统的分类:
+ 数据密集型（data-intensive） ,更多的是数据量、数据复杂性、以及数据的变更速度
+ 计算密集型（compute-intensive）,集中在CPU的运算

数据密集系统的通用功能:
+ 存储数据，以便自己或其他应用程序之后能再次找到 （数据库，即 databases）
+ 记住开销昂贵操作的结果，加快读取速度（缓存，即 caches）
+ 允许用户按关键字搜索数据，或以各种方式对数据进行过滤（搜索索引，即 search indexes）
+ 向其他进程发送消息，进行异步处理（流处理，即 stream processing）
+ 定期处理累积的大批量数据（批处理，即 batch processing）


<img src="/src/main/resources/note/ddia/img_2.png">

流式处理：关注实时性。kafka，storm，spark streaming，flink等
批处理：关注处理性能，不太要求实时性。MapReduce，spark.

大多数软件系统中都很重要的问题：

+ 可靠性（Reliability）系统在, 困境（adversity，比如硬件故障、软件故障、人为错误）中仍可正常工作（正确完成功能，并能达到期望的性能水准）。
+ 可伸缩性（Scalability）,有合理的办法应对系统的增长（数据量、流量、复杂性）
+ 可维护性（Maintainability）许多不同的人（工程师、运维）在不同的生命周期，都能高效地在系统上工作（使系统保持现有行为，并适应新的应用场景）


###  可靠性

可靠性: 出来了故障,也可以正常工作

常见错误,如何保证可靠 :

+ 硬件故障（hardware faults）,硬件冗余
+ 软件错误,硬件故障是随机的、相互独立的 ,但软件之间的关联非常紧密，错误往往会导致连锁的一连串故障。特定值的输入(2012 年 6 月 30 日的闰秒),特定bug,失控进程导致用尽一些共享资源,级联故障
  所以，软件容错的主要目的和方法是：提供足够的冗余信息和算法程序，使系统在实际运行时能够及时发现程序设计错误，及时采取补救措施，以提高软件可靠性，保证整个计算机系统的正常运行。主要的软件容错手段有：恢复快方法，N-版本程序设计，防卫式程序设计。
+ 人为错误 最好的系统会组合使用以下几种办法：
    - 以最小化犯错机会的方式设计系统。
    - 将人们最容易犯错的地方与可能导致失效的地方 解耦（decouple）
    - 各个层次进行彻底的测试【3】，从单元测试、全系统集成测试到手动测试 (充分的测试)
    - 允许从人为错误中简单快速地恢复，以最大限度地减少失效情况带来的影响。(快速恢复)
    - 配置详细和明确的监控，比如性能指标和错误率(详细的监控)
                                                                    

### 可伸缩性

可伸缩性（Scalability） 是用来描述系统应对负载增长能力的术语。

#### 描述负载
> 每秒向 Web 服务器发出的请求、数据库中的读写比率、聊天室中同时活跃的用户数量、缓存命中率或其他东西。

推特的两个主要业务是：

+ 发布推文  用户可以向其粉丝发布新消息（平均 4.6k 请求 / 秒，峰值超过 12k 请求 / 秒）。
+ 主页时间线  用户可以查阅他们关注的人发布的推文（300k 请求 / 秒）。

大体上讲，这一对操作有两种实现方式。

+ 发布推文时，只需将新推文插入全局推文集合即可 ,推特前期使用这个 ,但系统很难跟上主页时间线查询的负载
+ 为每个用户的主页时间线维护一个缓存，就像每个用户的推文收件箱 ,缺点是，发推现在需要大量的额外工作。

推特最终是 两种模式混合,将粉丝量巨大的,粉丝去拉取, 一般的推送

#### 3.2 描述性能
         
>批处理系统，通常关心的是 吞吐量（throughput），即每秒可以处理的记录数量，或者在特定规模数据集上运行作业的总时间 
> 对于在线系统，通常更重要的是服务的 响应时间（response time） ，即客户端发送请求到接收响应之间的时间。

#### 平均数指标 VS 百分位数指标
对于响应时间，如果想要知道更典型的响应时间，平均值并不是一个合适的指标，它无法告诉有多少用户实际经历了多少延迟。比如有100个响应，其中90个都是100ms响应，其余10个是10s响应，平均下来就是1s左右，如果以此作为响应时间的衡量指标，看起来还能接受。但是用户实际体验到的是10s响应，无法满足需求。

如果用百分位数指标，比如95%分位数，则得到95分位数响应时间是10s，技术人员就知道性能出了问题，需要改进了。


> 百分位点通常用于 服务级别目标（SLO, service level objectives） 和 服务级别协议（SLA, service level agreements），即定义服务预期性能和可用性的合同。

#### 应对负载的方法

大规模的系统架构通常没有万金油,应用的问题可能是读取量、写入量、要存储的数据量、数据的复杂度、响应时间要求、访问模式或者所有问题的大杂烩。

> 纵向伸缩,垂直伸缩，即 vertical scaling，转向更强大的机器
> 横向伸缩（scaling out，也称为水平伸缩，即 horizontal scaling，将负载分布到多台小机器上

### 可维护性

众所周知，软件的大部分开销并不在最初的开发阶段，而是在持续的维护阶段，包括修复漏洞、保持系统正常运行、调查失效、适配新的平台、为新的场景进行修改、偿还技术债、添加新的功能等等

软件系统的三个设计原则：

+ 可操作性（Operability）  便于运维团队保持系统平稳运行。
+ 简单性（Simplicity）从系统中消除尽可能多的 复杂度（complexity），使新工程师也能轻松理解系统（注意这和用户接口的简单性不一样）。
+ 可演化性（evolvability）使工程师在未来能轻松地对系统进行更改，当需求变化时为新应用场景做适配。也称为 可伸缩性（extensibility）、可修改性（modifiability） 或 可塑性（plasticity）。

#### 可操作性：人生苦短，关爱运维

“良好的运维经常可以绕开垃圾（或不完整）软件的局限性，而再好的软件摊上垃圾运维也没法可靠运行”。尽管运维的某些方面可以，而且应该是自动化的，但在最初建立正确运作的自动化机制仍然取决于人。

#### 简单性：管理复杂度

复杂度（complexity） 有各种可能的症状，例如：状态空间激增、模块间紧密耦合、纠结的依赖关系、不一致的命名和术语、解决性能问题的 Hack、需要绕开的特例等等

消除 额外复杂度 的最好工具之一是 抽象（abstraction)

高级编程语言是一种抽象，隐藏了机器码、CPU 寄存器和系统调用。 SQL 也是一种抽象，隐藏了复杂的磁盘 / 内存数据结构、来自其他客户端的并发请求、崩溃后的不一致性。

#### 可演化性：拥抱变化

修改数据系统并使其适应不断变化需求的容易程度，是与 简单性 和 抽象性 密切相关的：简单易懂的系统通常比复杂系统更容易修改。

### 小结

一个应用必须满足各种需求才称得上有用。有一些 功能需求（functional requirements，即它应该做什么，比如允许以各种方式存储，检索，搜索和处理数据）以及一些 非功能性需求（nonfunctional，即通用属性，例如安全性、可靠性、合规性、可伸缩性、兼容性和可维护性）。

+ 可靠性（Reliability） 意味着即使发生故障，系统也能正常工作。故障可能发生在硬件（通常是随机的和不相关的）、软件（通常是系统性的 Bug，很难处理）和人类（不可避免地时不时出错）。 容错技术 可以对终端用户隐藏某些类型的故障。
+ 可伸缩性（Scalability） 意味着即使在负载增加的情况下也有保持性能的策略。为了讨论可伸缩性，我们首先需要定量描述负载和性能的方法。我们简要了解了推特主页时间线的例子，介绍描述负载的方法，并将响应时间百分位点作为衡量性能的一种方式。在可伸缩的系统中可以添加 处理容量（processing capacity） 以在高负载下保持可靠。
+ 可维护性（Maintainability） 有许多方面，但实质上是关于工程师和运维团队的生活质量的。良好的抽象可以帮助降低复杂度，并使系统易于修改和适应新的应用场景。良好的可操作性意味着对系统的健康状态具有良好的可见性，并拥有有效的管理手段。


##  第二章：数据模型与查询语言

###  1.数据模型
大多数应用程序是通过一层一层叠加数据模型来构建的，每一层都面临的关键问题是：如何将其用下一层来表示？例如：

> 1. 观察现实世界，通过构建对象或数据结构，以及操作这些数据结构的API来对其建模。
2. 采用通用数据模型，存储这些数据结构。
3. 数据库工程师决定用何种内存、磁盘或网络的字节格式来表示上述数据。
4. 更下层，硬件工程师考虑如何用电流、磁场、光脉冲等来表示字节。

基本思想相同：每层都通过提供一个简洁的数据模型来隐藏下层的复杂性。这种抽象机制使得不同的人群可以高效协作。

### 2.关系模型与非关系模型

NoSQL的介绍 <a href="https://www.runoob.com/mongodb/nosql.html">Nosql</a>

<table><thead><tr><th>特性比较</th><th>关系模型</th><th>文档模型</th><th>图模型</th></tr></thead>
<tbody><tr><td>数据类型</td><td>高度组织化结构化数据</td><td>JSON或XML的文档型数据</td><td>图结构数据</td></tr>
<tr><td>查询语言</td><td>结构化查询语言&#xff08;SQL&#xff09;</td><td>非结构化查询语言&#xff08;独有&#xff09;</td><td>非结构化查询语言&#xff08;Cypher等&#xff09;</td></tr>
<tr><td>模式与联结</td><td>写时模式。数据和关系都存储在单独的表中&#xff0c;支持多表联结</td><td>无模式&#xff08;或称作读时模式&#xff09;&#xff0c;不支持多表联结。联结的工作其实从数据库转移到了应用层&#xff0c;通过对数据库进行多次查询来模拟联结</td><td>无模式&#xff08;或称作读时模式&#xff09;&#xff0c;不支持多表联结。联结的工作其实从数据库转移到了应用层&#xff0c;通过对数据库进行多次查询来模拟联结</td></tr>
<tr><td>规则</td><td>ACID&#xff0c;强一致性</td><td>CAP定理&#xff0c;弱一致性</td><td>CAP定理&#xff0c;弱一致性</td></tr><tr><td>优势</td><td>简便易学的SQL&#xff0c;强一致性&#xff0c;多表联结、多对一、多对多的表达比较简洁易懂</td><td>模式灵活性易于进行模式演变&#xff0c;局部性带来较好的查询性能&#xff0c;比较适合一对多</td><td>模型最贴近真实世界&#xff0c;支持百亿甚至千亿量级规模的巨型图的高效关系运算。由于图数据库模型的每个节点都直接包含一个关系列表&#xff0c;在定义时已经预先保存了关系&#xff0c;从而使得图数据库可以提供比关系型数据库高几个数量级的性能。对于复杂连接的查询&#xff0c;可能只有图数据库能达到响应要求。</td></tr>
<tr><td>劣势</td><td>格式要求严格&#xff0c;写时模式导致可扩展性太差。多表联结虽然操作简单&#xff0c;但是实际上是通过外键约束来实现&#xff0c;这种操作是“计算密集型”的&#xff0c;并且操作次数将是表中记录的指数级别&#xff0c;需要消耗大量的资源&#xff0c;性能太差。</td><td>查询定义语言不够标准&#xff0c;并且查询性能不高</td><td>需要预先定义好属性图结构&#xff0c;可能需要对整个图做大量计算。图遍历步数不能太深&#xff0c;超过三步性能就会急剧下降&#xff0c;这显然无法满足现实需求。</td></tr></tbody></table>

### 2.2 层次模型的局限与演化

> 层次模型：一对多，每个记录只有一个父节点。层次模型支持多对多有些困难，而且不支持联结。为了解决层次模型的局限性，提出了多种解决方案，最著名的就是：关系模型和网络模型。

>网络模型:一个记录可能有多个父节点。在网络模型中，记录之间的链接不是外键，而更像是编程语言中的指针（会存储在磁盘上）。访问记录的唯一方法是选择一条始于记录的路径，并沿着相关链接依次访问。这被称为访问路径。访问路径像是遍历列表，从链表的开头，一次查看一个记录，直到找到所需的记录。由于网络模型，一个记录可能有多个父节点，则遍历非常缓慢复杂，所以性能非常差。而手动路径选择需要大量的手写数据库查询代码，更是复杂而没有灵活性，最终导致了网络模型的失败。

> 关系模型：相比之下，关系模型所做的就简单多了，它只定义了所有数据的格式：关系（表）只是元组（行）的集合。没有复杂的嵌套结构，也没有复杂的访问路径。在关系数据库中，查询优化器自动决定以何种顺序执行查询，以及使用哪些索引。这些选择实际上等价于“访问路径”，最大的区别在于他们是由查询优化器自动生成的，而不是由应用开发人员所维护，开发人员只需懂的SQL即可，不必了解底层实现，极大降低了学习成本。这也是最终SQL称霸数据库领域的原因。

文档数据库可以认为是某种方式的层次模型（一对多关系）。

>其实在表示多对一和多对多关系时，关系数据库和文档数据库并没有根本的不同：相关项都是由唯一的标识符引用，该标识符在关系模型中被称为外键，而在文档数据库中被称为文档引用。
外键标识符可以在查询时通过联结操作来解析；文档引用标识符可以在查询时通过相关后续的多次查询来解析。

### 2.3 文档数据库的模式灵活性与数据局部性
读时模式 VS 写时模式

>文档数据库有时被称为无模式，其实更准确来说应该是“读时模式”，即数据结构是隐式的，只有在读取时才解释。读时模式类似于编程语言中的动态（运行时）类型检查。

>关系数据库被称为"写时模式"，模式是显式的，数据在写入时必须严格按照数据格式要求。写时模式类似于静态（编译时）类型检查。

文档数据库因为是读时模式，具有模式灵活性，可扩展性更强。

### 数据局部性的优缺点

优势：如果应用程序需要频繁访问整个文档或文档大部分内容，则文档数据库的数据局部性相对于关系数据库的多表联结具有性能优势，只需检索一次而无需像关系型数据库一样进行多次索引来检索所有数据。

局限性：只访问一部分时则无优势很浪费。文档更新时，通常会重写整个文档，很耗费性能。通常建议文档应该尽量小且避免写入时增加文档大小，使用原地覆盖更新。

### 2.4 MapReduce查询
MapReduce是一种编程模型，用于在许多机器上批量处理海量数据。一些NoSQL存储系统（如MongoDB 和CouchDB）支持有限的MapReduce方式在大量文档上执行只读查询。

MapReduce既不是声明式查询语言，也不是一个完全命令式的查询API，而是介于两者之间：查询的逻辑用代码片段来表示，而这些代码片段可以被处理框架重复地调用。

MapReduce查询有两个限制：

+ map和reduce函数对可执行的操作有限制，必须是纯函数。不能执行额外的数据库查询，也不能有任何副作用。
+ 可用性限制。必须编写两个函数：map和reduce函数，这两个函数必须在逻辑上密切协调，这通常比编写单个查询更难。

### 3. 图模型
如果数据大多是一对多关系（树结构模型），或者记录之间没有关系，那么文档模型是最合适的。
对于多对多关系，关系模型能够处理简单的多对多关系，但是真实世界的多对多关系是想当复杂的，随着数据之间的关联越来越复杂，图模型将是更加直观和有效的方法。

图数据库是专门为处理高度连接的数据而建立的。它有三个关键优势：
>（1）扩展性高：图中可以显示一些传统关系模式难以表达的东西。并且图有利于演化，向应用程序添加功能时，图可以容易地扩展以适应数据结构的不断变化。
（2）性能好：对于密集的数据关系处理，图数据库将性能提升了几个数量级。在传统数据库中，随着关系的数量和深度的增加，关系查询将会停止。
（3）敏捷：使用图数据库开发完全符合当今灵活的，测试驱动的开发实践。

本书中讨论了图模型中的属性图模型（property graph，以Neo4j、Titan为代表）和三元存储模型（triple-store，以Datamic、AllegroGraph为代表）

### 3.1 属性图模型和Cypher查询语言
代表的就是经典的图数据库Neo4j，有兴趣的可以参考清华大学张织老师的《Neo4j权威指南》，关于Neo4j和查询语言Cypher，介绍的非常详尽。

属性图的基本概念
>一个属性图是由顶点（vertex），边（edge），标签（label），关系类型（type of relation）和属性（property）组成的有向图。
顶点也被称为节点（node），边也被称为关系（relation）。在图形中，节点和关系是最重要的实体。所有节点都是独立存在的，通过标签来分组，相同标签的节点属于一个分组（集合）；关系通过关系类型来分组，类型相同的关系属于同一个集合。
节点可有零个，一个或多个标签，但关系有且仅有一个关系类型。
关系是有向的，关系的两端是起始节点和结束节点，通过有向的箭头来标识方向，节点之间的双向关系通过两个方向相反的关系来标识。
属性是一个键值对，每个节点或关系可以有一个或多个属性；属性值可以是标量类型或者标量类型的列表。


### 3.2 三元存储模型与SPARQL查询语言
三元存储模型其实就是RDF数据模型。

RDF数据模型
>RDF的由来。
从语义网到RDF。
语义网从本质上讲来源于一个简单而合理的想法：网站通常将信息以文字和图片方式发布给人类阅读。那么，为什么不考虑将信息发布为机器可读的格式给计算机阅读呢？ ————资源描述框架（Resource Description Framework ，RDF）就是这样一种机制，它让不同网站以一致的格式发布数据，这样来自不同网站的数据自动合并成一个数据网络，一种互联网级别的包含所有数据的数据库。

RDF的格式
RDF是一个抽象的数据模型，它有很多种RDF数据序列格式：
>（1）Turtle
（2）RDF/XML
（3）N-Triples
（4）RDFa
（5）TRIG
（6）Notation3（N3），Turtle可以认为是N3的一个子集。

RDF的定义
>（1）RDF使用web标识符来标志事物，并通过属性和属性值来描述资源。
（2）三元组：主、谓、客。
资源（主体）：是可拥有URI的任何事物。
属性（谓语）：是拥有名称的资源，用来描述资源之间的关系。比如：author，homepage等，当然也可以用URI标识，这使得万维网环境下全局性的标识资源以及资源间联系成为可能。
属性值（客体）：是某个属性的值——>第一种情况；是另一个资源——>第二种情况。
（3）陈述：资源、属性和属性值的组合可形成一个陈述，对应地，它们被称为陈述的主体、谓语、客体，表达成三元组结构。RDF图就是一个由RDF三元组构成的集合，RDF三元组可以看成是“节点——边——节点”的结构。这与万维网的图结构“文档——超链接——文档”相吻合。本质上，RDF图是节点和边均带有标签的有向图结构。

RDF 与属性图的联系与区别
>三元存储模型（RDF）几乎等同于属性图模型，只是使用不同的名词描述了相同的思想。
联系（逻辑完全一致）：RDF三元组结构，属性值第一种情况：对应属性图中顶点的定义。第二种情况：对应属性图中关系的定义。
区别（表达方法不同）：RDF图和属性图定义的结构略有不同，属性图更加直观和简单。

SPARQL查询语言

SPARQL是一种采用RDF数据模型的三元存储查询语言。它比Cypher更早，并且由于Cypher的模式匹配是借用SPARQL的，两者看起来非常相似

### 3.3 一阶谓词逻辑表示法与Datalog
Datalog的数据模型类似于三元存储模式，但更加通用一些，它采用一阶谓词逻辑：“谓语（主体，客体）”的表达方式而不是三元组（主体，谓语，客体）。

一阶谓词逻辑

一阶谓词逻辑表示法是一种重要的知识表示方法，它以数理逻辑为基础，是到目前为止能够表达人类思维活动规律的一种最精准形式语言。它与人类的自然语言比较接近，又可方便存储到计算机中去，并被计算机进行精确处理。因此，它是一种最早应用于人工智能中的表示方法。

Prolog语言

Prolog语言是以一阶谓词逻辑为理论基础的逻辑程序设计语言，是人工智能程序设计语言族中应用最广泛的一种。Prolog的基本语句有三种：事实，规则，目标。

>事实：用来说明一个问题中已知的对象和它们之间的关系，如：儿子（王健林，王思聪），表明王健林的儿子是王思聪。
规则：用来描述事实之间的依赖关系，如：bird（x）：——animal（x）, has （x，feather），表示凡是动物且有羽毛的都是鸟。
目标：向Prolog询问的问题就是程序运行的目标，如：？——student（lucy）表示lucy是学生吗？

Datalog其实是Prolog的子集。


### 3.4 图数据库与网络模型的比较

<table><thead><tr><th>特性比较</th><th>图数据库</th><th>网络模型</th></tr></thead>
<tbody><tr><td>模式</td><td>无模式&#xff08;读时模式&#xff09;</td><td>写时模式</td></tr>
<tr><td>查询方法</td><td>既可以通过顶点的唯一ID直接引用&#xff0c;也可以使用索引查找</td><td>唯一方法是遍历访问路径</td></tr>
<tr><td>查询语言</td><td>声明式</td><td>命令式</td></tr><tr><td>记录方法</td><td>顶点和边不是有序的</td><td>记录是有序集合&#xff0c;数据库必须保持这种排序&#xff08;很麻烦&#xff09;</td></tr>
<tr><td>数据结构</td><td>属性图&#xff08;顶点——边——顶点&#xff09;</td><td>父节点——子节点</td></tr></tbody></table>
<p>由对比可见&#xff0c;图数据库的网络模型从数据结构就决定了其根本不同&#xff0c;两者不可混为一谈。</p>


### 第三章：存储与检索

1. OLTP 与 OLAP
>概括来讲，存储引擎分为两大类：针对事务处理（OLTP）优化的架构，以及针对分析（OLAP）优化的架构。他们典型的访问模式存在很大差异：

OLTP系统通常面向用户，这意味着它们可能收到大量的请求。为了处理负载，应用程序通常在每个查询中只涉及少量的记录。应用程序基于某种键来请求记录，而存储引擎使用索引来查找所请求键的数据。磁盘寻道时间往往是瓶颈。

OLAP系统往往并不直接面对最终用户，它们主要由业务分析师来使用。OLAP处理的查询请求数目远低于OLTP系统，但是每个查询通常要求非常苛刻，需要在短时间内扫描数百万条记录（大数据时代，随着数据量的暴增，可能要求更大）。磁盘带宽通常是瓶颈，而面向列的存储对于这种工作负载成为日益流行的解决方案。

2. OLTP系统的存储引擎
   在OLTP方面，有两个主要流派的存储引擎：

日志结构流派：它只允许追加式更新文件和删除过时的文件，但不会修改已写入的文件。BitCask、SSTables、LSM-tree、LevelDB、Cassandra、HBase、Lucene等属于此类。日志结构存储引擎是一个相对较新的存储方案，其关键思想是：系统地将磁盘上随机访问写入转为顺序写入，由于磁盘驱动器和SSD的性能特性，可以实现更高的写入吞吐量。

更新流派：将磁盘视为可以覆盖一组固定大小的页。B-tree是这一哲学的最典型代表，传统的数据库，无论是关系型还是非关系型，绝大多数都基于此。

### 2.1 键值存储与哈希索引

#### 索引
> 1. 数据库的核心是数据结构。
2. OLTP系统为了高效地查找数据库特定键的值，需要新的数据结构：索引。
3. 索引是基于原始数据库派生而来的额外数据结构，添加或删除索引不会影响数据库的内容，只会影响查询性能。
4. 索引可以加速读取查询，但是每个索引都会减慢写速度。这涉及一种权衡。

#### 哈希索引
key-value类型并不是唯一可以索引的数据，但它随处可见，是其他更复杂索引的基础构造模块。key-value存储通常采用hash-map（或者hash-table）来实现。

#### 索引策略
假设数据存储全部采用追加式文件组成，以日志文件为例，那么最简单的哈希索引策略是：

>（1）保存内存中的hash-map，把每个键一一映射到数据文件中特定的字节偏移量，这样就能很方便的找到每个值的位置。
（2）每当在文件中追加新的key-value对时，则更新hash-map来反映刚刚写入数据的偏移量（包括插入新的键和更新已有的键）
（3）当查找某个值时，使用hash-map来找到文件中的偏移量，即存储位置，然后取其内容。

这就是Bitcask所采用的核心做法。只要所有的key可以放入内存，无论value的数据量有多大，只需一次磁盘寻址，就可以将value从磁盘加载到内存，可以提供高性能的读和写。这种存储引擎非常适合没有太多不同的key，而每个键的值频繁更新的场景，因为在这种场景下，将所有key保存在内存中是可行的。

#### 设计细节
>（1）如何避免最终用尽磁盘空间？
将日志分解成一定大小的段，当文件达到一定大小时就关闭它，并将后续写入到新的段文件中。
可以执行段压缩和多个段的合并，压缩合并的段会被写入另一个新文件。在执行压缩合并的过程中，段会被冻结，在后台线程完成压缩合并操作。此时，仍然可以用旧的段文件继续正常读取和写请求。当压缩合并完成后，将读请求切换到新的合并段上，然后旧的段文件可以安全删除。

>（2）文件格式
CSV并不是最佳的格式，最快最简单最节省内存的方法是使用二进制格式。

>（3）删除记录
如果要删除键和它关联的值，则必须在数据文件中追加一个特殊的删除记录（墓碑）。当合并段时，一旦发现墓碑标记，则会丢弃这个已删除键的所有值。

>（4）崩溃恢复
如果数据库重新启动，则内存中的hash-map将丢失。原则上，可以通过从头到尾读取整个段文件，然后记录每个键的最新值的偏移量，来恢复每个段的hash-map。但是，如果分段文件很大，可能扫描需要很长时间，这将使服务器重启变的缓慢。通过将每个段的hash-map的快照存储在磁盘上，可以更快地加载到内存中，从而加快恢复速度。

>（5）部分写入的记录
数据库将记录写入到日志的过程中，随时可能出现问题，导致写入错误。使用检验值，这样可以发现损坏部分并丢弃。

>（6）并发控制
由于写入以严格的先后顺序追加到日志中，通常写线程只能有一个，而读线程是可以并发的。


#### 问题分析
哈希索引是一个简单却非常精妙的设计，但是也有其局限性：

>（1）哈希表必须全部放入内存，但如果有大量的键，或者键需要频繁增加删除，就不太适应。

>（2）区间查询效率不高。哈希索引虽然采用顺序写，但是key值并没有排序，所以不能进行区间查询，必须采用逐个查找的方式。

### 2.2 日志结构流派

日志结构流派采用追加式更新和删除过时的文件，对比原地更新，其优势在于：

>（1）顺序写，比随机写入快得多
（2）追加式更新的段文件是追加的或不可变的，并发和崩溃恢复要简单的多。
（3）合并旧段可以避免碎片化问题。

#### LSM存储引擎（LSM-tree算法）工作流程
基于合并和压缩排序文件原理的存储引擎通常都被称为LSM存储引擎，他们基于LSM-tree算法。

>（1）当写入时，将其添加到内存中的平衡树数据结构中（例如红黑树），这个内存中的树有时被称为内存表。
（2）当内存表大于某个阈值（通常为几兆字节）时，将其作为SSTable文件写入磁盘。由于树已经维护了按键排序的key-value对，写磁盘可以比较高效。新的SSTable文件成为数据库的最新部分。当SSTable写磁盘的同时，写入可以继续添加到一个新的内存表实例。
（3）当处理读请求时，首先尝试在内存表中查找键，然后是最新的磁盘段文件，接下来是次新的磁盘段文件，以此类推，直到找到目标。（可见，这个读机制，导致读性能不佳）
（4）后台周期性地执行段合并与压缩过程，以合并多个段文件，并丢弃那些已被覆盖或删除的值。（可见，写性能高，可以支持非常高的写入吞吐量）
                                                                                                               
#### SSTable技术细节
>（1）数据按键排序如何维持？
在内存中维护排序结构是非常简单的，有很多广为人知的树状数据结构，例如红黑树或AVL树。使用这些数据结构，可以按任意顺序插入键，并以排序后的顺序读取它们。

>（2）如果数据库崩溃，最近的写入（在内存表中但尚未写入磁盘）如何处理？
在磁盘上保留单独的日志，每个写入都会立即追加到该日志。这个日志文件不需要按键排序，这不重要，它的唯一目的是在崩溃后恢复内存表。每当将内存表作为SSTable文件写入磁盘后，相应的日志可以被丢弃，以节省空间。

#### SSTable与LSM-tree
LSM-Tree（Log Structured Merge Tree，日志结构的合并树），是一种分层，有序，面向磁盘的数据结构，其核心思想是：磁盘批量的顺序写要远比随机写性能高出很多。围绕这一原理进行设计和优化，以此让写性能达到最优，正如我们普通的Log的写入方式，这种结构的写入，全部都是以Append的模式追加，不存在删除和修改。当然有得就有舍，这种结构虽然大大提升了数据的写入能力，却是以牺牲部分读取性能为代价，故此这种结构通常适合于写多读少的场景。

SSTable是一种拥有持久化，有序且不可变的的键值存储结构，它的key和value都是任意的字节数组，并且了提供了按指定key查找和指定范围的key区间迭代遍历的功能。SSTable内部包含了一系列可配置大小的Block块，典型的大小是64KB，关于这些Block块的index存储在SSTable的尾部，用于帮助快速查找特定的Block。当一个SSTable被打开的时候，index会被加载到内存，然后根据key在内存index里面进行一个二分查找，查到该key对应的磁盘的offset之后，然后去磁盘把响应的块数据读取出来。当然如果内存足够大的话，可以直接把SSTable直接通过MMap的技术映射到内存中，从而提供更快的查找。

在LSM-Tree结构里面，核心的数据结构就是SSTable。SSTable有一份在内存里面，其他的多级在磁盘上

<img src="/src/main/resources/note/ddia/img_3.png">

#### LSM-tree的缺点
>（1）由于需要不断进行压缩合并，有时会干扰正在进行的读写操作，导致读取性能更差。
（2）高写入吞吐量的同时，压缩的另一个问题就出来了：磁盘的有限写入带宽需要在初始写入（记录并刷新内存表到磁盘）和后台运行的压缩线程之间共享。数据库的数据量越大，压缩所需要的磁盘带宽就越多。
（3）如果写入吞吐量很高并且压缩没有仔细配置，那么就会发生压缩无法匹配新数据写入速率的情况。

#### LSM-tree算法优化
针对读的性能优化——布隆过滤器
如果查找的键在数据库不存在时，按照LSM-tree算法查询，必须首先检查内存表，然后将一直回溯访问到最旧的段文件，这将是一个及其耗费时间的过程。为了优化这种访问，存储引擎通常使用额外的布隆过滤器。

布隆过滤器：是一种比较巧妙的概率型数据结构。特点是能够高效的插入与查询，可以用来告诉你：“某样东西一定不存在或可能存在”，其返回结构是概率型的，而非确切的。

#### 针对写的性能优化——大小分级与分层压缩
不同的LSM存储引擎，采用的针对合并压缩的优化方式可能不一样。
LevelDB和RocksDB使用分层压缩，HBase使用大小分级，Cassandra则同时支持这两种方法。

>大小分级：将SSTable进行分级，由第一级合并成第二级，第二级再合并成第三级…依次进行下去。当内存数据达到一定大小时，会将数据排序写入磁盘生成一个SSTable文件，这是第一级的SSTable文件。当第一级的SSTable文件达到m（一般为4）个时，将这m个第一级的SSTable文件合并成一个第二级的SSTable，同理，依次进行下去。

>分层压缩：将数据分层，最底层为L0，其上分别是L1，L2，L3…每一层的数据级差为10。层数越小的块，其保存的数据越少也越新。这种分层压缩的优势是同一层的块之间没有重复数据。因为层间的合并，都是将所有数据块都合并。如L0层数据每次都是与L1层数据合并，生成新的L1层。


#### 2.3 更新流派
更新流派的代表就是：B-tree。

>（1）B-tree像SSTable一样，保留按键排序的key-value对，这样可以实现高效的key-value查询和区间查询。
（2）但是在本质上，B-tree具有非常不同的设计。日志结构索引将数据库分解成可变大小的段，通常大小为几兆字节或更大，并且始终按顺序写入段。而B-tree将数据库分解成固定大小的块或页（传统上大小为4KB），页是内部读/写的最小单元。这种设计更接近底层硬件，因为硬盘也是以固定大小的块排列。

#### B-tree设计细节
#### 使用B-tree索引查找
>B-tree的基本单位是页，每个页面可以使用地址或者位置进行标识，这样可以让一个页面引用另一个页面。这类似指针，不过是指向磁盘地址，而不是内存。通过页面引用可以构造一个树状页面。
某一页被指定为B-tree的根，每当查找索引中的一个键时，总是从这里开始。该页面包含若干个键和对子页的引用。每个孩子都负责一个连续范围内的键，相邻引用之间的键可以指示这些范围之间的边界。

#### 添加新键与插入分裂
如果要添加新键，则需要找到其范围包含新键的页，并将其添加到该页。如果页中没有足够的可用空间来容纳新键，则将其分裂为两个半满的页，并且父页页需要更新以包含分裂之后的新的键范围。

这种算法是分析和理解B-tree结构的关键：B-tree始终要保持树平衡，从而使树深保持在O(log n)。因此， B-tree的读和查找效率很高，而写效率一般。

#### B-tree（更新）带来的三大问题
>（1）B-tree底层的基本写操作是使用新数据覆盖磁盘上的旧页。遵循的原则是：覆盖不会改变页的磁盘存储位置，也就是说，当页被覆盖时，对该页的所有引用保持不变。
对于SSD，由于SSD必须一次擦除并重写非常大的存储芯片块，情况会更加复杂。例如插入导致页溢出的情况，需要分裂页，从而写两个分裂的页，并且覆盖其父页以更新对两个子页的引用。这个操作非常危险，因为如果数据库在完成部分写入后发生崩溃，最终会导致索引破坏（可能产生孤儿页）。

>（2）为了使数据库能从崩溃中恢复，常见B-tree的实现需要支持磁盘上的额外数据结构：预写日志（write-ahead log，WAL），也称为重做日志。

>（3）原地更新页的另一个复杂因素是：如果多个线程要同时访问B-tree，则需要注意并发控制。否则线程可能会看到树处于不一致的状态。


#### B-tree优化措施
（1）写时复制方案：不使用覆盖页和维护WAL来进行崩溃恢复。修改的页被写入不同的位置，树中父页的新版本被创建，并指向新的位置。
（2）保存键的缩略信息，而不是完整的键。从而可以将更多的键压入到页中，让树具有更高的分支因子，从而减少层数。
（3）添加额外的指针到树中。例如，每个叶子页面可能会向左和向右引用其同级别的兄弟页，这样可以顺序扫描键，而不用跳回到父页。

### 2.4 LSM-tree与B-tree的对比
从总体性能来说，LSM-tree通常写入更快，而B-tree被认为读取更快。
<table><thead><tr><th>特性比较</th><th>LSM-tree</th><th>B-tree</th></tr></thead><tbody>
<tr><td>读取性能</td><td>读取性能不佳。因为采用追加更新&#xff0c;可能在不同段中具有相同键的多个副本&#xff0c;因此查找需要一直查下去&#xff1a;首先尝试在内存表中查找键&#xff0c;然后是最新的磁盘段文件&#xff0c;接下来是次新的磁盘段文件&#xff0c;以此类推&#xff0c;直到找到目标或为空</td><td>读取性能更好。采用原地更新&#xff0c;每个键都恰好对应索引中的某个位置。B-tree始终要保持树平衡&#xff0c;从而使树深保持在O(log n)&#xff0c;查询很快。</td></tr>
<tr><td>写入性能</td><td>更低的写放大&#xff0c;定期重写SSTable以消除碎片化&#xff0c;从而具有更高的写入性能</td><td>B-tree的原地覆盖更新&#xff0c;导致即使某个页中只有几个字节更改&#xff0c;也必须承受写整个页的开销&#xff0c;写放大很大。并且极易产生碎片&#xff0c;导致某些磁盘空间无法使用。写性能不佳。</td></tr></tbody></table>


### 2.5 其它索引结构
### 二级索引
二级索引与主索引的最主要区别在于：它的键不是唯一的。

### 聚集索引和非聚集索引

>聚集索引：按照数据的物理存储进行划分，在索引中直接保存数据。
非聚集索引：强调的是逻辑分类（而非物理），定义了一套存储规则，存储索引中的数据的引用（堆文件）。堆文件的优点是：（1）当存在多个二级索引时，可以避免复制数据，即每个索引只引用堆文件中的位置信息，实际数据仍保存在一个位置。（2）当更新值而不更改键时，堆文件方法将非常高效。

聚集索引不同于主键，主键肯定是聚集索引，而聚集索引不一定就是主键。它可以唯一，也可以不唯一，取决于自定义的索引的unique 设置。

### 多列索引
最常见的多列索引是级联索引。
多维索引是更一般的通过多列索引的方法，尤其应用于地理空间数据。在这方面研究较少，还不能实用。

### 3. OLAP系统的存储引擎
   本章前面所讨论的索引算法适合OLTP，但不擅长应对分析查询，针对OLAP，目前主要有以下的存储引擎。

### 3.1 星型与雪花型分析模式
传统的数据仓库都相当公式化地使用了星型模式，也称为维度建模。

>（1）模式的中心是一个事实表。
（2）事实表的每一行表示在特定时间发生的事件。事实表的列是属性，列可能会引用其他表的外键，称为维度表。
（3）“星型模式”来源于当表关系可视化时，事实表位于中间，被一系列维度表包围，这些表的连接就像星星的光芒。
（4）将维度进一步细分为子空间，变体为雪花模式。

### 3.2 列式存储
如果事实表中有数以万亿行，PB大小的数据，则高效地存储和查询这些数据将成为一个具有挑战性的问题。这也是为什么大数据时代hbase列式存储流行的原因。

>面向列的存储布局依赖一组列文件，每个文件以相同顺序保存着数据行，不是将一行中所有值存储在一起，而是将每列中的所有值存储在一起。每个列存储在一个单独的文件中，查询只需读取和解析在该查询中使用的那些列，这可以节省大量的工作。
                
### 列压缩
面向列的存储非常适合压缩，这是因为列文件保存的是每一列的数据，同列数据往往数据类型和格式完全相同，这非常有利于压缩。

常见的两种压缩方法：位图编码、游程编码

### 列存储中的排序
注意：列存储中的排序是排序整行，单独排序每列是没有意义的。
排序的优点有二：

>（1）利于查询。
（2）有助于进一步压缩列。

### 3.3 聚合：数据立方体与物化视图

> （1）物化视图是查询结果的实际副本，并被写入到磁盘中。其实物化视图相当于提前预先做聚合计算，并将聚合结果保存，查询时直接调动，无需再临时做耗费时间的聚合计算。因此，当底层数据发生变化时，物化视图也需要随之更新。

>（2）物化视图的常见情况是：数据立方体。它是由不同维度分组的聚合网络。这个主要是第一个中国贡献的Apache顶级开源项目——kylin使用的，其查询速度超级快，目前在大数据分析领域备受关注。

> （3）物化视图（数据立方体）的优点是某些查询的速度相当快，远远超过其他大数据查询组件，主要是由于它们已经预先计算出来了。缺点是灵活性太差，并且预先的聚合也需要消耗很大的工作。预先聚合的结果保存需要消耗额外的内存和硬盘。

## 第四章 数据编码与演化

### 1. 模式演化

应用程序不可避免地需要随时间而变化、调整。当新产品推出，或为了更好地理解用户需求，或商业环境发生变化时，就需要不断添加或修改功能。
   特别地，许多服务需要支持滚动升级，即每次将新版本的服务逐步部署到几个节点，而不是同时部署到所有节点。滚动升级允许在不停机的情况下发布新版本的服务（因此鼓励频繁地发布小版本而不是大版本），并降低部署风险（允许错误版本在影响大量用户之前检测并回滚）。这些特性非常有利于应用程序的演化和更改。
   在滚动升级期间，或者由于各种其他原因，必须假设不同的节点正在运行应用代码的不同版本。因此，在系统内流动的所有数据都以提供向前兼容和向后兼容的方式进行编码显得非常重要。

### 2. 数据编码格式及兼容性情况
数据通常使用两种不同的数据表示形式：

>（1）在内存中：数据结构

>（2）在文件或传输中：字节序列

这两个表示之间需要进行类型的转化：从内存中的表示到字节序列的转化称为编码（序列化），相反的过程称为解码（反序列化）

### 2.1 语言特定的编码
编程语言特定的编码仅限于某一种编程语言，主要目标是快速且简单地编码数据，其存在很多深层次问题：

+ （1）编码与特定的编程语言绑定在一起，而用另一种语言访问数据就非常困难。
+ （2）为了在相同的对象类型中恢复数据，解码过程需要能够实例化任意的类，这经常导致一些安全问题。
+ （3）在这些库中，多版本数据通常是次要的，主要目标是快速且简单地编码数据，所以它们经常忽略向前或向后兼容问题。

基于这些原因，使用语言内置编码方案通常不是个好主意。

### 2.2 标准化编码：文本格式（JSON、XML与CSV）
JSON、XML和CSV都是标准化的文本格式编码，特别是作为数据交换格式（将数据从一个组织发送到另一个组织），它们非常受欢迎。

>JSON（JavaScript Object Notation）：JS对象简谱，是一种轻量级的数据交换格式，支持数字格式。

>XML（eXtensible Markup Language）：可扩展标记语言。不支持数字。

> CSV（Comma Separated Values）：逗号分隔值文件格式。不支持数字格式。


### 文本格式存在的一些问题
JSON、XML和CSV的兼容性取决于你如何使用它们。它们有可选的模式语言，这有时是有用的，有时却是一个障碍。这些文本格式对某些数据类型的支持有些模糊，必须小心处理数字和二进制字符串问题。
1.数字问题

>（1）在XML和CSV中，无法区分数字和碰巧由数字组成的字符串（除非引用外部模式）。因为XML和CSV不支持数字，无论解析给我们看的是数字还是字符串，都是以字符串形式存在，然后通过外部模式解析成数字或字符串。

> （2）JSON区分字符串和数字，但不区分整数和浮点数，并且不指定精度。

2.字符串问题

> JSON和XML对Unicode字符串（即人类可读文本）有很好的支持，但是它们不支持二进制字符串（没有字符编码的字节序列）

3.模式问题

> （1）XML 和JSON都有可选的模式支持。这些模式语言相当强大，因此学习和实现起比较复杂。

> （2）CSV没有任何模式，因此应用程序需要定义每行和每列的含义。如果应用程序更改添加新的行或列，则必须手动处理该更改。其实CSV也算是一个相当模糊的格式（如果一个值包含逗号或换行符，会发生什么）。尽管其转义规则已经被正式指定，但并不是所有的解析器都能正确实现它们。

XML 模式通常被称为 XML 模式定义（XSD）。它被用来描述和验证 XML 数据的结构和内容。XML 模式定义元素，属性和数据类型。

JSON 模式是一种基于 JSON 格式定义 JSON 数据结构的规范。

### 2.3 标准化编码：二进制格式（Thrift、Protocol Buffers和Avro）
这样的二进制模式驱动格式，支持使用清晰定义的向前和向后兼容性语义进行紧凑、高效的编码。这些模式对于静态类型语言中的文档和代码生成非常有用。然而，它们有一个缺点，即只有在数据解码后才是人类可读的。

Thrift和Protocol Buffers
>（1）Thrift 和Protocol Buffers（Protobuf）是基于相同原理的两种二进制编码库。
（2）Thrift最初是在Facebook开发的，Protocol Buffers最初是在Google开发的。
（3）Thrift 和Protocol Buffers都需要模式来编码任意的数据，然后再使用多语言编译工具将模式定义编译成对应语言的版本，以供特定语言使用。
（4）Thrift有三种不同的二进制编码格式：Binary-Protocol、Compact-Protocol和Dense-Protocol。但是因为Dense-Protocol只支持C++，不算是跨语言的标准化编码，一般被认为是特定语言的编码。

Binary-Protocol
在普通二进制编码的基础上进行改进，与普通的二进制编码的区别和联系：

>相同点：每个字段都有一个类型注释（用于指示它是否是字符串、整数、列表等），并且都可以在需要时指定长度。
区别：最大的区别是没有字段名，而是用数字类型的字段标签（1、2和3等）代替，这些数字标签就是模式定义里出现的数字。数字类型的字段标签相当于字段的别名，从而可以省略字段的全名引用，节省存储。

Compact-Protocol
在Binary-Protocol的基础上进行改进，可以大幅节省存储空间，其改进大致有两点：

>（1）将字段类型和标签打包到单字节中，并使用可变长度的整数来实现。
（2）对于数字，灵活使用字节编码，并不是全部使用完全的8个字节。例如-64~63之间的数字只需一个字节，-8192 ~8191之间需要两个字节，更大的数字才需要更多字节。

Protocol Buffers
与Compact-Protocol非常类似，只是它的位打包方式略有不同，并且没有list类型。

<table><thead><tr><th>特性比较</th><th>Compact-Protocol</th><th>Protocol Buffers</th></tr></thead><tbody>
<tr><td>打包方式</td><td>字段类型和标签打包为&#xff1a;4/4划分8位</td><td>字段类型和标签打包为&#xff1a;5/3划分8位</td></tr>
<tr><td>数字编码方式</td><td>以1337为例&#xff0c;保留13位&#xff0c;以7/6划分&#xff0c;然后&#xff0c;低位的6——&gt;1/6/0共8位&#xff0c;高位的7——&gt;0/7共8位</td><td>以1337为例&#xff0c;保留14位&#xff0c;以7/7划分&#xff0c;然后&#xff0c;低位的7——&gt;1/7共8位&#xff0c;高位的7——&gt;0/7共8位</td></tr>
<tr><td>list和array类型</td><td>有</td><td>无。取代的是有字段的重复标记&#xff0c;对于重复字段&#xff0c;表示同一个字段标签只是简单地多次出现在记录中。</td></tr></tbody></table>


字段标签和模式演化

一条编码记录只是一组编码字段的拼接。每个字段由其标签号标识，并使用数据类型进行注释。如果没有设置字段标识，则将其从编码的记录中简单地忽略。由此可见，字段标签对编码数据的含义至关重要。
如何进行模式演化？

>向前兼容：可以添加新的字段到模式，只要给每个字段一个新的标记号码。当旧的代码试图读取新代码写入的数据，则包含有它不能识别的标记号码，那么它会自动忽略该标记号码标记的字段。实现时，通过数据类型的注释来通知解析器跳过特定的字节数。

>向后兼容：只要每个字段都有一个唯一的标记号码，新的代码总是可以读取旧的数据，因为标记号码仍然具有相同的含义。唯一的要求是不能重复添加相同字段。因此，在模式初始部署之后添加的每个字段都必须是可选的（未有字段）或具有默认值（已有字段）。

Avro
由于前面的两种二进制编码格式：Thrift和Protocol Buffers不适合Hadoop的用例，因此Avro在2009年作为Hadoop的子项目而启动。
Avro也使用模式来指定编码的数据结构。它有两种模式语言：

Avro IDL：用于人工编辑。
基于JSON：更易于机器读取。

Avro与Thrift和Protocol Buffers的显著不同在于：没有标签来标识字段和数据类型。因此它远比Thrift和Protocol Buffers更节省空间。

那么问题来了：

没有字段标签和数据类型标签，如何正确解码二进制数据？
那么问题来了：

>没有字段标签和数据类型标签，如何正确解码二进制数据？

>采取了最笨但是却是最安全的方法：按照二进制数据出现在模式中的顺序遍历这些字段，然后直接采用模式告诉你每个字段的数据类型。

>这意味着：只有当读取数据的代码使用与写入数据的代码完全相同的模式时，才能正确解码二进制数据。读和写的模式如果有任何不匹配，都将无法解码数据。（特别注意！这里读模式和写模式只要匹配即可，并没有要求顺序完全一致，即使顺序不一致，也可以匹配。）


### Avro如何支持模式演化？
（1）写模式与读模式

>写模式：当应用程序想要对某些数据进行编码时，它使用所知道的模式的任何版本来编码数据。

>读模式：当应用程序想要解码某些数据时，它期望数据符合某个模式，即读模式。这是应用程序代码所依赖的模式。

Avro 的关键思想是：写模式和读模式不必完全一模一样，它们只需保持兼容。当数据被解码时，Avro库通过对比查看写模式和读模式，并将数据从写模式转换为读模式来解决差异。Avro规范明确定义了这种解决方法的工作原理。
例如：比较重要和值得关注的三个规则是：
> 第一、如果写模式和读模式的字段顺序不同，也没有问题。因为模式解析通过字段名匹配字段。

> 第二、如果读取数据的代码遇到出现在写模式但不在读模式中的字段，则忽略它。

> 第三、如果读取数据的代码需要某个字段，但是写模式不包含该字段，则使用在读模式中声明的默认值填充。

（2）模式演化规则

> 向前兼容：将新版本的模式作为writer（写模式），将旧版本的模式作为reader（读模式）

> 向后兼容：将新版本的模式作为reader（读模式），将旧版本的模式作为writer（写模式）
一兆韦德新店
保持兼容性的策略：只能添加或删除具有默认值的字段。
根据前面Avro匹配规范的第二、第三条规则，如果我们规定在新版本中，只能添加或删除具有默认值的字段，则向前兼容，向后兼容均能完美解决。
为什么一定要求“具有默认值”？理解两点：

> 1.如果要添加一个没有默认值的字段，不会影响向前兼容性。但是新的reader将无法读取旧的writer写的数据，因此，将破坏向后兼容性。

> 2.如果要删除没有默认值的字段，不会影响向后兼容性。但是旧的reader将无法读取新的writer写入的数据，因此，将破坏向前兼容性。

（3）reader如何知道特定的数据采用哪个writer的模式编码？
取决于Avro使用的上下文，具体场景具体分析：

> 1.有很多记录的大文件：该文件的writer可以仅在文件的开头包含writer的模式信息。Avro通过指定一个文件格式来做到这一点。

> 2.具有单独写入记录的数据库：在数据库中，不同的记录可能在不同的时间点、使用不同的writer模式编写，显然不能粗暴地假设所有记录都具有相同的模式。最简单的解决方案是在每个编码记录的开始处包含一个版本号，并在数据库中保留一个模式版本列表。reader可以获取记录，提取版本号，然后从数据库中查询该版本号的writer模式。

> 3.通过网络连接发送记录：当两个进程通过双向网络连接进行通信时，他们可以在建立连接时协商模式版本，然后在连接的生命周期中使用该模式。这也就是Avro RPC协议的基本原理。


### Avro的优点
显而易见，Avro不包括任何标签号，可以大幅节省存储空间。

由于Avro不包括任何标签号，其对于动态生成的模式更友好。具体体现在，例如转储关系型数据库到一个文件：

使用Avro时，很容易就可以根据关系模型生成Avro模式，并使用该模式对数据库内容进行编码，然后将其全部转储到Avro对象容器文件中。如果数据库模式发生变化，则简单地从更新的数据库模式中生成新的Avro模式即可（有专门的API可用），并用新的Avro模式导出数据。数据导出过程不需要关注模式的改变，每次运行时都可以简单地进行模式转换，并且更新的writer模式仍然可以与旧的reader模式匹配。

相比之下，如果使用Thrift和Protocol Buffers，则每次数据模式更改时，管理员都必须手动更新从数据库列名到字段标签的映射。

Avro为静态类型编程语言提供了可选的代码生成，它既支持代码生成，也可以在不生成代码的情况下直接使用，这方便了动态类型编程语言。

静态类型编程语言：Java，C++，C#
静态生成的模式：Thrift和Protocol Buffers。它们依赖于代码生成：在定义了模式之后，可以使用选择的编程语言生成实现此模式的代码。

代码生成在对这些静态编译语言很有用，因为它允许使用高效的内存结构来解码数据，并且在编写访问数据结构的程序时，支持在IDE中进行类型检查和自动完成。

动态类型编程语言：JavaScript，Ruby，Python
动态生成的模式：Avro。

对于动态类型编程语言，由于没有编译时类型检查，生成代码没有太多意义。对于动态生成的模式的情况，代码生成对获取数据反而是不必要的障碍。

### 3. 数据流模式
数据可以从一个进程流向另一个进程，本节将探讨一些最常见的进程间数据流动的方式。

基于数据库的数据流
>写入数据库的进程对数据进行编码，而读取数据库的进程对数据进行解码。

>数据库肯定需要向后兼容，而大多数情况下向前兼容同样要保证。例如：

>当用旧版本的应用程序更新新版本的应用程序所写入的数据时，可能会丢失未知字段（这是由于读写模式的原理决定的），解决方法如下：

部署新版本的应用程序时，用新版本完全替换旧版本当然是可行的，但是对于数据库这可能耗费相当长的时间，一般是不被允许的。通过添加具有默认值为空的新列，而不重写现有数据可以解决。（这其实就是Avro模式演化采取的规则）

基于服务的数据流：REST和RPC

客户端对请求进行编码，服务器对请求进行解码并对响应进行编码，客户端最终对响应进行解码。

面向服务/微服务体系结构的一个关键设计目标是：通过使服务可独立部署和演化，让应用程序更易于更改和维护。换句话说，应该期望新旧版本的服务器和客户端同时运行，因此服务器和客户端使用的数据编码必须在不同版本的服务API之间兼容，这正是本节讨论的内容。

流行的web服务方法

两种流行的Web服务方法：

> REST：不是一种协议，而是一种基于HTTP原则的设计理念。它强调简单的数据格式，使用URL来标识资源，并使用HTTP功能进行缓存控制、身份验证和内容类型协商。最受欢迎，互操作性更好。

>SOAP：是一种基于XML的协议，用于发出网络API请求。虽然它最常用于HTTP，但其目的是独立于HTTP，并避免使用大多数HTTP功能，它带有庞大复杂的多种相关标准，不受欢迎，互操作性也存在一些问题。

### 远程过程调用（RPC）
前面所讲的web服务仅仅是通过网络发出API请求的一系列技术的最新体现，所有这些都是基于远程过程调用（RPC）的思想。

RPC的问题
RPC 模型试图使向远程网络服务发出的请求看起来与在统一进程中调用编程语言中的函数或方法相同（这种抽象成为位置透明）。但是残酷的现实已经告诉我们，网络请求和本地函数调用非常不同！尝试使远程服务看起来像编程语言中的本地对象一样是毫无意义的。

RPC的发展方向
虽然有各种问题，但是RPC并没有消失，而是在各种编码的基础上构建各自不同的多种RPC框架。例如Thrift和Avro带有RPC支持，gRPC是使用Protocol Buffers的RPC实现，Rest.li使用HTTP上的JSON等。
新一代的RPC框架更加认清了现实，明确了远程请求和本地函数调用不同的事实。差异化发展，优化各自的独特功能。

基于消息传递的数据流
异步消息传递（使用消息代理或Actor），节点之间通过互相发送消息进行通信，消息由发送者编码并由接收者解码。

异步消息传递系统与RPC相比，优点在于：

>（1）它在逻辑上将发送方和接收方分离（发布方只是发布消息，并不关心谁使用它们）
（2）它支持将一条消息发送给多个接收方。
（3）它避免了发送方需要知道接收方的IP地址和端口号。
（4）如果接收方不可用或过载，它可以充当缓冲区，从而提高系统的可靠性
（5）它可以自动将消息重新发送到崩溃的进程，从而防止消息丢失。

这些优点，主要是由于消息传递通信通常是单向、异步的。

并发线程中通信的两种策略：共享数据和消息传递。和共享数据方式相比，消息传递机制最大的优点是不会产生数据竞争状态。

实现消息传递的两种常见类型：

> 基于channel的消息传递（消息代理）:保证消息传送，防止消息丢失。即使进程崩溃，仍然会保证消息传送。

> 基于Actor的消息传递（分布式Actor框架）：不保证消息传送，可能会消息丢失。