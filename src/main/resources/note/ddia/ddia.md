## 设计数据密集型应用 概要阅读笔记
                        

<img src="/src/main/resources/note/ddia/img.png">

#第一部分：数据系统基础
   
## 第一章：可靠性、可伸缩性和可维护性

<img src="/src/main/resources/note/ddia/img_1.png">

系统的分类:
+ 数据密集型（data-intensive） ,更多的是数据量、数据复杂性、以及数据的变更速度
+ 计算密集型（compute-intensive）,集中在CPU的运算

数据密集系统的通用功能:
+ 存储数据，以便自己或其他应用程序之后能再次找到 （数据库，即 databases）
+ 记住开销昂贵操作的结果，加快读取速度（缓存，即 caches）
+ 允许用户按关键字搜索数据，或以各种方式对数据进行过滤（搜索索引，即 search indexes）
+ 向其他进程发送消息，进行异步处理（流处理，即 stream processing）
+ 定期处理累积的大批量数据（批处理，即 batch processing）


<img src="/src/main/resources/note/ddia/img_2.png">

流式处理：关注实时性。kafka，storm，spark streaming，flink等
批处理：关注处理性能，不太要求实时性。MapReduce，spark.

大多数软件系统中都很重要的问题：

+ 可靠性（Reliability）系统在, 困境（adversity，比如硬件故障、软件故障、人为错误）中仍可正常工作（正确完成功能，并能达到期望的性能水准）。
+ 可伸缩性（Scalability）,有合理的办法应对系统的增长（数据量、流量、复杂性）
+ 可维护性（Maintainability）许多不同的人（工程师、运维）在不同的生命周期，都能高效地在系统上工作（使系统保持现有行为，并适应新的应用场景）


###  可靠性

可靠性: 出来了故障,也可以正常工作

常见错误,如何保证可靠 :

+ 硬件故障（hardware faults）,硬件冗余
+ 软件错误,硬件故障是随机的、相互独立的 ,但软件之间的关联非常紧密，错误往往会导致连锁的一连串故障。特定值的输入(2012 年 6 月 30 日的闰秒),特定bug,失控进程导致用尽一些共享资源,级联故障
  所以，软件容错的主要目的和方法是：提供足够的冗余信息和算法程序，使系统在实际运行时能够及时发现程序设计错误，及时采取补救措施，以提高软件可靠性，保证整个计算机系统的正常运行。主要的软件容错手段有：恢复快方法，N-版本程序设计，防卫式程序设计。
+ 人为错误 最好的系统会组合使用以下几种办法：
    - 以最小化犯错机会的方式设计系统。
    - 将人们最容易犯错的地方与可能导致失效的地方 解耦（decouple）
    - 各个层次进行彻底的测试【3】，从单元测试、全系统集成测试到手动测试 (充分的测试)
    - 允许从人为错误中简单快速地恢复，以最大限度地减少失效情况带来的影响。(快速恢复)
    - 配置详细和明确的监控，比如性能指标和错误率(详细的监控)
                                                                    

### 可伸缩性

可伸缩性（Scalability） 是用来描述系统应对负载增长能力的术语。

#### 描述负载
> 每秒向 Web 服务器发出的请求、数据库中的读写比率、聊天室中同时活跃的用户数量、缓存命中率或其他东西。

推特的两个主要业务是：

+ 发布推文  用户可以向其粉丝发布新消息（平均 4.6k 请求 / 秒，峰值超过 12k 请求 / 秒）。
+ 主页时间线  用户可以查阅他们关注的人发布的推文（300k 请求 / 秒）。

大体上讲，这一对操作有两种实现方式。

+ 发布推文时，只需将新推文插入全局推文集合即可 ,推特前期使用这个 ,但系统很难跟上主页时间线查询的负载
+ 为每个用户的主页时间线维护一个缓存，就像每个用户的推文收件箱 ,缺点是，发推现在需要大量的额外工作。

推特最终是 两种模式混合,将粉丝量巨大的,粉丝去拉取, 一般的推送

#### 3.2 描述性能
         
>批处理系统，通常关心的是 吞吐量（throughput），即每秒可以处理的记录数量，或者在特定规模数据集上运行作业的总时间 
> 对于在线系统，通常更重要的是服务的 响应时间（response time） ，即客户端发送请求到接收响应之间的时间。

#### 平均数指标 VS 百分位数指标
对于响应时间，如果想要知道更典型的响应时间，平均值并不是一个合适的指标，它无法告诉有多少用户实际经历了多少延迟。比如有100个响应，其中90个都是100ms响应，其余10个是10s响应，平均下来就是1s左右，如果以此作为响应时间的衡量指标，看起来还能接受。但是用户实际体验到的是10s响应，无法满足需求。

如果用百分位数指标，比如95%分位数，则得到95分位数响应时间是10s，技术人员就知道性能出了问题，需要改进了。


> 百分位点通常用于 服务级别目标（SLO, service level objectives） 和 服务级别协议（SLA, service level agreements），即定义服务预期性能和可用性的合同。

#### 应对负载的方法

大规模的系统架构通常没有万金油,应用的问题可能是读取量、写入量、要存储的数据量、数据的复杂度、响应时间要求、访问模式或者所有问题的大杂烩。

> 纵向伸缩,垂直伸缩，即 vertical scaling，转向更强大的机器
> 横向伸缩（scaling out，也称为水平伸缩，即 horizontal scaling，将负载分布到多台小机器上

### 可维护性

众所周知，软件的大部分开销并不在最初的开发阶段，而是在持续的维护阶段，包括修复漏洞、保持系统正常运行、调查失效、适配新的平台、为新的场景进行修改、偿还技术债、添加新的功能等等

软件系统的三个设计原则：

+ 可操作性（Operability）  便于运维团队保持系统平稳运行。
+ 简单性（Simplicity）从系统中消除尽可能多的 复杂度（complexity），使新工程师也能轻松理解系统（注意这和用户接口的简单性不一样）。
+ 可演化性（evolvability）使工程师在未来能轻松地对系统进行更改，当需求变化时为新应用场景做适配。也称为 可伸缩性（extensibility）、可修改性（modifiability） 或 可塑性（plasticity）。

#### 可操作性：人生苦短，关爱运维

“良好的运维经常可以绕开垃圾（或不完整）软件的局限性，而再好的软件摊上垃圾运维也没法可靠运行”。尽管运维的某些方面可以，而且应该是自动化的，但在最初建立正确运作的自动化机制仍然取决于人。

#### 简单性：管理复杂度

复杂度（complexity） 有各种可能的症状，例如：状态空间激增、模块间紧密耦合、纠结的依赖关系、不一致的命名和术语、解决性能问题的 Hack、需要绕开的特例等等

消除 额外复杂度 的最好工具之一是 抽象（abstraction)

高级编程语言是一种抽象，隐藏了机器码、CPU 寄存器和系统调用。 SQL 也是一种抽象，隐藏了复杂的磁盘 / 内存数据结构、来自其他客户端的并发请求、崩溃后的不一致性。

#### 可演化性：拥抱变化

修改数据系统并使其适应不断变化需求的容易程度，是与 简单性 和 抽象性 密切相关的：简单易懂的系统通常比复杂系统更容易修改。

### 小结

一个应用必须满足各种需求才称得上有用。有一些 功能需求（functional requirements，即它应该做什么，比如允许以各种方式存储，检索，搜索和处理数据）以及一些 非功能性需求（nonfunctional，即通用属性，例如安全性、可靠性、合规性、可伸缩性、兼容性和可维护性）。

+ 可靠性（Reliability） 意味着即使发生故障，系统也能正常工作。故障可能发生在硬件（通常是随机的和不相关的）、软件（通常是系统性的 Bug，很难处理）和人类（不可避免地时不时出错）。 容错技术 可以对终端用户隐藏某些类型的故障。
+ 可伸缩性（Scalability） 意味着即使在负载增加的情况下也有保持性能的策略。为了讨论可伸缩性，我们首先需要定量描述负载和性能的方法。我们简要了解了推特主页时间线的例子，介绍描述负载的方法，并将响应时间百分位点作为衡量性能的一种方式。在可伸缩的系统中可以添加 处理容量（processing capacity） 以在高负载下保持可靠。
+ 可维护性（Maintainability） 有许多方面，但实质上是关于工程师和运维团队的生活质量的。良好的抽象可以帮助降低复杂度，并使系统易于修改和适应新的应用场景。良好的可操作性意味着对系统的健康状态具有良好的可见性，并拥有有效的管理手段。


##  第二章：数据模型与查询语言

###  1.数据模型
大多数应用程序是通过一层一层叠加数据模型来构建的，每一层都面临的关键问题是：如何将其用下一层来表示？例如：

> 1. 观察现实世界，通过构建对象或数据结构，以及操作这些数据结构的API来对其建模。
2. 采用通用数据模型，存储这些数据结构。
3. 数据库工程师决定用何种内存、磁盘或网络的字节格式来表示上述数据。
4. 更下层，硬件工程师考虑如何用电流、磁场、光脉冲等来表示字节。

基本思想相同：每层都通过提供一个简洁的数据模型来隐藏下层的复杂性。这种抽象机制使得不同的人群可以高效协作。

### 2.关系模型与非关系模型

NoSQL的介绍 <a href="https://www.runoob.com/mongodb/nosql.html">Nosql</a>

<table><thead><tr><th>特性比较</th><th>关系模型</th><th>文档模型</th><th>图模型</th></tr></thead>
<tbody><tr><td>数据类型</td><td>高度组织化结构化数据</td><td>JSON或XML的文档型数据</td><td>图结构数据</td></tr>
<tr><td>查询语言</td><td>结构化查询语言&#xff08;SQL&#xff09;</td><td>非结构化查询语言&#xff08;独有&#xff09;</td><td>非结构化查询语言&#xff08;Cypher等&#xff09;</td></tr>
<tr><td>模式与联结</td><td>写时模式。数据和关系都存储在单独的表中;支持多表联结</td><td>无模式&#xff08;或称作读时模式&#xff09;;不支持多表联结。联结的工作其实从数据库转移到了应用层;通过对数据库进行多次查询来模拟联结</td><td>无模式&#xff08;或称作读时模式&#xff09;;不支持多表联结。联结的工作其实从数据库转移到了应用层;通过对数据库进行多次查询来模拟联结</td></tr>
<tr><td>规则</td><td>ACID;强一致性</td><td>CAP定理;弱一致性</td><td>CAP定理;弱一致性</td></tr><tr><td>优势</td><td>简便易学的SQL;强一致性;多表联结、多对一、多对多的表达比较简洁易懂</td><td>模式灵活性易于进行模式演变;局部性带来较好的查询性能;比较适合一对多</td><td>模型最贴近真实世界;支持百亿甚至千亿量级规模的巨型图的高效关系运算。由于图数据库模型的每个节点都直接包含一个关系列表;在定义时已经预先保存了关系;从而使得图数据库可以提供比关系型数据库高几个数量级的性能。对于复杂连接的查询;可能只有图数据库能达到响应要求。</td></tr>
<tr><td>劣势</td><td>格式要求严格;写时模式导致可扩展性太差。多表联结虽然操作简单;但是实际上是通过外键约束来实现;这种操作是“计算密集型”的;并且操作次数将是表中记录的指数级别;需要消耗大量的资源;性能太差。</td><td>查询定义语言不够标准;并且查询性能不高</td><td>需要预先定义好属性图结构;可能需要对整个图做大量计算。图遍历步数不能太深;超过三步性能就会急剧下降;这显然无法满足现实需求。</td></tr></tbody></table>

### 2.2 层次模型的局限与演化

> 层次模型：一对多，每个记录只有一个父节点。层次模型支持多对多有些困难，而且不支持联结。为了解决层次模型的局限性，提出了多种解决方案，最著名的就是：关系模型和网络模型。

>网络模型:一个记录可能有多个父节点。在网络模型中，记录之间的链接不是外键，而更像是编程语言中的指针（会存储在磁盘上）。访问记录的唯一方法是选择一条始于记录的路径，并沿着相关链接依次访问。这被称为访问路径。访问路径像是遍历列表，从链表的开头，一次查看一个记录，直到找到所需的记录。由于网络模型，一个记录可能有多个父节点，则遍历非常缓慢复杂，所以性能非常差。而手动路径选择需要大量的手写数据库查询代码，更是复杂而没有灵活性，最终导致了网络模型的失败。

> 关系模型：相比之下，关系模型所做的就简单多了，它只定义了所有数据的格式：关系（表）只是元组（行）的集合。没有复杂的嵌套结构，也没有复杂的访问路径。在关系数据库中，查询优化器自动决定以何种顺序执行查询，以及使用哪些索引。这些选择实际上等价于“访问路径”，最大的区别在于他们是由查询优化器自动生成的，而不是由应用开发人员所维护，开发人员只需懂的SQL即可，不必了解底层实现，极大降低了学习成本。这也是最终SQL称霸数据库领域的原因。

文档数据库可以认为是某种方式的层次模型（一对多关系）。

>其实在表示多对一和多对多关系时，关系数据库和文档数据库并没有根本的不同：相关项都是由唯一的标识符引用，该标识符在关系模型中被称为外键，而在文档数据库中被称为文档引用。
外键标识符可以在查询时通过联结操作来解析；文档引用标识符可以在查询时通过相关后续的多次查询来解析。

### 2.3 文档数据库的模式灵活性与数据局部性
读时模式 VS 写时模式

>文档数据库有时被称为无模式，其实更准确来说应该是“读时模式”，即数据结构是隐式的，只有在读取时才解释。读时模式类似于编程语言中的动态（运行时）类型检查。

>关系数据库被称为"写时模式"，模式是显式的，数据在写入时必须严格按照数据格式要求。写时模式类似于静态（编译时）类型检查。

文档数据库因为是读时模式，具有模式灵活性，可扩展性更强。

### 数据局部性的优缺点

优势：如果应用程序需要频繁访问整个文档或文档大部分内容，则文档数据库的数据局部性相对于关系数据库的多表联结具有性能优势，只需检索一次而无需像关系型数据库一样进行多次索引来检索所有数据。

局限性：只访问一部分时则无优势很浪费。文档更新时，通常会重写整个文档，很耗费性能。通常建议文档应该尽量小且避免写入时增加文档大小，使用原地覆盖更新。

### 2.4 MapReduce查询
MapReduce是一种编程模型，用于在许多机器上批量处理海量数据。一些NoSQL存储系统（如MongoDB 和CouchDB）支持有限的MapReduce方式在大量文档上执行只读查询。

MapReduce既不是声明式查询语言，也不是一个完全命令式的查询API，而是介于两者之间：查询的逻辑用代码片段来表示，而这些代码片段可以被处理框架重复地调用。

MapReduce查询有两个限制：

+ map和reduce函数对可执行的操作有限制，必须是纯函数。不能执行额外的数据库查询，也不能有任何副作用。
+ 可用性限制。必须编写两个函数：map和reduce函数，这两个函数必须在逻辑上密切协调，这通常比编写单个查询更难。

### 3. 图模型
如果数据大多是一对多关系（树结构模型），或者记录之间没有关系，那么文档模型是最合适的。
对于多对多关系，关系模型能够处理简单的多对多关系，但是真实世界的多对多关系是想当复杂的，随着数据之间的关联越来越复杂，图模型将是更加直观和有效的方法。

图数据库是专门为处理高度连接的数据而建立的。它有三个关键优势：
>（1）扩展性高：图中可以显示一些传统关系模式难以表达的东西。并且图有利于演化，向应用程序添加功能时，图可以容易地扩展以适应数据结构的不断变化。
（2）性能好：对于密集的数据关系处理，图数据库将性能提升了几个数量级。在传统数据库中，随着关系的数量和深度的增加，关系查询将会停止。
（3）敏捷：使用图数据库开发完全符合当今灵活的，测试驱动的开发实践。

本书中讨论了图模型中的属性图模型（property graph，以Neo4j、Titan为代表）和三元存储模型（triple-store，以Datamic、AllegroGraph为代表）

### 3.1 属性图模型和Cypher查询语言
代表的就是经典的图数据库Neo4j，有兴趣的可以参考清华大学张织老师的《Neo4j权威指南》，关于Neo4j和查询语言Cypher，介绍的非常详尽。

属性图的基本概念
>一个属性图是由顶点（vertex），边（edge），标签（label），关系类型（type of relation）和属性（property）组成的有向图。
顶点也被称为节点（node），边也被称为关系（relation）。在图形中，节点和关系是最重要的实体。所有节点都是独立存在的，通过标签来分组，相同标签的节点属于一个分组（集合）；关系通过关系类型来分组，类型相同的关系属于同一个集合。
节点可有零个，一个或多个标签，但关系有且仅有一个关系类型。
关系是有向的，关系的两端是起始节点和结束节点，通过有向的箭头来标识方向，节点之间的双向关系通过两个方向相反的关系来标识。
属性是一个键值对，每个节点或关系可以有一个或多个属性；属性值可以是标量类型或者标量类型的列表。


### 3.2 三元存储模型与SPARQL查询语言
三元存储模型其实就是RDF数据模型。

RDF数据模型
>RDF的由来。
从语义网到RDF。
语义网从本质上讲来源于一个简单而合理的想法：网站通常将信息以文字和图片方式发布给人类阅读。那么，为什么不考虑将信息发布为机器可读的格式给计算机阅读呢？ ————资源描述框架（Resource Description Framework ，RDF）就是这样一种机制，它让不同网站以一致的格式发布数据，这样来自不同网站的数据自动合并成一个数据网络，一种互联网级别的包含所有数据的数据库。

RDF的格式
RDF是一个抽象的数据模型，它有很多种RDF数据序列格式：
>（1）Turtle
（2）RDF/XML
（3）N-Triples
（4）RDFa
（5）TRIG
（6）Notation3（N3），Turtle可以认为是N3的一个子集。

RDF的定义
>（1）RDF使用web标识符来标志事物，并通过属性和属性值来描述资源。
（2）三元组：主、谓、客。
资源（主体）：是可拥有URI的任何事物。
属性（谓语）：是拥有名称的资源，用来描述资源之间的关系。比如：author，homepage等，当然也可以用URI标识，这使得万维网环境下全局性的标识资源以及资源间联系成为可能。
属性值（客体）：是某个属性的值——>第一种情况；是另一个资源——>第二种情况。
（3）陈述：资源、属性和属性值的组合可形成一个陈述，对应地，它们被称为陈述的主体、谓语、客体，表达成三元组结构。RDF图就是一个由RDF三元组构成的集合，RDF三元组可以看成是“节点——边——节点”的结构。这与万维网的图结构“文档——超链接——文档”相吻合。本质上，RDF图是节点和边均带有标签的有向图结构。

RDF 与属性图的联系与区别
>三元存储模型（RDF）几乎等同于属性图模型，只是使用不同的名词描述了相同的思想。
联系（逻辑完全一致）：RDF三元组结构，属性值第一种情况：对应属性图中顶点的定义。第二种情况：对应属性图中关系的定义。
区别（表达方法不同）：RDF图和属性图定义的结构略有不同，属性图更加直观和简单。

SPARQL查询语言

SPARQL是一种采用RDF数据模型的三元存储查询语言。它比Cypher更早，并且由于Cypher的模式匹配是借用SPARQL的，两者看起来非常相似

### 3.3 一阶谓词逻辑表示法与Datalog
Datalog的数据模型类似于三元存储模式，但更加通用一些，它采用一阶谓词逻辑：“谓语（主体，客体）”的表达方式而不是三元组（主体，谓语，客体）。

一阶谓词逻辑

一阶谓词逻辑表示法是一种重要的知识表示方法，它以数理逻辑为基础，是到目前为止能够表达人类思维活动规律的一种最精准形式语言。它与人类的自然语言比较接近，又可方便存储到计算机中去，并被计算机进行精确处理。因此，它是一种最早应用于人工智能中的表示方法。

Prolog语言

Prolog语言是以一阶谓词逻辑为理论基础的逻辑程序设计语言，是人工智能程序设计语言族中应用最广泛的一种。Prolog的基本语句有三种：事实，规则，目标。

>事实：用来说明一个问题中已知的对象和它们之间的关系，如：儿子（王健林，王思聪），表明王健林的儿子是王思聪。
规则：用来描述事实之间的依赖关系，如：bird（x）：——animal（x）, has （x，feather），表示凡是动物且有羽毛的都是鸟。
目标：向Prolog询问的问题就是程序运行的目标，如：？——student（lucy）表示lucy是学生吗？

Datalog其实是Prolog的子集。


### 3.4 图数据库与网络模型的比较

<table><thead><tr><th>特性比较</th><th>图数据库</th><th>网络模型</th></tr></thead>
<tbody><tr><td>模式</td><td>无模式&#xff08;读时模式&#xff09;</td><td>写时模式</td></tr>
<tr><td>查询方法</td><td>既可以通过顶点的唯一ID直接引用;也可以使用索引查找</td><td>唯一方法是遍历访问路径</td></tr>
<tr><td>查询语言</td><td>声明式</td><td>命令式</td></tr><tr><td>记录方法</td><td>顶点和边不是有序的</td><td>记录是有序集合;数据库必须保持这种排序&#xff08;很麻烦&#xff09;</td></tr>
<tr><td>数据结构</td><td>属性图&#xff08;顶点——边——顶点&#xff09;</td><td>父节点——子节点</td></tr></tbody></table>
<p>由对比可见;图数据库的网络模型从数据结构就决定了其根本不同;两者不可混为一谈。</p>


### 第三章：存储与检索

1. OLTP 与 OLAP
>概括来讲，存储引擎分为两大类：针对事务处理（OLTP）优化的架构，以及针对分析（OLAP）优化的架构。他们典型的访问模式存在很大差异：

OLTP系统通常面向用户，这意味着它们可能收到大量的请求。为了处理负载，应用程序通常在每个查询中只涉及少量的记录。应用程序基于某种键来请求记录，而存储引擎使用索引来查找所请求键的数据。磁盘寻道时间往往是瓶颈。

OLAP系统往往并不直接面对最终用户，它们主要由业务分析师来使用。OLAP处理的查询请求数目远低于OLTP系统，但是每个查询通常要求非常苛刻，需要在短时间内扫描数百万条记录（大数据时代，随着数据量的暴增，可能要求更大）。磁盘带宽通常是瓶颈，而面向列的存储对于这种工作负载成为日益流行的解决方案。

2. OLTP系统的存储引擎
   在OLTP方面，有两个主要流派的存储引擎：

日志结构流派：它只允许追加式更新文件和删除过时的文件，但不会修改已写入的文件。BitCask、SSTables、LSM-tree、LevelDB、Cassandra、HBase、Lucene等属于此类。日志结构存储引擎是一个相对较新的存储方案，其关键思想是：系统地将磁盘上随机访问写入转为顺序写入，由于磁盘驱动器和SSD的性能特性，可以实现更高的写入吞吐量。

更新流派：将磁盘视为可以覆盖一组固定大小的页。B-tree是这一哲学的最典型代表，传统的数据库，无论是关系型还是非关系型，绝大多数都基于此。

### 2.1 键值存储与哈希索引

#### 索引
> 1. 数据库的核心是数据结构。
2. OLTP系统为了高效地查找数据库特定键的值，需要新的数据结构：索引。
3. 索引是基于原始数据库派生而来的额外数据结构，添加或删除索引不会影响数据库的内容，只会影响查询性能。
4. 索引可以加速读取查询，但是每个索引都会减慢写速度。这涉及一种权衡。

#### 哈希索引
key-value类型并不是唯一可以索引的数据，但它随处可见，是其他更复杂索引的基础构造模块。key-value存储通常采用hash-map（或者hash-table）来实现。

#### 索引策略
假设数据存储全部采用追加式文件组成，以日志文件为例，那么最简单的哈希索引策略是：

>（1）保存内存中的hash-map，把每个键一一映射到数据文件中特定的字节偏移量，这样就能很方便的找到每个值的位置。
（2）每当在文件中追加新的key-value对时，则更新hash-map来反映刚刚写入数据的偏移量（包括插入新的键和更新已有的键）
（3）当查找某个值时，使用hash-map来找到文件中的偏移量，即存储位置，然后取其内容。

这就是Bitcask所采用的核心做法。只要所有的key可以放入内存，无论value的数据量有多大，只需一次磁盘寻址，就可以将value从磁盘加载到内存，可以提供高性能的读和写。这种存储引擎非常适合没有太多不同的key，而每个键的值频繁更新的场景，因为在这种场景下，将所有key保存在内存中是可行的。

#### 设计细节
>（1）如何避免最终用尽磁盘空间？
将日志分解成一定大小的段，当文件达到一定大小时就关闭它，并将后续写入到新的段文件中。
可以执行段压缩和多个段的合并，压缩合并的段会被写入另一个新文件。在执行压缩合并的过程中，段会被冻结，在后台线程完成压缩合并操作。此时，仍然可以用旧的段文件继续正常读取和写请求。当压缩合并完成后，将读请求切换到新的合并段上，然后旧的段文件可以安全删除。

>（2）文件格式
CSV并不是最佳的格式，最快最简单最节省内存的方法是使用二进制格式。

>（3）删除记录
如果要删除键和它关联的值，则必须在数据文件中追加一个特殊的删除记录（墓碑）。当合并段时，一旦发现墓碑标记，则会丢弃这个已删除键的所有值。

>（4）崩溃恢复
如果数据库重新启动，则内存中的hash-map将丢失。原则上，可以通过从头到尾读取整个段文件，然后记录每个键的最新值的偏移量，来恢复每个段的hash-map。但是，如果分段文件很大，可能扫描需要很长时间，这将使服务器重启变的缓慢。通过将每个段的hash-map的快照存储在磁盘上，可以更快地加载到内存中，从而加快恢复速度。

>（5）部分写入的记录
数据库将记录写入到日志的过程中，随时可能出现问题，导致写入错误。使用检验值，这样可以发现损坏部分并丢弃。

>（6）并发控制
由于写入以严格的先后顺序追加到日志中，通常写线程只能有一个，而读线程是可以并发的。


#### 问题分析
哈希索引是一个简单却非常精妙的设计，但是也有其局限性：

>（1）哈希表必须全部放入内存，但如果有大量的键，或者键需要频繁增加删除，就不太适应。

>（2）区间查询效率不高。哈希索引虽然采用顺序写，但是key值并没有排序，所以不能进行区间查询，必须采用逐个查找的方式。

### 2.2 日志结构流派

日志结构流派采用追加式更新和删除过时的文件，对比原地更新，其优势在于：

>（1）顺序写，比随机写入快得多
（2）追加式更新的段文件是追加的或不可变的，并发和崩溃恢复要简单的多。
（3）合并旧段可以避免碎片化问题。

#### LSM存储引擎（LSM-tree算法）工作流程
基于合并和压缩排序文件原理的存储引擎通常都被称为LSM存储引擎，他们基于LSM-tree算法。

>（1）当写入时，将其添加到内存中的平衡树数据结构中（例如红黑树），这个内存中的树有时被称为内存表。
（2）当内存表大于某个阈值（通常为几兆字节）时，将其作为SSTable文件写入磁盘。由于树已经维护了按键排序的key-value对，写磁盘可以比较高效。新的SSTable文件成为数据库的最新部分。当SSTable写磁盘的同时，写入可以继续添加到一个新的内存表实例。
（3）当处理读请求时，首先尝试在内存表中查找键，然后是最新的磁盘段文件，接下来是次新的磁盘段文件，以此类推，直到找到目标。（可见，这个读机制，导致读性能不佳）
（4）后台周期性地执行段合并与压缩过程，以合并多个段文件，并丢弃那些已被覆盖或删除的值。（可见，写性能高，可以支持非常高的写入吞吐量）
                                                                                                               
#### SSTable技术细节
>（1）数据按键排序如何维持？
在内存中维护排序结构是非常简单的，有很多广为人知的树状数据结构，例如红黑树或AVL树。使用这些数据结构，可以按任意顺序插入键，并以排序后的顺序读取它们。

>（2）如果数据库崩溃，最近的写入（在内存表中但尚未写入磁盘）如何处理？
在磁盘上保留单独的日志，每个写入都会立即追加到该日志。这个日志文件不需要按键排序，这不重要，它的唯一目的是在崩溃后恢复内存表。每当将内存表作为SSTable文件写入磁盘后，相应的日志可以被丢弃，以节省空间。

#### SSTable与LSM-tree
LSM-Tree（Log Structured Merge Tree，日志结构的合并树），是一种分层，有序，面向磁盘的数据结构，其核心思想是：磁盘批量的顺序写要远比随机写性能高出很多。围绕这一原理进行设计和优化，以此让写性能达到最优，正如我们普通的Log的写入方式，这种结构的写入，全部都是以Append的模式追加，不存在删除和修改。当然有得就有舍，这种结构虽然大大提升了数据的写入能力，却是以牺牲部分读取性能为代价，故此这种结构通常适合于写多读少的场景。

SSTable是一种拥有持久化，有序且不可变的的键值存储结构，它的key和value都是任意的字节数组，并且了提供了按指定key查找和指定范围的key区间迭代遍历的功能。SSTable内部包含了一系列可配置大小的Block块，典型的大小是64KB，关于这些Block块的index存储在SSTable的尾部，用于帮助快速查找特定的Block。当一个SSTable被打开的时候，index会被加载到内存，然后根据key在内存index里面进行一个二分查找，查到该key对应的磁盘的offset之后，然后去磁盘把响应的块数据读取出来。当然如果内存足够大的话，可以直接把SSTable直接通过MMap的技术映射到内存中，从而提供更快的查找。

在LSM-Tree结构里面，核心的数据结构就是SSTable。SSTable有一份在内存里面，其他的多级在磁盘上

<img src="/src/main/resources/note/ddia/img_3.png">

#### LSM-tree的缺点
>（1）由于需要不断进行压缩合并，有时会干扰正在进行的读写操作，导致读取性能更差。
（2）高写入吞吐量的同时，压缩的另一个问题就出来了：磁盘的有限写入带宽需要在初始写入（记录并刷新内存表到磁盘）和后台运行的压缩线程之间共享。数据库的数据量越大，压缩所需要的磁盘带宽就越多。
（3）如果写入吞吐量很高并且压缩没有仔细配置，那么就会发生压缩无法匹配新数据写入速率的情况。

#### LSM-tree算法优化
针对读的性能优化——布隆过滤器
如果查找的键在数据库不存在时，按照LSM-tree算法查询，必须首先检查内存表，然后将一直回溯访问到最旧的段文件，这将是一个及其耗费时间的过程。为了优化这种访问，存储引擎通常使用额外的布隆过滤器。

布隆过滤器：是一种比较巧妙的概率型数据结构。特点是能够高效的插入与查询，可以用来告诉你：“某样东西一定不存在或可能存在”，其返回结构是概率型的，而非确切的。

#### 针对写的性能优化——大小分级与分层压缩
不同的LSM存储引擎，采用的针对合并压缩的优化方式可能不一样。
LevelDB和RocksDB使用分层压缩，HBase使用大小分级，Cassandra则同时支持这两种方法。

>大小分级：将SSTable进行分级，由第一级合并成第二级，第二级再合并成第三级…依次进行下去。当内存数据达到一定大小时，会将数据排序写入磁盘生成一个SSTable文件，这是第一级的SSTable文件。当第一级的SSTable文件达到m（一般为4）个时，将这m个第一级的SSTable文件合并成一个第二级的SSTable，同理，依次进行下去。

>分层压缩：将数据分层，最底层为L0，其上分别是L1，L2，L3…每一层的数据级差为10。层数越小的块，其保存的数据越少也越新。这种分层压缩的优势是同一层的块之间没有重复数据。因为层间的合并，都是将所有数据块都合并。如L0层数据每次都是与L1层数据合并，生成新的L1层。


#### 2.3 更新流派
更新流派的代表就是：B-tree。

>（1）B-tree像SSTable一样，保留按键排序的key-value对，这样可以实现高效的key-value查询和区间查询。
（2）但是在本质上，B-tree具有非常不同的设计。日志结构索引将数据库分解成可变大小的段，通常大小为几兆字节或更大，并且始终按顺序写入段。而B-tree将数据库分解成固定大小的块或页（传统上大小为4KB），页是内部读/写的最小单元。这种设计更接近底层硬件，因为硬盘也是以固定大小的块排列。

#### B-tree设计细节
#### 使用B-tree索引查找
>B-tree的基本单位是页，每个页面可以使用地址或者位置进行标识，这样可以让一个页面引用另一个页面。这类似指针，不过是指向磁盘地址，而不是内存。通过页面引用可以构造一个树状页面。
某一页被指定为B-tree的根，每当查找索引中的一个键时，总是从这里开始。该页面包含若干个键和对子页的引用。每个孩子都负责一个连续范围内的键，相邻引用之间的键可以指示这些范围之间的边界。

#### 添加新键与插入分裂
如果要添加新键，则需要找到其范围包含新键的页，并将其添加到该页。如果页中没有足够的可用空间来容纳新键，则将其分裂为两个半满的页，并且父页页需要更新以包含分裂之后的新的键范围。

这种算法是分析和理解B-tree结构的关键：B-tree始终要保持树平衡，从而使树深保持在O(log n)。因此， B-tree的读和查找效率很高，而写效率一般。

#### B-tree（更新）带来的三大问题
>（1）B-tree底层的基本写操作是使用新数据覆盖磁盘上的旧页。遵循的原则是：覆盖不会改变页的磁盘存储位置，也就是说，当页被覆盖时，对该页的所有引用保持不变。
对于SSD，由于SSD必须一次擦除并重写非常大的存储芯片块，情况会更加复杂。例如插入导致页溢出的情况，需要分裂页，从而写两个分裂的页，并且覆盖其父页以更新对两个子页的引用。这个操作非常危险，因为如果数据库在完成部分写入后发生崩溃，最终会导致索引破坏（可能产生孤儿页）。

>（2）为了使数据库能从崩溃中恢复，常见B-tree的实现需要支持磁盘上的额外数据结构：预写日志（write-ahead log，WAL），也称为重做日志。

>（3）原地更新页的另一个复杂因素是：如果多个线程要同时访问B-tree，则需要注意并发控制。否则线程可能会看到树处于不一致的状态。


#### B-tree优化措施
（1）写时复制方案：不使用覆盖页和维护WAL来进行崩溃恢复。修改的页被写入不同的位置，树中父页的新版本被创建，并指向新的位置。
（2）保存键的缩略信息，而不是完整的键。从而可以将更多的键压入到页中，让树具有更高的分支因子，从而减少层数。
（3）添加额外的指针到树中。例如，每个叶子页面可能会向左和向右引用其同级别的兄弟页，这样可以顺序扫描键，而不用跳回到父页。

### 2.4 LSM-tree与B-tree的对比
从总体性能来说，LSM-tree通常写入更快，而B-tree被认为读取更快。
<table><thead><tr><th>特性比较</th><th>LSM-tree</th><th>B-tree</th></tr></thead><tbody>
<tr><td>读取性能</td><td>读取性能不佳。因为采用追加更新;可能在不同段中具有相同键的多个副本;因此查找需要一直查下去&#xff1a;首先尝试在内存表中查找键;然后是最新的磁盘段文件;接下来是次新的磁盘段文件;以此类推;直到找到目标或为空</td><td>读取性能更好。采用原地更新;每个键都恰好对应索引中的某个位置。B-tree始终要保持树平衡;从而使树深保持在O(log n);查询很快。</td></tr>
<tr><td>写入性能</td><td>更低的写放大;定期重写SSTable以消除碎片化;从而具有更高的写入性能</td><td>B-tree的原地覆盖更新;导致即使某个页中只有几个字节更改;也必须承受写整个页的开销;写放大很大。并且极易产生碎片;导致某些磁盘空间无法使用。写性能不佳。</td></tr></tbody></table>


### 2.5 其它索引结构
### 二级索引
二级索引与主索引的最主要区别在于：它的键不是唯一的。

### 聚集索引和非聚集索引

>聚集索引：按照数据的物理存储进行划分，在索引中直接保存数据。
非聚集索引：强调的是逻辑分类（而非物理），定义了一套存储规则，存储索引中的数据的引用（堆文件）。堆文件的优点是：（1）当存在多个二级索引时，可以避免复制数据，即每个索引只引用堆文件中的位置信息，实际数据仍保存在一个位置。（2）当更新值而不更改键时，堆文件方法将非常高效。

聚集索引不同于主键，主键肯定是聚集索引，而聚集索引不一定就是主键。它可以唯一，也可以不唯一，取决于自定义的索引的unique 设置。

### 多列索引
最常见的多列索引是级联索引。
多维索引是更一般的通过多列索引的方法，尤其应用于地理空间数据。在这方面研究较少，还不能实用。

### 3. OLAP系统的存储引擎
   本章前面所讨论的索引算法适合OLTP，但不擅长应对分析查询，针对OLAP，目前主要有以下的存储引擎。

### 3.1 星型与雪花型分析模式
传统的数据仓库都相当公式化地使用了星型模式，也称为维度建模。

>（1）模式的中心是一个事实表。
（2）事实表的每一行表示在特定时间发生的事件。事实表的列是属性，列可能会引用其他表的外键，称为维度表。
（3）“星型模式”来源于当表关系可视化时，事实表位于中间，被一系列维度表包围，这些表的连接就像星星的光芒。
（4）将维度进一步细分为子空间，变体为雪花模式。

### 3.2 列式存储
如果事实表中有数以万亿行，PB大小的数据，则高效地存储和查询这些数据将成为一个具有挑战性的问题。这也是为什么大数据时代hbase列式存储流行的原因。

>面向列的存储布局依赖一组列文件，每个文件以相同顺序保存着数据行，不是将一行中所有值存储在一起，而是将每列中的所有值存储在一起。每个列存储在一个单独的文件中，查询只需读取和解析在该查询中使用的那些列，这可以节省大量的工作。
                
### 列压缩
面向列的存储非常适合压缩，这是因为列文件保存的是每一列的数据，同列数据往往数据类型和格式完全相同，这非常有利于压缩。

常见的两种压缩方法：位图编码、游程编码

### 列存储中的排序
注意：列存储中的排序是排序整行，单独排序每列是没有意义的。
排序的优点有二：

>（1）利于查询。
（2）有助于进一步压缩列。

### 3.3 聚合：数据立方体与物化视图

> （1）物化视图是查询结果的实际副本，并被写入到磁盘中。其实物化视图相当于提前预先做聚合计算，并将聚合结果保存，查询时直接调动，无需再临时做耗费时间的聚合计算。因此，当底层数据发生变化时，物化视图也需要随之更新。

>（2）物化视图的常见情况是：数据立方体。它是由不同维度分组的聚合网络。这个主要是第一个中国贡献的Apache顶级开源项目——kylin使用的，其查询速度超级快，目前在大数据分析领域备受关注。

> （3）物化视图（数据立方体）的优点是某些查询的速度相当快，远远超过其他大数据查询组件，主要是由于它们已经预先计算出来了。缺点是灵活性太差，并且预先的聚合也需要消耗很大的工作。预先聚合的结果保存需要消耗额外的内存和硬盘。

## 第四章 数据编码与演化

### 1. 模式演化

应用程序不可避免地需要随时间而变化、调整。当新产品推出，或为了更好地理解用户需求，或商业环境发生变化时，就需要不断添加或修改功能。
   特别地，许多服务需要支持滚动升级，即每次将新版本的服务逐步部署到几个节点，而不是同时部署到所有节点。滚动升级允许在不停机的情况下发布新版本的服务（因此鼓励频繁地发布小版本而不是大版本），并降低部署风险（允许错误版本在影响大量用户之前检测并回滚）。这些特性非常有利于应用程序的演化和更改。
   在滚动升级期间，或者由于各种其他原因，必须假设不同的节点正在运行应用代码的不同版本。因此，在系统内流动的所有数据都以提供向前兼容和向后兼容的方式进行编码显得非常重要。

### 2. 数据编码格式及兼容性情况
数据通常使用两种不同的数据表示形式：

>（1）在内存中：数据结构

>（2）在文件或传输中：字节序列

这两个表示之间需要进行类型的转化：从内存中的表示到字节序列的转化称为编码（序列化），相反的过程称为解码（反序列化）

### 2.1 语言特定的编码
编程语言特定的编码仅限于某一种编程语言，主要目标是快速且简单地编码数据，其存在很多深层次问题：

+ （1）编码与特定的编程语言绑定在一起，而用另一种语言访问数据就非常困难。
+ （2）为了在相同的对象类型中恢复数据，解码过程需要能够实例化任意的类，这经常导致一些安全问题。
+ （3）在这些库中，多版本数据通常是次要的，主要目标是快速且简单地编码数据，所以它们经常忽略向前或向后兼容问题。

基于这些原因，使用语言内置编码方案通常不是个好主意。

### 2.2 标准化编码：文本格式（JSON、XML与CSV）
JSON、XML和CSV都是标准化的文本格式编码，特别是作为数据交换格式（将数据从一个组织发送到另一个组织），它们非常受欢迎。

>JSON（JavaScript Object Notation）：JS对象简谱，是一种轻量级的数据交换格式，支持数字格式。

>XML（eXtensible Markup Language）：可扩展标记语言。不支持数字。

> CSV（Comma Separated Values）：逗号分隔值文件格式。不支持数字格式。


### 文本格式存在的一些问题
JSON、XML和CSV的兼容性取决于你如何使用它们。它们有可选的模式语言，这有时是有用的，有时却是一个障碍。这些文本格式对某些数据类型的支持有些模糊，必须小心处理数字和二进制字符串问题。
1.数字问题

>（1）在XML和CSV中，无法区分数字和碰巧由数字组成的字符串（除非引用外部模式）。因为XML和CSV不支持数字，无论解析给我们看的是数字还是字符串，都是以字符串形式存在，然后通过外部模式解析成数字或字符串。

> （2）JSON区分字符串和数字，但不区分整数和浮点数，并且不指定精度。

2.字符串问题

> JSON和XML对Unicode字符串（即人类可读文本）有很好的支持，但是它们不支持二进制字符串（没有字符编码的字节序列）

3.模式问题

> （1）XML 和JSON都有可选的模式支持。这些模式语言相当强大，因此学习和实现起比较复杂。

> （2）CSV没有任何模式，因此应用程序需要定义每行和每列的含义。如果应用程序更改添加新的行或列，则必须手动处理该更改。其实CSV也算是一个相当模糊的格式（如果一个值包含逗号或换行符，会发生什么）。尽管其转义规则已经被正式指定，但并不是所有的解析器都能正确实现它们。

XML 模式通常被称为 XML 模式定义（XSD）。它被用来描述和验证 XML 数据的结构和内容。XML 模式定义元素，属性和数据类型。

JSON 模式是一种基于 JSON 格式定义 JSON 数据结构的规范。

### 2.3 标准化编码：二进制格式（Thrift、Protocol Buffers和Avro）
这样的二进制模式驱动格式，支持使用清晰定义的向前和向后兼容性语义进行紧凑、高效的编码。这些模式对于静态类型语言中的文档和代码生成非常有用。然而，它们有一个缺点，即只有在数据解码后才是人类可读的。

Thrift和Protocol Buffers
>（1）Thrift 和Protocol Buffers（Protobuf）是基于相同原理的两种二进制编码库。
（2）Thrift最初是在Facebook开发的，Protocol Buffers最初是在Google开发的。
（3）Thrift 和Protocol Buffers都需要模式来编码任意的数据，然后再使用多语言编译工具将模式定义编译成对应语言的版本，以供特定语言使用。
（4）Thrift有三种不同的二进制编码格式：Binary-Protocol、Compact-Protocol和Dense-Protocol。但是因为Dense-Protocol只支持C++，不算是跨语言的标准化编码，一般被认为是特定语言的编码。

Binary-Protocol
在普通二进制编码的基础上进行改进，与普通的二进制编码的区别和联系：

>相同点：每个字段都有一个类型注释（用于指示它是否是字符串、整数、列表等），并且都可以在需要时指定长度。
区别：最大的区别是没有字段名，而是用数字类型的字段标签（1、2和3等）代替，这些数字标签就是模式定义里出现的数字。数字类型的字段标签相当于字段的别名，从而可以省略字段的全名引用，节省存储。

Compact-Protocol
在Binary-Protocol的基础上进行改进，可以大幅节省存储空间，其改进大致有两点：

>（1）将字段类型和标签打包到单字节中，并使用可变长度的整数来实现。
（2）对于数字，灵活使用字节编码，并不是全部使用完全的8个字节。例如-64~63之间的数字只需一个字节，-8192 ~8191之间需要两个字节，更大的数字才需要更多字节。

Protocol Buffers
与Compact-Protocol非常类似，只是它的位打包方式略有不同，并且没有list类型。

<table><thead><tr><th>特性比较</th><th>Compact-Protocol</th><th>Protocol Buffers</th></tr></thead><tbody>
<tr><td>打包方式</td><td>字段类型和标签打包为&#xff1a;4/4划分8位</td><td>字段类型和标签打包为&#xff1a;5/3划分8位</td></tr>
<tr><td>数字编码方式</td><td>以1337为例;保留13位;以7/6划分;然后;低位的6——&gt;1/6/0共8位;高位的7——&gt;0/7共8位</td><td>以1337为例;保留14位;以7/7划分;然后;低位的7——&gt;1/7共8位;高位的7——&gt;0/7共8位</td></tr>
<tr><td>list和array类型</td><td>有</td><td>无。取代的是有字段的重复标记;对于重复字段;表示同一个字段标签只是简单地多次出现在记录中。</td></tr></tbody></table>


字段标签和模式演化

一条编码记录只是一组编码字段的拼接。每个字段由其标签号标识，并使用数据类型进行注释。如果没有设置字段标识，则将其从编码的记录中简单地忽略。由此可见，字段标签对编码数据的含义至关重要。
如何进行模式演化？

>向前兼容：可以添加新的字段到模式，只要给每个字段一个新的标记号码。当旧的代码试图读取新代码写入的数据，则包含有它不能识别的标记号码，那么它会自动忽略该标记号码标记的字段。实现时，通过数据类型的注释来通知解析器跳过特定的字节数。

>向后兼容：只要每个字段都有一个唯一的标记号码，新的代码总是可以读取旧的数据，因为标记号码仍然具有相同的含义。唯一的要求是不能重复添加相同字段。因此，在模式初始部署之后添加的每个字段都必须是可选的（未有字段）或具有默认值（已有字段）。

Avro
由于前面的两种二进制编码格式：Thrift和Protocol Buffers不适合Hadoop的用例，因此Avro在2009年作为Hadoop的子项目而启动。
Avro也使用模式来指定编码的数据结构。它有两种模式语言：

Avro IDL：用于人工编辑。
基于JSON：更易于机器读取。

Avro与Thrift和Protocol Buffers的显著不同在于：没有标签来标识字段和数据类型。因此它远比Thrift和Protocol Buffers更节省空间。

那么问题来了：

没有字段标签和数据类型标签，如何正确解码二进制数据？
那么问题来了：

>没有字段标签和数据类型标签，如何正确解码二进制数据？

>采取了最笨但是却是最安全的方法：按照二进制数据出现在模式中的顺序遍历这些字段，然后直接采用模式告诉你每个字段的数据类型。

>这意味着：只有当读取数据的代码使用与写入数据的代码完全相同的模式时，才能正确解码二进制数据。读和写的模式如果有任何不匹配，都将无法解码数据。（特别注意！这里读模式和写模式只要匹配即可，并没有要求顺序完全一致，即使顺序不一致，也可以匹配。）


### Avro如何支持模式演化？
（1）写模式与读模式

>写模式：当应用程序想要对某些数据进行编码时，它使用所知道的模式的任何版本来编码数据。

>读模式：当应用程序想要解码某些数据时，它期望数据符合某个模式，即读模式。这是应用程序代码所依赖的模式。

Avro 的关键思想是：写模式和读模式不必完全一模一样，它们只需保持兼容。当数据被解码时，Avro库通过对比查看写模式和读模式，并将数据从写模式转换为读模式来解决差异。Avro规范明确定义了这种解决方法的工作原理。
例如：比较重要和值得关注的三个规则是：
> 第一、如果写模式和读模式的字段顺序不同，也没有问题。因为模式解析通过字段名匹配字段。

> 第二、如果读取数据的代码遇到出现在写模式但不在读模式中的字段，则忽略它。

> 第三、如果读取数据的代码需要某个字段，但是写模式不包含该字段，则使用在读模式中声明的默认值填充。

（2）模式演化规则

> 向前兼容：将新版本的模式作为writer（写模式），将旧版本的模式作为reader（读模式）

> 向后兼容：将新版本的模式作为reader（读模式），将旧版本的模式作为writer（写模式）
一兆韦德新店
保持兼容性的策略：只能添加或删除具有默认值的字段。
根据前面Avro匹配规范的第二、第三条规则，如果我们规定在新版本中，只能添加或删除具有默认值的字段，则向前兼容，向后兼容均能完美解决。
为什么一定要求“具有默认值”？理解两点：

> 1.如果要添加一个没有默认值的字段，不会影响向前兼容性。但是新的reader将无法读取旧的writer写的数据，因此，将破坏向后兼容性。

> 2.如果要删除没有默认值的字段，不会影响向后兼容性。但是旧的reader将无法读取新的writer写入的数据，因此，将破坏向前兼容性。

（3）reader如何知道特定的数据采用哪个writer的模式编码？
取决于Avro使用的上下文，具体场景具体分析：

> 1.有很多记录的大文件：该文件的writer可以仅在文件的开头包含writer的模式信息。Avro通过指定一个文件格式来做到这一点。

> 2.具有单独写入记录的数据库：在数据库中，不同的记录可能在不同的时间点、使用不同的writer模式编写，显然不能粗暴地假设所有记录都具有相同的模式。最简单的解决方案是在每个编码记录的开始处包含一个版本号，并在数据库中保留一个模式版本列表。reader可以获取记录，提取版本号，然后从数据库中查询该版本号的writer模式。

> 3.通过网络连接发送记录：当两个进程通过双向网络连接进行通信时，他们可以在建立连接时协商模式版本，然后在连接的生命周期中使用该模式。这也就是Avro RPC协议的基本原理。


### Avro的优点
显而易见，Avro不包括任何标签号，可以大幅节省存储空间。

由于Avro不包括任何标签号，其对于动态生成的模式更友好。具体体现在，例如转储关系型数据库到一个文件：

使用Avro时，很容易就可以根据关系模型生成Avro模式，并使用该模式对数据库内容进行编码，然后将其全部转储到Avro对象容器文件中。如果数据库模式发生变化，则简单地从更新的数据库模式中生成新的Avro模式即可（有专门的API可用），并用新的Avro模式导出数据。数据导出过程不需要关注模式的改变，每次运行时都可以简单地进行模式转换，并且更新的writer模式仍然可以与旧的reader模式匹配。

相比之下，如果使用Thrift和Protocol Buffers，则每次数据模式更改时，管理员都必须手动更新从数据库列名到字段标签的映射。

Avro为静态类型编程语言提供了可选的代码生成，它既支持代码生成，也可以在不生成代码的情况下直接使用，这方便了动态类型编程语言。

静态类型编程语言：Java，C++，C#
静态生成的模式：Thrift和Protocol Buffers。它们依赖于代码生成：在定义了模式之后，可以使用选择的编程语言生成实现此模式的代码。

代码生成在对这些静态编译语言很有用，因为它允许使用高效的内存结构来解码数据，并且在编写访问数据结构的程序时，支持在IDE中进行类型检查和自动完成。

动态类型编程语言：JavaScript，Ruby，Python
动态生成的模式：Avro。

对于动态类型编程语言，由于没有编译时类型检查，生成代码没有太多意义。对于动态生成的模式的情况，代码生成对获取数据反而是不必要的障碍。

### 3. 数据流模式
数据可以从一个进程流向另一个进程，本节将探讨一些最常见的进程间数据流动的方式。

基于数据库的数据流
>写入数据库的进程对数据进行编码，而读取数据库的进程对数据进行解码。

>数据库肯定需要向后兼容，而大多数情况下向前兼容同样要保证。例如：

>当用旧版本的应用程序更新新版本的应用程序所写入的数据时，可能会丢失未知字段（这是由于读写模式的原理决定的），解决方法如下：

部署新版本的应用程序时，用新版本完全替换旧版本当然是可行的，但是对于数据库这可能耗费相当长的时间，一般是不被允许的。通过添加具有默认值为空的新列，而不重写现有数据可以解决。（这其实就是Avro模式演化采取的规则）

基于服务的数据流：REST和RPC

客户端对请求进行编码，服务器对请求进行解码并对响应进行编码，客户端最终对响应进行解码。

面向服务/微服务体系结构的一个关键设计目标是：通过使服务可独立部署和演化，让应用程序更易于更改和维护。换句话说，应该期望新旧版本的服务器和客户端同时运行，因此服务器和客户端使用的数据编码必须在不同版本的服务API之间兼容，这正是本节讨论的内容。

流行的web服务方法

两种流行的Web服务方法：

> REST：不是一种协议，而是一种基于HTTP原则的设计理念。它强调简单的数据格式，使用URL来标识资源，并使用HTTP功能进行缓存控制、身份验证和内容类型协商。最受欢迎，互操作性更好。

>SOAP：是一种基于XML的协议，用于发出网络API请求。虽然它最常用于HTTP，但其目的是独立于HTTP，并避免使用大多数HTTP功能，它带有庞大复杂的多种相关标准，不受欢迎，互操作性也存在一些问题。

### 远程过程调用（RPC）
前面所讲的web服务仅仅是通过网络发出API请求的一系列技术的最新体现，所有这些都是基于远程过程调用（RPC）的思想。

RPC的问题
RPC 模型试图使向远程网络服务发出的请求看起来与在统一进程中调用编程语言中的函数或方法相同（这种抽象成为位置透明）。但是残酷的现实已经告诉我们，网络请求和本地函数调用非常不同！尝试使远程服务看起来像编程语言中的本地对象一样是毫无意义的。

RPC的发展方向
虽然有各种问题，但是RPC并没有消失，而是在各种编码的基础上构建各自不同的多种RPC框架。例如Thrift和Avro带有RPC支持，gRPC是使用Protocol Buffers的RPC实现，Rest.li使用HTTP上的JSON等。
新一代的RPC框架更加认清了现实，明确了远程请求和本地函数调用不同的事实。差异化发展，优化各自的独特功能。

基于消息传递的数据流
异步消息传递（使用消息代理或Actor），节点之间通过互相发送消息进行通信，消息由发送者编码并由接收者解码。

异步消息传递系统与RPC相比，优点在于：

>（1）它在逻辑上将发送方和接收方分离（发布方只是发布消息，并不关心谁使用它们）
（2）它支持将一条消息发送给多个接收方。
（3）它避免了发送方需要知道接收方的IP地址和端口号。
（4）如果接收方不可用或过载，它可以充当缓冲区，从而提高系统的可靠性
（5）它可以自动将消息重新发送到崩溃的进程，从而防止消息丢失。

这些优点，主要是由于消息传递通信通常是单向、异步的。

并发线程中通信的两种策略：共享数据和消息传递。和共享数据方式相比，消息传递机制最大的优点是不会产生数据竞争状态。

实现消息传递的两种常见类型：

> 基于channel的消息传递（消息代理）:保证消息传送，防止消息丢失。即使进程崩溃，仍然会保证消息传送。

> 基于Actor的消息传递（分布式Actor框架）：不保证消息传送，可能会消息丢失。


# 第五章 数据复制

## 1. 数据复制的目的

复制主要指通过互联网络在多台机器上保存相同数据的副本。复制主要用于以下目的：

>（1）高可用：即使某台机器出现故障，系统也能保持正常运行。

> （2）低延迟：将数据放置在距离用户较近的地方，从而实现更快地交互。

> （3）可扩展：采用多副本读取，大幅提高系统读操作的吞吐量。

> （4）高容错：允许应用程序在出现网络中断时继续工作。

## 2. 数据复制方案及问题讨论
主要有三种复制方案：主从复制、多主节点复制和无主节点复制。

### 2.1 主从复制

所有的客户端写入操作都发送到主节点，由主节点负责将数据更改事件发送到其它副本（从节点）。每个副本都可以接收读请求，但内容可能是过期值。

主从复制原理
> 指定一个节点为主节点。当客户端写数据库时，必须将写请求发送给主节点，主节点将数据首先写入本地存储。

>其它副本都是从节点。主节点将数据写入本地存储后，然后将数据更改以日志或更改流的方式发送给所有的从节点。每个从节点获得更改日志后将其应用到本地，且严格保持与主节点相同的写入顺序。

> 客户端读数据时，可以在主节点或从节点执行查询。只有主节点才可以接受写请求，从节点都是只读的！

> 主从复制问题

>主从复制是最经典也使用最广泛的复制方案，但是仍然有许多问题需要考虑。


### 主从复制问题

主从复制是最经典也使用最广泛的复制方案，但是仍然有许多问题需要考虑。

### 同步异步问题

+ 同步复制：主节点需等待直到从节点确认完成写入，才会向客户端报告完成。
+ 异步复制：主节点向从节点发送完消息之后立即返回，向客户端报告完成，不用等待从节点的完成确认。

同步异步的优缺点分析：
<table><thead><tr><th>优缺点比较</th><th>同步复制</th><th>异步复制</th></tr></thead><tbody>
<tr><td>优点</td><td>安全性高。一旦向用户确认;从节点可以明确保证完成了与主节点的更新同步;数据已经处于最新版本。万一主节点发生故障;总是可以在从节点继续访问最新的数据。</td><td>效率高;吞吐性能好。不管从节点上数据多么滞后;主节点不需要确认从节点写入;主节点总是可以响应写请求;系统的吞吐性能好。</td></tr>
<tr><td>缺点</td><td>效率低下。只要同步的从节点无法完成确认;写入就不能视为成功。主节点会阻塞其后所有的写操作;直到同步副本确认完成</td><td>安全性低下;可能导致数据丢失。如果主节点发生崩溃且不可恢复;则所有尚未复制到从节点的写请求都会丢失。</td></tr></tbody></table>

在实践中，将所有从节点都配置成同步复制是不必要且不切实际的。一般情况下，如果数据库启用了同步复制，通常意味着 其中某一个节点是同步的，而其他节点则是异步模式。这样可以保证至少有两个节点拥有最新的数据副本。这种配置也被成为“半同步”。

新的从节点如何复制数据？

主要逻辑是：主节点产生快照，将快照拷贝到新的从节点，从节点连接到主节点并请求快照点之后所发生的数据更改日志，获得日志后，从节点应用这些快照点之后的所有数据变更，这个过程称为“追赶”。

如何处理节点失效？

+ 从节点失效：追赶式恢复

> 从节点的本地磁盘上都保存了副本收到的数据变更日志。如果从节点发生崩溃，根据日志，从节点可以知道在发生故障之前所处理的最后一笔事务，然后连接到主节点，并请求自那笔事务之后的所有数据变更。在收到这些数据变更日志之后，将其应用到本地来追赶主节点。

+ 主节点失效：节点切换

>如果主节点失效，问题则比较复杂，这里面涉及很多细节考量。总的来说，解决思路是固定的：选择某个从节点将其提升为主节点，客户端也需要更新，这样之后的写请求会发送给新的主节点，然后其他从节点要接收来自新的主节点的变更数据，这一过程称为切换。

>自动切换的步骤：
> 
>（1）确认主节点失效
> 
>（2）选举新的主节点
> 
>（3）重新配置系统，使新的主节点生效。

### 复制日志的实现
主从复制技术的实现依赖于复制的日志，这在实践中有多种不同的实现方法：

+ 基于语句的复制

这是最简单的情况，主节点记录所执行的每个写请求，并将该操作语句作为日志发送给从节点。这种复制日志最简单直观，但有一些不适用的场景：

>（1）任何调用了非确定性函数的语句，如NOW（）获取当前时间，RAND（）获取一个随机数等，可能会在不同的副本上产生不同的值。
> 
>（2）如果语句中使用了自增列，则所有的副本必须按照完全相同的顺序执行，否则可能会产生不同的结果。在这种情况下，如果有多个同时并发执行的事务，会有很大的限制。
>
>（3）有副作用的语句（如：触发器，存储过程，用户定义的函数等），可能会在每个副本上产生不同的副作用。

这种复制日志方式主要应用于MySQL5.1之前的版本。

+ 基于预写日志传输

所有对数据库写入的字节序列都被计入日志，因此可以使用完全相同的日志在另一个节点上构建副本，除了将日志写入磁盘外，主节点还可以通过网络将其发生给从节点。从节点收到日志进行处理，建立和主节点内容完全相同的数据副本。

PostgreSQL、Oracle支持这种复制方式。
主要缺点：日志描述的数据结果非常底层：一个WAL包含了哪些磁盘块的哪些字节发生改变，诸如此类的细节。这使得复制方案和存储引擎紧密耦合。如果数据库的存储格式从一个版本改为另一个版本，那么系统通常无法支持主从节点上运行不同版本的软件。

对运营产生的影响：如果复制协议允许从节点的软件版本比主节点更新，则可以实现数据库软件的不停机升级。首先升级从节点，然后执行主节点切换，使升级后的从节点成为新的主节点。但是WAL传输，要求版本必须严格一致，那么势必以停机为代价。

+ 基于行的逻辑日志复制
由于WAL传输的问题，另一种方法是复制和存储引擎采用不同的日志格式，这样复制和存储逻辑剥离。这种复制日志称为逻辑日志，以区分物理存储引擎的数据表示。

关系数据库的逻辑日志通常是指一系列记录来描述数据表行级别的写请求：

>（1）对于行插入：日志包含所有相关列的新值
> 
>（2）对于行删除：日志里有足够的信息来唯一标识已删除的行。主要是靠主键，但如果表上没有定义主键，就需要记录所有列的旧值。
>
>（3）对于行更新，日志包含足够的信息来唯一标识更新的行，以及所有列的新值。

基于行的逻辑日志的优势：

>（1）由于逻辑日志和存储引擎逻辑解耦，因此更容易地保持向后兼容，从而使主从节点能够运行不同版本的软件甚至是不同的存储引擎。
>
>（2）对于外部应用程序来说，逻辑日志程序也更容易解析。如果要将数据库的内容发送到外部系统（如离线分析的数据仓库），或者构建自定义索引和缓存等，基于逻辑日志的复制更有优势。

基于触发器的复制

前面的三种复制方法都是由数据库系统来实现的，不涉及任何应用程序代码。为了实现更高的灵活性，例如，只想复制数据的一部分，或者想从一种数据库复制到另一种数据库，或者需要定制、管理冲突解决逻辑，则需要将复制控制交给应用程序层。

通过触发器技术，可以将数据更改记录到一个单独的表中，然后外部处理逻辑访问该表，实施必要的自定义应用层逻辑。越灵活，越容易出错，基于触发器的复制通常问题多多。

## 复制滞后问题
对于异步复制，由于各种问题可能会出现复制滞后。如果一个应用正好从一个异步的从节点读取数据，而该副本落后于主节点，则应用可能会读到过期的信息。从而导致数据库中出现明显的不一致。复制滞后可能出现的三个关键问题如下：

+ 读自己的写

表现场景：用户在写入不久即查看数据，则新数据可能尚未到达从节点。在用户看来，似乎是刚刚提交的数据丢失了。

解决方法：保证“写后读一致性”，也称为读写一致性。该机制保证如果用户重新加载页面，他们总能看到自己最近提交的更新。

+ 单调读

表现场景：用户看到了最新内容之后又读到了过期的内容，出现了用户数据向后回滚的奇怪情况，好像时间被回拨。

解决方法：保证“单调读一致性”，这是一个比强一致性弱，但是比最终一致性强的保证。该机制保证如果用户依次进行多次读取，则他绝不会看到回滚现象，即在读取较新值之后又发生读旧值的情况。实现单调读一致性的最简单方式是：确保每个用户总是从固定的同一副本执行读取。

+ 前缀一致读

表现场景：这是分区（分片）数据库中出现的一个特殊问题。分区数据经多副本复制后出现了不同程度的滞后，导致观察者先看到果，后看到因。

解决方法：保证“前缀一致读”。该机制保证，对于一系列按照某个顺序发生的写请求，那么读取这些内容时也会按照当时写入的顺序。实现前缀一致读的最简单方式是：确保任何具有因果顺序关系的写入都交给一个分区来完成。

## 2.2 多主节点复制

系统存在多个主节点，每个都可以接收写请求，客户端将写请求发送到其中的一个主节点上，由该主节点负责将数据更改事件同步到其它主节点和自己的从节点。

适用场景

在一个数据中心内部使用多节点基本没有太多意义，多主节点主要的应用场景如下：

多数据中心

在每个数据中心都配置主节点；

> 在每个数据中心内，仍然采用常规的主从复制方案；
>
>在数据中心之间，由各个数据中心的主节点来负责同其他数据中心的主节点进行数据的交换、更新。

多数据中心的优势：

>（1）性能更好。传统的一个数据中心的主从复制，所有写请求都要由广域网传送至主节点所在的数据中心，这大大增加了写入延迟。多数据中心的设计，就近原则。使得每个写操作都可以在本地数据中心快速响应，然后采用异步复制方式将变化同步到其它数据中心。这相当于屏蔽了数据中心之间的网络延迟，极大地提高了性能。
>
>（2）容错性更好。只有一个数据中心，如果主节点所在的数据中心发生故障，必须进行主从切换，这中间涉及全部从节点的认主问题。多数据中心则不必那么麻烦，每个数据中心都是独立于其他数据中心的，只需要将发生故障的数据中心进行切换即可，影响范围极大地缩小了。
>
>（3）可靠性更好。数据中心之间由于地域的限制，通常使用广域网，它往往不如数据中心内的本地网络可靠。多数据中心之间通常采用异步复制，可以更好地容忍此类问题。

多数据中心的缺点;

不同数据中心可能会同时修改相同的数据，因此必须解决潜在的写冲突。

离线客户端操作
另一种多主复制比较适合的场景是：应用在与网络断开后还需要继续工作。

这种情况下，每个设备都有一个充当主节点的本地数据库，然后在所有设备之间采用异步方式同步这些多主节点上的副本，同步时间可能是数个小时或者几天，具体时间取决于设备何时可以再次联网。

从架构层面看，上述设置基本等同于数据中心之间的多主复制，只不过是极端情况，即一个设备就是一个数据中心，而且他们之间的网络连接非常不可靠。

协作编辑

实时协作编辑应用程序允许多个用户同时编辑文档，它不完全等价于数据库复制问题，但两者有很多相似之处。当一个用户编辑文档时，所做的更改会立即应用到本地副本，然后异步复制到服务器以及编辑同一文档的其它用户。

为了确保不会发生编辑冲突，应用程序必须先将文档锁定，然后才能对其进行编辑。如果另一个用户想要编辑同一个文档，首先必须等到第一个用户提交修改并释放锁，这相当于在主节点上执行事务操作。

最大问题

多主复制的最大问题是可能产生写冲突。

如果是主从复制数据库，第二个写请求会被阻塞直到第一个写完成，要么被中止。但是在多主复制模式，这两个写请求都是成功的，并且只能在稍后的时间点才能异步检测到冲突。

我们既不想丧失多主节点的优势，又想解决了冲突问题。该怎么做？

避免冲突

>（1）最理想的解决冲突的策略是避免发生冲突，即如果应用层可以保证对特定记录的写请求总是通过同一个主节点，这样就不会发生写冲突。
>
>（2）实践中实现，不同的用户总是对应不同的数据中心，并只在该数据中心的主节点上进行读写。

收敛于一致状态

多主节点复制模型的最终不一致性：

>（1）对于主从复制，如果同一个字段有多个更新，则最后一个写操作将决定该字段的最终值。无论如何，都能达到最终一致性。
>
>（2）对于多主节点复制，因为有多个主节点，没有绝对一致的写入顺序，每个副本都只是按照它看到的写入顺序执行，那么数据库将处于最终不一致状态。

最终一致性是复制模型的最基本要求，因此多主节点复制模型必须以一种收敛趋同的方式来解决冲突。实现收敛的冲突解决方案有如下几种：

>（1）基于时间戳：最后写入者获胜。
>
>（2）基于ID：最高（级别）写入者获胜。为每个副本分配一个唯一的ID ，规则为：序号高的副本写入始终优先于序号低的副本。
>
>（3）利用预定义好的格式来记录和保留冲突相关的所有信息，然后依靠应用层的逻辑，事后解决冲突

自定义冲突解决逻辑

解决冲突的最合适方式还是依靠应用层，绝大多数多主节点复制模式都有工具来让用户编写应用代码来解决冲突。

>（1）在写入时执行：只要数据库系统在复制变更日志时检测到冲突，就会调用应用层的冲突处理程序。
>
>（2）在读取时执行：当检测到冲突时，所有冲突写入值都会暂时保存下来。下一次读取数据时，会将数据的多个版本读返回给应用层。应用层提示用户解决或者自动解决冲突并将最终结果返回到数据库。

自动冲突解决
有一些有意思的研究尝试自动解决并发修改所产生的冲突（这是好的。），如下：

>（1）无冲突的复制数据类型
>
>（2）可合并的持久数据结构

>（3）操作转换

## 多主节点模型的拓扑结构
常见的有三种拓扑结构：环形拓扑、星形拓扑和全部-至-全部型拓扑。

>（1）目前基本都使用全部-至-全部型拓扑：每个主节点将其写入同步到其它所有主节点。
> 
>（2）MySQL比较特别，默认只支持环形拓扑：每个主节点接收前序主节点的写入，并将这些写入转发给后序主节点。
> 
>（3）基本没有使用星形拓扑：一个指定的根节点将写入转发给所有其它节点。（这种方式不就是主从复制吗？和多主节点没啥关系了）

环形和星形拓扑的问题是：如果某一个节点发生了故障，在修复前，会影响其它节点之间复制日志的转发。
全部-至-全部型拓扑的问题是：存在某些网络链路比其他链路更快的情况，从而导致复制日志之间的覆盖。

## 2.3 无主节点复制
没有主节点，客户端将写请求发送到多个节点上，读取时从多个节点上并行读取，以此检测和纠正某些过期数据。

其实最早的数据复制系统就是无主节点的（去中心复制），但是后来被关系型数据库主导时代了。当亚马逊采用了Dynamo系统后，无主复制再次流行了起来。Riak，Cassandra，Voldemort都是受Dynamo的启发而设计的无主节点，开源数据库系统，这类数据库也被称为Dynamo风格数据库。

无主节点复制的读取和写入操作总是并行发送到所有的副本，并根据节点的响应情况作出判断，这里面涉及如下重要问题：

节点失效

读写quorum——判断读写是否有效

>仲裁条件： ω + r > n 。表示如果有 n ,n个副本，写入需要w 个节点确认，读取至少需要查询r rr个节点，则达到仲裁条件可以认为写入成功，读取的节点节点中一定会包含最新值。满足上述的w、r 也被称为法定票数写和法定票数读，也可以认为w 、r 是用来判定写、读是否有效的最低票数（必须同时满足）。如果可用节点数小于所需的w 或r ，则写入或读取就会返回错误。

>（1）在Dynamo风格的数据库中，参数w 、r 通常是可配置的。
>
>(2) 最常见的配置是设置n nn为奇数，然后w = r = ( n + 1 )（向上取整）
>
>（3）可以根据需求和应用场景，灵活配置。例如，对于读多写少的负载，设置w = n 和r = 1 比较适合，这样读取速度更快，缺点是一个失效的节点就会使得数据库所有写入因无法满足quorum而失败。（当w = n 和r = 1 时，得到的是WARO机制：在更新时写所有副本，只有所有副本中更新都成功才算成功，保证了所有副本的一致性。此时，读取时读取任意一个副本即可。）

读修复和反熵——修复失效节点

任何复制模型的最基本要求是：确保所有的数据最终复制到所有的副本，在所有副本上达到最终一致性。当一个失效的节点重新上线之后，它如何赶上中间错过的写请求呢？

>（1）读修复：当客户端并行读取多个副本时，可以检测到过期的返回值。这种方法主要适合那些被频繁读取的场景。读修复的问题是：只有在发生读取时才可能执行修复，那些很少访问的数据有可能在某些副本中已经丢失而无法检测到。
>
>（2）反熵：一些数据存储有后台进程不断查找副本之间数据的差异，将任何缺少的数据从一个副本复制到另一个副本。反熵过程的缺点是：并不保证以特定的顺序复制写入，并且会引入明显的同步滞后。

Quorum一致的局限性

仲裁条件失效

即使在 ω + r > n 的情况下，也可能存在返回旧值的边界条件。可能的情况包括：

> 如果采用sloppy quorum，写操作的w 个节点和读取的r 个节点可能完全不同（因为这里涉及节点集合n之外的节点），因此，无法保证读写请求一定存在重叠的节点。
> 
> 如果具有新值的节点后来发生了失效，但恢复数据来自某个旧值，则总的新值副本数实际会低于w ww，这就打破了之前的判定条件。
> 
> 即使一切工作正常，也会出现一些边界情况，例如“可线性化与quorum”

监控旧值

人的容忍度是有限的，而最终一致性的实现时间不确定的，那么旧值的落后就没有一个上限。即使应用程序可以容忍读取旧值，也需要仔细监控了解复制的当前运行状态。如果出现了明显的滞后，它就是一个重要的信号提醒我们需要采取必要措施来排查原因。

主从复制已经建立了完善的统一监控模块，可以导出复制滞后的相关指标。而对于无主节点复制系统，并没有固定的写入顺序，因而监控就变的更加困难。如果数据库只支持读时修复（不支持反熵），旧值的落后就没有一个上限。

sloppy quorum与数据回传

在一个大规模集群中，客户可能在网络中断期间还能连接到某些数据库节点，但这些节点又不是能够满足数据仲裁的那些节点。此时，数据库设计者就面临着一个选择：

>（1）如果无法达到w 或r 所要求的quorum，将错误明确的返回给客户端？
>
>（2）或者，我们应该接受该写请求，只是将它们暂时写入一些可访问的节点中？（需要注意的是：这些节点并不在n个节点集合中）

后一种方案就是放松的仲裁（sloppy quorum）：写入和读取仍然需要w 和r 个成功的响应，但包含了那些并不在先前指定的n个节点。一旦网络问题解决，临时节点需要把接收到的写入全部发送到原始主节点上，这就是数据回传。

sloppy quorum的优点：提高写入可用性
>带来的问题是：即使满足w + r > n，也不能保证在读取时，一定可以读到最新值，因为新值可能被临时写入n nn之外的某些节点且尚未传回来。

检测并发写
>Dynamo数据库允许多个客户端对相同的主键同时发起写操作，即使采用严格的quorum机制也可能会发生写冲突。

如何保证最终一致性？

核心的问题是：由于网络延迟不稳定或局部失效，请求在不同的节点上可能会呈现不同的顺序。我们希望副本可以收敛于相同的内容，这样才能达到最终一致，但是以谁为准？

最后写入者获胜

>为每个写请求附加一个时间戳，然后选择最新的时间戳，丢弃较早时间戳的写入。

避免并发

>要想完全避免LWW完全无副作用的唯一方法是：只写入一次然后写入值视为不可变，这样就避免了对同一个主键的并发写。例如，Cassandra的一个推荐使用方法就是采用UUID作为主键，这样每个写操作都针对不同的、系统唯一的主键。

并发的问题

并发处理
服务器判断操作是否并发的依据主要依靠对比版本号（或时间戳），而不需要解释新旧值本身。算法的工作流程如下：
> （1）服务器为每个主键维护一个版本号，每当主键新值写入时递增版本号，并将新版本号与写入的值一起保存。
> 
> （2）当客户端读取主键时，服务器将返回所有（未被覆盖）的当前值以及最新的版本号。
> 
> （3）客户端写主键，写请求必须包含之前读到的版本号，读到的值和新值合并后的集合。
> 
> （4）当服务器收到特定版本号的写入时，覆盖该版本号或更低版本的所有值（因为这些值已经被合并到新传入的值集合中），但必须保存更高版本号的所有值（因为这些值与当前的写操作属于并发）

并发删除

并发合并在删除时不能简单地从数据库删除，系统必须保留一个对应的版本号以恰当的标记该项目需要在合并时被剔除，这种删除标记被称为“墓碑”。



# 第六章 数据分区
1. 数据分区方式
 
基于关键字区间分区
>  （1）为每个分区分配一段连续的关键字或关键字区间范围。
>
> （2）关键字的区间段不一定要均匀分布，这主要是因为数据本身非常可能就不均匀。比如单词表，以x，i，o等开头的单词显然很少很少。为了均匀分布数据，分布边界应该适配数据本身的分布特征。
>
> （3）基于关键字的区间分区的缺点是某些访问模式会导致热点。（比如关键字按天，节假日数据肯定会有明显不同）

基于关键字区间分区的问题：

> （1）数据倾斜：如果分区不均匀，则会出现某些分区节点比其他分区承担更多的数据量或查询负载，称之为数据倾斜
> 
> （2）热点：数据倾斜会导致分区效率严重下降，极端情况下，所有的负载可能会集中在一个分区节点上，这种负载严重不成比例的分区即成为系统热点。

基于关键字哈希值分区
针对数据倾斜和热点问题，许多分布式系统采用了基于关键字哈希函数的方式来分区。

> 基于关键字哈希值分区，可以很好地将关键字均匀地分配到多个分区中。分区边界可以是均匀间隔。但是这种情况下可能并不能均匀分配负载，此时就需要一致性哈希。
> 
> 基于关键字哈希值分区的缺点是：丧失了良好的区间查询特性。
> 
> 基于哈希的分区可以减轻热点，但无法做到完全避免。一个极端情况是：所有的读/写操作都是针对同一个关键字，则最终所有请求都将被路由到同一个分区。（比如当年的鹿晗关晓彤事件）。大多数系统今天仍然无法自动消除这种高度倾斜的负载，而只能通过应用层来减轻倾斜程度。例如，如果某个关键字被确认为热点，一个简单的技术是在关键字的开头或结尾添加一个随机数，只需要一个两位数的十进制随机数就可以将关键字的写操作分布到100个不同的关键字，从而分配到不同的分区。

2. 分区与二级索引
 
 二级索引通常不能唯一标识一条记录，而是用来加速特定值的查询。二级索引带来的主要挑战是它们不能规整地映射到分区中。有两种主要的方法来支持对二级索引进行分区：基于文档的分区和基于词条的分区。

基于文档分区的二级索引

>这种索引方法中，每个分区完全独立，各自维护自己的二级索引，且只负责自己分区内的文档而不关心其它分区中数据。文档分区索引也被称为本地索引，而不是全局索引。因此，这种查询分区数据库的方法有时也被称为分散/聚集，显然这种二级索引的查询代价高昂。即使采用了并行查询，也容易导致读延迟显著放大。

基于词条的二级索引分区

> 对所有的数据构建全局索引，而不是每个分区维护自己的本地索引。而且，为了避免成为瓶颈，不能将全局索引存储在一个节点上，否则就破坏了设计分区均衡的目标。所以，全局索引也必须进行分区，且可以与数据关键字采用不同的分区策略。

>主要优点是：读取更加高效，它不需要采用scatter/gather对所有的分区都执行一遍查询。
>
>主要缺点是：写入速度较慢且非常复杂，主要因为单个文档的更新时，里面可能会涉及多个二级索引，而二级索引的分区又可能完全不同甚至在不同的节点上，由此势必引入显著的写放大。

3. 分区再平衡

随着时间的推移，数据库可能总会出现某些变化：

> （1）查询压力增大，因此需要更多的CPU来处理负载。
> 
> （2）数据规模增加，因此需要更多的磁盘和内存来存储数据。
> 
> （3）节点可能出现故障，因此需要其他机器来接管失效的节点。

所有这些变化都要求数据和请求可以从一个节点转移到另一个节点。这样一个迁移负载的过程称为再平衡。无论哪种分区方案，分区再平衡需要满足：

> （1）平衡之后，负载、数据存储、读写请求等应该在集群范围内更均匀分布。
> 
> （2）再平衡执行过程中，数据库应该可以继续正常提供读写服务。
> 
> （3）避免不必要的负载迁移，以加快动态再平衡，并尽量减少网络和磁盘I/O影响。

动态再平衡的策略

固定数量的分区

>创建远超实际节点数的分区数，然后为每个节点分配多个分区。选中的整个分区会在节点之间迁移，但分区的总数量仍维持不变，也不会改变关键字到分区的映射关系。这里唯一需要调整的是分区和节点的对应关系。

动态分区
>设置固定边界、固定数量的分区非常不便，而手动重新配置分区边界又非常繁琐。因此，一些数据库如Hbase和RethinkDB采用了动态创建分区。当分区的数据增加超过一个可配的参数阈值，它就拆分成两个分区。每个承担一半的数据量。相反，如果大量数据被删除，并且分区缩小到某个阈值以下，则将其与相邻分区进行合并。

动态分区的优点是：分区数量可以自动适配数据总量。

>动态分区的问题是：对于一个空的数据库，因为没有任何先验知识可以帮助确定分区的边界，所以可能会从一个分区开始。可能初始数据集很小，但直到第一个分裂点之前，所有的写入操作都必须由单个节点来处理，而其他节点则处于空闲状态。为了缓解这个问题，Hbase和MongoDB允许在一个空的数据库上配置一组初始分区（这称为预分裂）

按节点比例分区

>前面所讲的两种分区策略，分区数量都与节点数无关。固定数量的分区方式，每个分区的大小与数据集的大小成正比。动态分区方式，拆分和合并操作使每个分区的大小维持在设定的最小值和最大值之间，因此，分区数量和数据集大小成正比。而Cassandra和Ketama采用第三种方式，使分区数与集群节点数成正比关系。换句话，既是每个节点具有固定数量的分区。

4. 请求路由
   
现在我们已经将数据集分布到多个节点上，但是仍然有一个悬而未决的问题：当客户端需要发送请求时，如何知道应该连接哪个节点？同时，如果发生了分区再平衡，分区与节点的对应关系随之还会变化，如何确定？
  
概括来讲，有三种不同的处理策略;

> 允许客户端链接任意的节点（例如，采用循环式的负载均衡器）。随机选择一个节点，如果该节点恰好拥有所请求的分区，则直接处理该请求；否则，将请求转发到下一个合适的节点，接收答复，并将答复返回给客户端。
> 
> 将所有客户端的请求都发送到一个路由层，由后者负责将请求转发到对应的分区节点上。路由层本身不处理任何请求，它仅仅充当一个分区感知的负载均衡器。
> 
> 客户端自己感知分区和节点分配关系。此时，客户端可以直接连接到目标节点，而不需要任何中介。

这三种方法各有利弊，但是无论哪种方法，核心问题是：作出路由决策的组件，如何知道分区与节点的对应关系以及其变化情况？

这其实是一个很有挑战性的共识问题，所有参与者都要达成共识这一点很重要。在这里只讲一种分布式数据系统的典型方案：ZooKeeper

>依靠独立的协调服务（如ZooKeeper）跟踪集群范围内的元数据。每个节点都向ZooKeeper中注册自己，ZooKeeper维护分区到节点的最终映射关系。其它参与者（如路由层或分区感知的客户端）可以向ZooKeeper订阅此消息。一旦分区发生了改变，或者添加、删除节点，ZooKeeper就会主动通知路由层，这样使路由信息保持最新状态。


# 第七章 事务

## 1. 事务的作用

事务作为一个抽象层，可以将应用程序的多个读、写操作捆绑在一起成为一个逻辑操作单元，即事务中的所有读写是一个执行的整体，整个事务要么成功（提交），要么失败（中止或回滚）。无论如何，不会出现部分失败的情况。使得应用程序可以忽略数据库内部的一些复杂的并发问题，以及某些硬件、软件故障，从而简化应用层的处理逻辑，大量的错误可以转化为简单的事务中止和应用层重试。

### 事务的保证
   2.1 ACID
   事务所提供的安全保证即大家所熟悉的ACID。但是实际上，各家数据库所实现的ACID并不尽相同。例如，围绕着“隔离性”就存在很多含糊不清的争议。

+ 1、A (Atomicity) 原子性

>原子性很容易理解，也就是说事务里的所有操作要么全部做完，要么都不做，而不是两者之间的状态。

+ 2、C (Consistency) 一致性

>ACID的一致性主要是指对数据有特定的预期状态，任何数据更改必须满足这些状态约束（或恒等条件）。
> 
>例如现有完整性约束a+b=10，如果一个事务改变了a，那么必须得改变b，使得事务结束后依然满足a+b=10，否则事务失败。

+ 3、I (Isolation) 隔离性
>所谓的隔离性是指并发的事务之间相互隔离，不会互相影响。如果一个事务要访问的数据正在被另外一个事务修改，只要另外一个事务未提交，它所访问的数据就不受未提交事务的影响。
>
>经典教材中把隔离定义为可串行化：可以假装它是数据库上运行的唯一事务。虽然实际上他们可能同时运行，但数据库系统要确保当事务提交时，其结果与串行执行完全相同。
>
>例如现在有个交易是从A账户转100元至B账户，在这个交易还未完成的情况下，如果此时B查询自己的账户，是看不到新增加的100元的。

+ 4、D (Durability) 持久性

持久性是指一旦事务提交后，它所做的修改将会永久的保存在数据库上，即使出现宕机也不会丢失。

### 2.2 CAP
不符合ACID标准的系统有时被冠以BASE，即基本可用性（Basically Available），软状态（Soft state），最终一致性（Eventual consistence），更一般的，我们习惯称他们只满足CAP定理。

CAP定理（CAP theorem）, 又被称作 布鲁尔定理（Brewer’s theorem）, 它指出对于一个分布式计算系统来说，不可能同时满足以下三点:

>（1）一致性(Consistency) (所有节点在同一时间具有相同的数据)
>
>（2）可用性(Availability) (保证每个请求不管成功或者失败都有响应)
>
>（3）分区容错性(Partition tolerance) (系统中任意信息的丢失或失败不会影响系统的继续运作)

CAP理论的核心是：一个分布式系统不可能同时很好的满足一致性，可用性和分区容错性这三个需求，最多只能同时较好的满足两个。
因此，根据 CAP 原理将 NoSQL 数据库分成了满足 CA 原则、满足 CP 原则和满足 AP 原则三 大类：

>（1）CA - 单点集群，满足一致性，可用性的系统，通常在可扩展性上不太强大。
>
>（2）CP - 满足一致性，分区容忍性的系统，通常性能不是特别高。
>
>（3）AP - 满足可用性，分区容忍性的系统，通常可能对一致性要求低一些。

### 2.3 一致性讨论
ACID和CAP中的一致性含义是不同的。

ACID中的一致性主要是指对数据有特定的预期状态，任何数据更改必须满足这些状态约束（或恒等条件）。这种一致性本质上要求应用层来维护状态一致，应用程序有责任正确定义事务来保持一致性。原子性、隔离性和持久性是数据库自身的属性，而ACID中的一致性更多是应用层的属性。

CAP中的一致性用来表示“可线性化（也称为原子一致性、强一致性等）”。其基本想法是：让一个系统看起来好像只有一个数据副本。有了这个保证，应用程序就不需要关心系统内部的多个副本了。

### 2.4 单对象和多对象事务操作
>ACID中的原子性和隔离性主要针对客户端在同一事务中包含多个写操作，这些定义假定在一个事务中会修改多个对象（如行，文档，记录等）。这种多对象事务目的通常是为了在多个数据对象之间保持同步。

## 3. 弱隔离级别

### 3.1 强隔离级别 VS 弱隔离级别

   数据库不可避免的存在各种并发问题。一直以来，数据库力求试图通过事务隔离来对应用开发者隐藏内部的各种并发问题。

经典教材中把隔离定义为可串行化，可串行化隔离意味着数据库保证事务的最终执行结果与串行（一次一个，没有任何并发）执行结果相同，可以将其理解为强隔离级别。

可串行化的隔离会严重影响性能，而很多数据库却不愿牺牲性能，因而倾向于采用较弱级别（非串行化）隔离，它可以防止某些而不是全部的并发问题。

SQL 标准里定义了四个隔离级别：

>（1）读未提交（Read Uncommitted）：会出现脏读（Dirty Read）—— 一个事务会读到另一个事务的中间状态。
>
>（2）读已提交（Read Committed）：会出现不可重复读（Unrepeatable Read） —— 事务只会读到已提交的数据，但是在一个事务中，前后两次读取一个值得到的结果不一致。
>
>（3）可重复读（Repeatable Read）：会出现幻读（Phantom Read） —— 一个事务执行两个相同的查询语句，得到的是两个不同的结果集（数量不同）。同样的条件，第1次和第2次读出来的记录数不一样。注意是数量不一致，好像凭空多（少）了几个。
>
>（4）可串行化（Serializable）：可以找到一个事务串行执行的序列，其结果与事务并发执行的结果是一样的。
SQL 标准定义的的这四个隔离级别，只适用于基于锁的事务并发控制。后来有人写了一篇论文 A Critique of ANSI SQL Isolation Levels 来批判 SQL 标准对隔离级别的定义，并在论文里提到了一种新的隔离级别 —— 快照隔离（Snapshot Isolation，简称 SI）。在 Snapshot Isolation 下，不会出现脏读、不可重复度和幻读三种读异常。并且读操作不会被阻塞，对于读多写少的应用 Snapshot Isolation 是非常好的选择。并且，在很多应用场景下，Snapshot Isolation 下的并发事务并不会导致数据异常。所以，主流数据库都实现了 Snapshot Isolation，比如 Oracle、SQL Server、PostgreSQL、TiDB、CockroachDB（关于 MySQL 的隔离级别，可以参考https://www.jianshu.com/p/69fd2ca17cfd）。

下面将介绍几种实际中经常用到的弱隔离：

3.2 读-提交
读-提交是最基本的事务隔离级别，它只提供两种保证：

>（1）读数据库时，只能看到已成功提交的数据（防止“脏读”）
>
>（2）写数据库时，只会覆盖已成功提交的数据（防止“脏写”）

防止“脏读”
> 假定某个事务已经完成部分数据写入，但事务尚未提交（或中止），此时如果另一个事务可以看到尚未提交的数据，那就是“脏读”。

当有如下需求时，需要防止脏读：

>（1）如果事务需要更新多个对象。脏读意味着另一个事务可能会看到部分更新，而非全部。
>
>（2）如果事务发生中止，则所有写入操作都需要回滚。脏读意味着可能会看到尚未回滚的数据，这些数据并未实际提交到数据库中。

防止“脏写”
>如果两个事务同时尝试更新相同的对象，当然地，后写的操作会覆盖较早的写入。但是，如果先前的写入是尚未提交事务的一部分，此时如果被覆盖，那就是“脏写”。防止脏写的通常方式是推迟第二个写请求，直到前面的事务完成提交（或中止）。

当有如下需求时，需要防止脏写：
>典型情景就是：事务需要更新多个对象，此时多个事务同时尝试更新，非常可能产生脏写，会带来非预期的错误。比如：抢购小米。

实现读-提交
>读-提交隔离非常流行，它是oracel 11g，postgreSQL，SQL Server2012以及很多其他数据库的默认配置。

>防止脏写：行级锁。当事务想修改某个对象时，它必须首先获得该对象的锁，然后一直持有直到事务提交（或中止）。给定时刻，只有一个事务可以拿到特定对象的锁。如果有另一个事务尝试更新同一个对象，则必须等待，直到前面的事务完成了提交（或中止）后，才能获得锁并继续。这种锁定是由处于读-提交模式（或更强的隔离级别）数据库自动完成。

防止脏读：
>（1）读锁。和前面的行级锁类似，所有试图读取该对象的事务必须先申请锁，事务完成后释放锁。但是，读锁的方式在实际中并不可行，因为运行时间较长的写事务会导致许多只读的事务等待太长时间，这会严重影响只读事务的响应延迟，且可操作性差：由于读锁，应用程序任何局部的性能问题会扩散进而影响整个应用，产生连锁反应。
>
>（2）考虑到性能和实际情况，普遍采取的方法是：对于每个待更新的对象，数据库都会维护其旧值和当前持锁事务将要设置的新值两个版本。在事务提交之前，所有其它读操作都读取旧值；仅当写事务提交之后，才会切换到读取新值。


## 3.3 快照
快照与备份

快照是数据存储的某一时刻的状态记录；备份则是数据存储的某一个时刻的副本。这是两种完全不同的概念。

详细介绍参考：https://www.jianshu.com/p/74007799313d

快照：一般来说，原则就是就是快照时锁定物理单元内容，并记录本次快照和上一次快照的所对应的物理地址（或者是上一层逻辑地址）的差异。因为快照仅仅记录逻辑地址和物理地址的对应关系，因此快照的速度非常快

备份：备份，则是另外一份数据副本。另外，备份又分全量备份和增量备份。增量备份类似快照，但不同的地方在于两次快照之间只记录了两层地址之间的对应关系的差异，而增量备份则把这些差异中，新增地址所对应的底层数据也复制了一份出来。

快照和备份的不同特性在于：

>（1）备份的数据安全性更好：如果原始数据损坏（例如物理介质损坏，或者绕开了快照所在层的管理机制对锁定数据进行了改写），快照回滚是无法恢复出正确的数据的，而备份可以。
>
>（2）快照的速度比备份快得多：生成快照的速度比备份速度快的多。也因为这个原因，为了回避因为备份时间带来的各种问题（例如IO占用、数据一致性等）很多备份软件是先生成快照，然后按照快照所记录的对应关系去读取底层数据来生成备份。
>
>（3）占用空间不同：备份会占用双倍的存储空间，而快照所占用的存储空间则取决于快照的数量以及数据变动情况。极端情况下，快照可能会只占用1%不到的存储空间，也可能会占用数十倍的存储空间。（PS：不过如果同一份数据，同时做相同数量的快照和增量备份的话，备份还是会比快照占用的存储空间多得多。）

读倾斜

读倾斜（不可重复读）：在一个事务的不同时间点看到不同值。

典型的读倾斜场景如下：

>（1）备份场景：备份复制整个数据库可能需要数小时才能完成。在备份过程中，可以继续写入数据库。因此，得到的镜像中可能包含部分旧版本数据和部分新版本数据。如果从这样的备份进行恢复，最终就导致永久性的不一致。
>
>（2）分析查询与完整性检查场景：在分析业务中，查询非常可能会扫描大半个数据库。如果这些查询在不同的时间点观察数据库，可能会返回无意义的结果。

快照级别隔离

快照级别隔离是解决上述两个问题的最常见手段。其总体做法：每个事务都从数据库的一致性快照中读取，事务一开始所看到的是最近提交的数据，即使数据随后可能被另一个事务更改，但保证每个事务都只看到该特定时间点的旧数据。

快照级别隔离对于长时间运行的只读查询（如备份和分析）非常有用。如果数据在执行查询的同时还在发生变化，那么查询结果对应的物理含义就难以厘清。而如果查询的是数据库在某时刻所冻结的一致性快照，则查询结果的含义非常明确。

实现快照级别隔离

>（1）防止“脏写”：同读提交一样，使用写锁
>
>（2）防止“脏读”和“不可重复读”：多版本并发控制。与读提交类似，但是更为通用。考虑到多个正在进行的事务可能会在不同的时间点查看数据库状态，所以，数据库保留了多个不同的提交版本。

补充

关于多版本并发控制（Multi-Version Concurrency Control，MVCC），书上讲的很有问题，十分不明确，详细技术细节请参考：https://www.jianshu.com/p/8845ddca3b23（了解MVCC的概念即可，这个概念讲的不错，具体细节看不懂。。。）

1、数据库并发场景有三种，分别为：

> 读-读：不存在任何问题，也不需要并发控制
>
>读-写：有线程安全问题，可能会造成事务隔离性问题，可能遇到脏读，幻读，不可重复读
>
>写-写：有线程安全问题，可能会存在更新丢失问题，比如第一类更新丢失，第二类更新丢失

2、MVCC带来的好处是？

多版本并发控制（MVCC）是一种用来解决读-写冲突的无锁并发控制，也就是为事务分配单向增长的时间戳，为每个修改保存一个版本，版本与事务时间戳关联，读操作只读该事务开始前的数据库的快照。 所以MVCC可以为数据库解决以下问题：

>（1）在并发读写数据库时，可以做到在读操作时不用阻塞写操作，写操作也不用阻塞读操作，提高了数据库并发读写的性能
>
>（2）同时还可以解决脏读，幻读，不可重复读等事务隔离问题，但不能解决更新丢失问题

3、总体的隔离策略

总之，MVCC就是因为大牛们，不满意只让数据库采用悲观锁这样性能不佳的形式去解决读-写冲突问题，而提出的解决方案，所以在数据库中，因为有了MVCC，所以我们可以形成两个组合：

>（1）MVCC + 悲观锁：MVCC解决读写冲突，悲观锁解决写写冲突
>
>（2）MVCC + 乐观锁：MVCC解决读写冲突，乐观锁解决写写冲突

3.4 并发写

正如前面所介绍的，我们长篇累牍讨论的读提交以及快照级别隔离，其实都只是为了解决读写并发问题。而并发写同样存在很多需要解决的问题，比如：脏写、更新丢失、写倾斜。

更新丢失

写事务并发最著名的就是更新丢失问题，脏写只是一个特例。

场景

>更新丢失可能发生的场景比如：应用程序从数据库读取某些值，根据应用逻辑作出修改，然后写回新值（read-modify-write）。当有两个事务在同样的数据对象上执行类似操作时，由于隔离性，第二个写操作并不包括第一个事务修改后的值，最终会导致第一个事务的修改值可能会丢失。

解决方案
1、原子写操作

>在数据库层面，提供原子更新操作，以避免在应用层完成“read-modify-write”操作。对于支持原子写操作的数据库，这就是最好的解决方案。
>
>原子操作通常采用对读取对象加独占锁的方式来实现，这样在更新被提交之前，不会有其他事务可以读它。

2、显式加锁

> 在应用层解决。如果数据库不支持内置原子操作，则防止更新丢失的方法是由应用程序显式加锁锁定待更新的对象。然后，应用程序可以执行“read-modify-write”这样的操作序列，此时如果有其它事务尝试同时读取对象，则必须等待当前正在执行的序列全部完成。

3、自动检测更新丢失

> 原子操作和锁都是通过强制“read-modify-write”操作序列串行执行来防止丢失更新。另一种思路则是先让他们并发执行，但如果事务管理器检测到更新丢失风险，则中止当前事务，并强制回退到安全的“read-modify-write”方式。

4、原子比较和设置

>对于不支持事务的数据库，使用该操作可以避免更新丢失，即只有在上次读取的数据没有发生变化时才允许更新，如果已经发生了变化，则回退到“read-modify-wrtie”的方式。

5、冲突解决与复制

对于支持多副本的数据库，防止更新丢失还需要考虑另一个维度：由于多节点上的数据副本，不同的节点可能会并发修改数据，因此，必须采取一些额外的措施来防止更新丢失。

前面提到的加锁和原子修改都有个前提：只有一个最新的数据副本。然而对于多主节点或者无主节点的多副本数据库，由于支持多个并发写，且通常以异步方式来同步更新，所以会出现多个最新的数据副本，此时，加锁和原子比较将不再适用。往往需要依靠应用层逻辑或特定的数据结构来解决、合并多版本。

如果操作可交换（顺序无关，在不同的副本上以不同的顺序执行时仍然得到相同的结果），则原子操作在多副本情况下也可以工作。

写倾斜

>写倾斜既不是脏写也不是更新丢失，关键区分在于它的两笔事务更新的是两个不同的对象。可以将写倾斜视为一种更广义的更新丢失问题。即如果两个事务读取相同的一组对象，然后更新其中一部分：如果不同事务更新的是同一个对象，则发生的是脏写或更新丢失；如果不同事务更新的是不同对象，则发生的是写倾斜。

为何会产生写倾斜？

《寻秦记》的逻辑与悖论。

所有写倾斜的例子都遵循以下类似的模式：

> 1、首先，输入一些匹配条件，即采用select查询所有满足条件的行
> 
> 2、根据查询的结果，应用层代码来决定下一步的操作
> 
> 3、如果应用程序决定继续执行，它将发起数据库写入，并提交事务

关键的悖论在于：第二步直接决定第三步的操作，而第三步的写入会反过来改变第二步作出决定的前提条件，这就陷入了一个矛盾之中。

解决写倾斜的唯一方法是串行化的隔离。

## 4 强隔离级别：串行化
弱隔离级别为了实现并发高性能作出了很多妥协，它可以防止某些异常，但还需要应用开发人员手动处理其他复杂情况（比如：显式加锁）。只有可串行化的强隔离才可以防止所有这些问题。
实现可串行化隔离的三种不同方法：

4.1 严格串行执行事务

>如果每个事务的执行速度非常快，且每个CPU核可以满足事务的吞吐量要求，严格串行执行是一个非常简单有效的方案。（不太现实）

4.2 两阶段加锁（two-phase locking，2PL）

两阶段加锁的概念

两阶段加锁 ≈ 防止脏写加锁+防止脏读加锁

>(1)如果事务A已经读取了某个对象，此时事务B想要写入该对象，则B必须等到A提交或中止之后才能继续。以确保B不会在事务A执行的过程中去修改对象。
>
>（2）如果事务A已经修改了对象，此时事务B想要读取该对象，则B必须等到A提交或中止之后才能继续。对于2PL，不会出现读到旧值的情况。

2PL不仅在并发写之间互斥，读取也会和修改互斥。

快照级别隔离的“读写互不干扰”，非常准确地点明了它和两阶段加锁的关键区别。

实现两阶段加锁

基本规则：

> （1）如果事务要读取对象，必须先以共享模式获得锁。可以有多个事务同时获得一个对象的共享锁，但是如果某个事务已经获得了对象的独占锁，则所有其它事务必须等待。——读锁可以共享。
> 
> （2）如果事务要修改对象，必须以独占模式获取锁。不允许多个事务同时持有该锁。——写锁必须独占。
> 
> （3）如果事务首先读取对象，然后尝试写入对象，则需要将共享锁升级为独占锁。

事务获得锁后，一直持有锁直到事务结束。这也是名字“两阶段”的由来：在第一阶段即事务执行之前要获取锁，第二阶段即事务结束时释放锁。

两阶段加锁的性能

首先，锁机制过多，容易出现死锁。


其次，其事务吞吐量和查询响应时间相比于其他弱隔离级别下降非常多。这主要因为：锁的获取和释放本身需要很大的开销，并且严重降低了事务的并发性。

谓词锁

>真正的可串行化隔离可以防止写倾斜和幻读问题。但两阶段加锁并不能防止所有形式的写倾斜和幻读，为此，需要引入一种谓词锁。它的作用类似于共享/独占锁，区别在于，它并不属于某个特定的对象（如表的某一行），而是作用于满足某些搜索条件的所有查询对象。
>
>将两阶段加锁和谓词锁结合使用，数据库可以防止所有形式的写倾斜以及其他竞争条件，才能成为真正的可串行化。

索引区间锁

>谓词锁的缺点是：性能不佳，如果活动事务中存在许多锁，那么检查匹配这些锁就会变得非常耗时。因此，绝大多数使用2PL的数据库实际上实现的是索引区间锁，本质上它是对谓词锁的简化或近似。

4.3 可串行化的快照隔离（SSI）

>一种最新的算法，可以避免前面方法的大部分缺点。它秉持乐观预期的原则，允许多个事务并发执行而不互相阻塞；仅当事务尝试提交时，才检查可能的冲突，如果发现违背了串行化，则某些事务会被中止。

# 第八章 分布式系统的挑战

本章对分布式系统可能出现的故障作出了一个全面，近乎悲观的总结。故障可能来自网络问题，以及时钟与时序问题等等，并讨论这些问题的可控程度。关键在于，分布式系统与在单节点上的软件有着非常显著的区别：很多在单节点上不可能出现的问题，却是困扰分布式系统的大问题！

## 1. 不确定性与部分失效

###  1.1 单节点的确定-正确性

在单节点上开发程序时，通常它会以一种确定-正确性的方式运行，不会出现模棱两可的现象：要么工作，要么出错，而不会介于两者之间。

这背后设计计算机设计的一个非常审慎的选择：如果发生了某种内部错误，我们宁愿使计算机全部崩溃，也不愿返回一个错误的结果，错误的结果往往更难处理。这种确定-正确性的设计思想可以一直追溯到第一台数字计算机。

### 1.2 分布式系统的不确定性

然而，对于分布式系统，理想化的确定-正确性模型不再适用。可能出现系统的一部分工作正常，但其他某些部分出现难以预测的故障，这被称为“部分失效”。

问题的难点在于这种部分失效是不确定的：因为涉及多个节点和网络，哪个节点何时出问题？是完全不可预料的。正是这种不确定性和部分失效极大地提高了分布式系统的复杂性。

要使分布式系统可靠工作，就必然面临部分失效，这就需要依靠软件系统来提供容错机制。换句话说，我们要在不可靠的组件上构建可靠的系统。

## 2. 不可靠的网络

###  2.1 可能存在的网络故障
   分布式系统一般采用无共享架构的水平扩展，即通过网络连接多个节点，网络是跨节点通信的唯一途径。一个节点可以发送消息到另一个节点，但网络并不保证它是否能到达，什么时候到达。发送之后等待响应的过程中，有很多事情可能会出错，常见的出错有：

 （a）请求丢失；（b）远程节点关闭；（c）响应丢失

  这些问题在一个异步网络中无法明确区分，发送者拥有的唯一信息是：尚未收到响应。至于原因，无法判断。

### 2.2 解决方法：超时

处理网络故障问题通常采用超时机制：在等待一段时间后，如果仍然没有收到回复则选择放弃，并认为响应不会到达。

问题：超时设置多长？

两难：较长的时长意味着更长时间的等待，这会影响性能和效率；较短的时长可以帮助快速检测故障，但误判几率增大。

对于分布式系统，没有公式条例可以设置超时时长。

只能通过实验方式来一步步设置超时：先在多台机器上，多次测量网络往返时间，以确定延迟的大概范围；然后结合应用特点，在故障检测与过早超时风险之间选择一个合适的中间值。

更好的做法是：超时设置并不是一个不变的常量，而是持续测量响应时间及其变化，然后根据最新的响应时间分布来自动调整。