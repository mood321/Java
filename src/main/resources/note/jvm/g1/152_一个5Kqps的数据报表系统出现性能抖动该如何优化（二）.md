1、一套线上环境的参数设置

-XX:InitialHeapSize=20G -XX:MaxHeapSize=20G -Xss1M -XX:+UseG1GC -XX:SurvivorRatio=8 -XX:MaxGCPauseMillis=20 -XX:G1HeapRegionSize=4M -XX:MaxTenuringThreshold=15 -XX:InitiatingHeapOccupancyPercent=45

 

这一套参数，是一套非常常规的参数，对于一般的大内存，多核心的机器来说是，只要并发压力不是大到离谱，一般来说都是没什么性能问题的。因为机器的配置足够好

 

2、案例背景回顾

案例的业务背景：一个提供订单数据分析的业务系统。

数据报表系统的配置：32G 16C，给报表系统的堆内存大小：20G，可以看到这个配置是相当相当高的了。一般来说，4C 8G的机器扛1500+qps是没什么问题的。这套系统因为主要是查询的数据量大，查询的qps较高，总体的qps在8k左右，因为报表系统也是集群化部署，单台也就3-5K之间徘徊，所以整体的性能是完全够用的。

 

这个系统的职责就是，前置服务是一个订单查询服务，以及一个大盘系统，订单查询系统会有大量用户日常使用，并根据一些条件来发起一些查询请求，调用这个数据查询服务来查询一套数据报表。但是请求相对比较均衡，对数据报表系统产生的请求的压力在4000-6000qps的水平，大盘系统一般是一些卖家在一些特殊活动的时期，或者是特殊的交易窗口的时候会开启，用户量大概在20W左右，日活1W-2W左右，平常对报表系统的压力，也就是在3000qps的水平。如图所示：

![picture.png](http://wechatapppro-1252524126.cdn.xiaoeknow.com/apppuKyPtrl1086/image/ueditor/74182000_1644391999.png?imageView2/2/q/80%7CimageMogr2/ignore-error/1)

 

另外数据大盘系统还有一些自动刷新页面，每隔5s更新一下页面最新的交易数据，这种页面一般都是在交易窗口期，或者是特殊时间段才会开启。类似于秒杀场景的时候的交易数据监控。

![picture.png](https://wechatapppro-1252524126.cdn.xiaoeknow.com/appAKLWLitn7978/image/b_u_5b2225aa46488_oGKN7IvA/ky1dg72m078r.png)

订单数据分析系统的特点：QPS高，查询数据量大，数据会快速成为垃圾数据。

 

这一套数据分析系统，在正常情况下是没有什么问题的，运行的也一直都很稳定，直到有一次特殊的交易窗口，因为这次交易窗口涉及到的商家比较多，达到了5w日活，打开大盘的人数大大增加，导致产生了8K+的qps，订单查询的qps也接近了8000左右。这么大的qps，虽然我们数据报表系统是集群化部署，单台服务分下来的请求量大概在6K+左右，正常来说，我们服务器的配置已经算不错了。6Kqps还没有达到极限，但是不知为什么，在数据报表系统运行一段时间之后，就会出现一次性能抖动，出现接口查询超时的问题，抖动之后，就会恢复正常一段时间。过一段时间又一次发生抖动。

![picture.png](https://wechatapppro-1252524126.cdn.xiaoeknow.com/appAKLWLitn7978/image/b_u_5b2225aa46488_oGKN7IvA/ky1dg72m078r.png)

这个现像虽然说不会影响系统的使用，顶多刷新一次就OK了，但是用户体验是非常的差的。于是我们不得不着手排查原因。

首先我们登录了服务器，查看了参数配置，具体的参数配置大概就是我们开头的那一套参数：

-XX:InitialHeapSize=20G -XX:MaxHeapSize=20G -Xss1M -XX:+UseG1GC -XX:SurvivorRatio=8 -XX:MaxGCPauseMillis=20 -XX:G1HeapRegionSize=4M -XX:MaxTenuringThreshold=15 -XX:InitiatingHeapOccupancyPercent=45

从参数上来看，暂时没有发现什么问题。紧接着我们打开拉下来了GC日志，通过GC日志我们发现。

我们给堆内存了20G的内存，然而，Eden区的总大小，始终在1-2G徘徊，运行了很久爬到了2G之后，无法继续往上增加。而G1垃圾回收器，本身就是一个自动调整新生代区域的回收器，最小内存5% * 20 = 1G，而我们观察的日志中，最大也才给到2G，也就是10%的空间。然后，就导致很快就触发以此Mixedgc的过程，MixedGC几乎是几次YGC发生一次。并且MixedGC的次数很多，每次整个MixedGC过程结束之后，就会空闲出大量的空间。很显然这个现像是不正常的。大家下图：其中绿色的region代表的是eden + survivor

![picture.png](https://wechatapppro-1252524126.cdn.xiaoeknow.com/appAKLWLitn7978/image/b_u_5b2225aa46488_oGKN7IvA/ky1dg72m078r.png)

我们本来以为是参数配置的问题，但是查看了参数之后，没有发现调整新生代最大空间的这个参数设置。

所以一定不是手动配置参数导致的问题，而是G1的自动调整出的问题！那么自动调整新生代大小，出来5% -60%的比例，还有什么因素呢？

 

答案其实很简单！我们前面讲到的停顿预测模型！停顿预测模型+YGC的时间结合起来，是G1动态调整新生代大小的一个依据。

假如说，YGC需要的时间比较久，比如说，新生代现在占用了10G的内存，每次回收需要的时间大概是在200ms+，无法满足停顿时间，就只能调小新生代的总空间大小以此来尽量满足停顿时间。

![picture.png](https://wechatapppro-1252524126.cdn.xiaoeknow.com/appAKLWLitn7978/image/b_u_5b2225aa46488_oGKN7IvA/ky1dg72m078r.png)

所以，即使新生代需要扩展，在接下来发生YGC的时候，结合停顿预测模型和历史GC数据，就会判定无法满足GC的时间，此时在YGC结束之后，还是调整region个数到一个合理的范围，不会增大很多，一直到新生代的region达到预测模型中的极限值左右，就会在这个附近徘徊，比如我们这个案例中的情况就是，从5%上涨到10%左右的时候，就一直保持在10%上下浮动。

![picture.png](https://wechatapppro-1252524126.cdn.xiaoeknow.com/appAKLWLitn7978/image/b_u_5b2225aa46488_oGKN7IvA/ky1dg72m078r.png)

YGC之后，新生代region数量保持到一个G1认为合理的区间，如图所示：

 

![picture.png](https://wechatapppro-1252524126.cdn.xiaoeknow.com/appAKLWLitn7978/image/b_u_5b2225aa46488_oGKN7IvA/ky1dg72m078r.png)

因此新生代的可用内存始终上不去。这就导致，如果说我们的数据报表系统查询的qps比较高的时候，会有大量的短周期对象，进入到老年代。从而导致MixedGC的发生，从我们对MixedGC之后堆内存的空闲情况就可以看的出来，其实是有大量的对象晋升至了老年代的。

 

3、问题如何解决？

新生代内存比例始终上不去，导致老年代快速被填满达到45%从而触发MixedGC，最终导致频繁触发MixedGC。MixedGC时间本身是比较长的，最终导致的系统整体的性能抖动。

 

4、解决思路

思路：避免大量短周期存活对象进入老年代，这个是核心的思路。那么调优应该调什么呢？

 

（1）第一个思路

首先第一个思路就是，我们直接把新生代的比例调整下，比如说初始比例直接调整到20%，然后，新生代的region数量就直接从20%开始，这样子的话就能解决这个问题。

 

 

-XX:InitialHeapSize=20G -XX:MaxHeapSize=20G -Xss1M -XX:+UseG1GC -XX:SurvivorRatio=8

**-XX:G1NewSizePercent=20** -XX:MaxGCPauseMillis=20 -XX:G1HeapRegionSize=4M -XX:MaxTenuringThreshold=15 -XX:InitiatingHeapOccupancyPercent=45

 

大家思考下这样可以吗？这种方式看似还可以，实际上并不可取，因为这个值，只适合在这种特定的时间节点里面使用。假如说QPS再继续增大，我们应该怎么办？继续提高这个值？直到手动设置到60%吗？到最后需要做的可能就是把新生代的最小值定死在一个比较高的值，或者说，直接定死到60%，最大值和最小值一样。

![picture.png](http://wechatapppro-1252524126.cdn.xiaoeknow.com/apppuKyPtrl1086/image/ueditor/34773800_1644392000.png?imageView2/2/q/80%7CimageMogr2/ignore-error/1)

很显然这种方式虽然能暂时解决问题，但是无法从根本上解决问题。所以说，这种方式不可取。

（2）第二种思路（调整停顿时间）

其实我们回顾一下前面讲的内容就能发现，G1是根据停顿时间的长短，来预测我到底能回收多少垃圾的，以调整新生代region的数量。那么停顿时间的长短，是不是从根本上对我新生代的分区是有很大影响的？如果停顿时间太短，一定会造成每次回收，回收不了太多垃圾，对于新生代垃圾回收，就只能通过控制新生代的region数量来保证停顿时间。那么我们是不是直接把这个停顿时间调整一下就可以了？

 

 

-XX:InitialHeapSize=20G -XX:MaxHeapSize=20G -Xss1M -XX:+UseG1GC -XX:SurvivorRatio=8 -XX:MaxGCPauseMillis=20 -XX:G1HeapRegionSize=4M -XX:MaxTenuringThreshold=15 -XX:InitiatingHeapOccupancyPercent=45

 

事实上我们当时在线上也是这么去做的，因为当时这个20ms的值是考虑到，反正G1是能控制停顿时间的，我们不希望让接口停顿的时间过长，就拍拍脑门儿直接定了一个特别小的值，20ms。在当时的场景，我们经过一系列的分析之后，最终把停顿时间设定在了300ms，因为一个报表系统的查询，其实对响应时间的要求没有那么高，并且300ms这个停顿，偶尔发生一次，也不会导致接口的超时。

--XX:InitialHeapSize=20G -XX:MaxHeapSize=20G -Xss1M -XX:+UseG1GC -XX:SurvivorRatio=8 -XX:MaxGCPauseMillis=300 -XX:G1HeapRegionSize=4M -XX:MaxTenuringThreshold=15 -XX:InitiatingHeapOccupancyPercent=45

 

参数调整以后，经过一段时间的运行，以及对GC日志的观察，我们发现Eden区的数量，会随着系统运行不断的变大，最终稳定在一个比较合理的值 40%左右，不管是平时还是高峰期（开启了交易窗口）都没有出现抖动现像了。

 

![picture.png](http://wechatapppro-1252524126.cdn.xiaoeknow.com/apppuKyPtrl1086/image/ueditor/35154400_1644392000.png?imageView2/2/q/80%7CimageMogr2/ignore-error/1)

5、总结

系统发生了性能抖动之后。主要原因是因为新生代区域过小，导致大量对象进入老年代，并快速成为垃圾对象。

优化思路：因为设置的停顿时间不合理导致新生代的大小不合理，导致大量对象进入老年代，所以最终的优化手段是调整停顿时间。

 

由此可见，即使是G1这种非常灵活的回收器，在参数设置上也不是想当然的认为是什么就设置成什么。尤其是停顿时间，不一定是停顿时间越小越好。

 

6、思考题

希望大家能够基于本节课的思路，带着自己的理解，去观察一下线上使用了G1回收器的服务，去查看一下参数，结合系统的请求访问量和GC日志的变化过程，包括监控数据，去分析一下停顿时间设置的是否合理？