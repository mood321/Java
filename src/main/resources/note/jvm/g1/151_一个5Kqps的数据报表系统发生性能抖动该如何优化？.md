1、一些核心参数介绍

 

-Xms/InitialHeapSize    初始堆大小  

-Xmx/MaxHeapSize 最大堆大小

-Xss 每个线程的堆栈大小  

-XX:NewRatio 年轻代(包括Eden和两个Survivor区)与年老代的比值 使用G1时一般此参数不设置，由G1来动态的调整，逐渐调整至最优值

-XX:SurvivorRatio  Eden区与Survivor区的大小比值    8   

-XX:PretenureSizeThreshold  大对象晋升老年代阈值    默认Region的一半   

-XX:MaxTenuringThreshold   新生代晋升老年代阈值    15  晋升到老年代对象的年龄，每个对象在坚持过一次MinorGC后，年龄就增加1，当超过这个参数值时，就进入老年代

-XX:MaxGCPauseMillis  垃圾回收的最长时间(最大暂停时间) 200ms  设置GC最大的停顿时间，G1会尽量达到此期望值，如果GC时间超长，那么会逐渐减少GC时回收的区域，以此来靠近此阈值

-XX:InitiatingHeapOccupancyPercent  启动并发GC时的老年代以及即将分配的对象的总内存占用堆内存百分比  45  

-XX:G1HeapRegionSize  G1内堆内存区块大小 (Xms + Xmx ) /2 / 2048 , 不大于32M，不小于1M，且为2的指数    

-XX:GCTimeRatio  GC时间占运行时间的比例 G1默认为9，GC时间的计算公式为1/(1+9) = 10%

-XX:G1HeapWastePercent   触发Mixed GC的可回收空间百分比 5%  在并发标记之后，我们可以知道old gen regions中有多少空间要被回收，在每次YGC之后和再次发生Mixed GC之前，会检查垃圾占比是否达到此参数，只有达到了，下次才会发生Mixed GC

-XX:G1MixedGCLiveThresholdPercent  MixGC的Region中存活对象占比    默认85%  只有小于此参数，才会被选入CSet（新生代会全部被选取）

-XX:G1MixedGCCountTarget      8    一次并发标记之后，最多执行Mixed GC的次数

-XX:G1NewSizePercent      5%  新生代占堆的最小比例

-XX:G1MaxNewSizePercent      60% 新生代占堆的最大比例

-XX:G1OldCSetRegionThresholdPercent Mixed GC每次回收Region的数量   10% 一次Mixed GC中能被选入CSet的最多old generation region数量比列

-XX:ParallelGCThreads           STW期间，并行GC线程数

-XX:ConcGCThreads         -XX:ParallelGCThreads/4 并发标记阶段，并行执行的线程数

 

2、一套线上环境的参数设置

-XX:InitialHeapSize=20G -XX:MaxHeapSize=20G -Xss1M -XX:+UseG1GC -XX:SurvivorRatio=8 -XX:MaxGCPauseMillis=20 -XX:G1HeapRegionSize=4M -XX:MaxTenuringThreshold=15 -XX:InitiatingHeapOccupancyPercent=45

-XX:MaxTenuringThreshold=15 最大只能是15，因为底层这个年龄值，是用了一个4位的2进制存。

这一套参数，是一套非常常规的参数，对于一般的大内存，多核心的机器来说，只要并发压力不是大到离谱，一般来说都是没什么性能问题的。因为机器的配置足够好。那这样一组参数真的就没有任何问题了吗？

很显然不是的。接下来给大家看一个线上的实际的案例，一起来分析一下这个问题发生的原因。

 

3、案例

案例的业务背景：一个提供订单数据分析的业务系统。

数据报表系统的配置：32G 16C，给报表系统的堆内存大小：20G，可以看到这个配置是相当相当高的了。一般来说，4C 8G的机器扛1500+qps是没什么问题的。这套系统因为主要是查询的数据量大，查询的qps较高，总体的qps在8k左右，因为报表系统也是集群化部署，单台也就3-5K之间徘徊，所以整体的性能是完全够用的。

 

这个系统的职责就是，前置服务是一个订单查询服务，以及一个大盘系统，订单查询系统会有大量用户日常使用，并根据一些条件来发起一些查询请求，调用这个数据查询服务来查询一套数据报表。但是请求相对比较均衡，对数据报表系统产生的请求的压力在4000-6000qps的水平（高峰期，平常是没有这个值），大盘系统一般是一些卖家（商家）在一些特殊活动的时期，或者是特殊的交易窗口的时候会开启（传统电商，还是垂直领域的电商，都有一些活动窗口期），总用户量200W，用户量大概在20W左右，日活1W-2W左右（打开大盘的一些商家），平常对报表系统的压力，也就是在3000qps的水平。如图所示：

![picture.png](https://wechatapppro-1252524126.cdn.xiaoeknow.com/appAKLWLitn7978/image/b_u_5b2225aa46488_oGKN7IvA/ky1dg72m078r.png)

 

另外数据大盘系统还有一些自动刷新页面，每隔5s更新一下页面最新的交易数据，这种页面一般都是在交易窗口期，或者是特殊时间段才会开启。类似于秒杀场景的时候的交易数据监控。

![picture.png](https://wechatapppro-1252524126.cdn.xiaoeknow.com/appAKLWLitn7978/image/b_u_5b2225aa46488_oGKN7IvA/ky1dg72m078r.png)

订单数据分析系统的特点：QPS高，查询数据量大，数据会快速成为垃圾数据。

 

这一套数据分析系统，在正常情况下是没有什么问题的，运行的也一直都很稳定，直到有一次特殊的交易窗口，因为这次交易窗口涉及到的商家比较多，活动也比较多，达到了5w日活，打开大盘的人数大大增加，导致产生了8K+的qps，订单查询的qps也接近了8000左右。这么大的qps，虽然我们数据报表系统是集群化部署，单台服务分下来的请求量大概在6K+左右，正常来说，我们服务器的配置已经算不错了。6Kqps还没有达到极限，但是不知为什么，在数据报表系统运行一段时间之后，就会出现一次性能抖动，出现接口查询超时的问题，抖动之后，就会恢复正常一段时间。过一段时间又一次发生抖动。

![picture.png](https://wechatapppro-1252524126.cdn.xiaoeknow.com/appAKLWLitn7978/image/b_u_5b2225aa46488_oGKN7IvA/ky1dg72m078r.png)

这个现像虽然说不会影响系统的使用，顶多刷新一次就OK了，但是用户体验是非常的差的。于是我们不得不着手排查原因。

首先我们登录了服务器，查看了参数配置，具体的参数配置大概就是我们开头的那一套参数：

-XX:InitialHeapSize=20G -XX:MaxHeapSize=20G -Xss1M -XX:+UseG1GC -XX:SurvivorRatio=8 -XX:MaxGCPauseMillis=20 -XX:G1HeapRegionSize=4M -XX:MaxTenuringThreshold=15 -XX:InitiatingHeapOccupancyPercent=45

从参数上来看，暂时没有发现什么问题。紧接着我们打开拉下来了GC日志，通过GC日志我们发现。

我们给堆内存了20G的内存，然而，Eden区的总大小，始终在1-2G徘徊，运行了很久爬到了2G之后，无法继续往上增加。而G1垃圾回收器，本身就是一个自动调整新生代区域的回收器，最小内存5% * 20 = 1G，而我们观察的日志中，最大也才给到2G，也就是10%的空间。然后，就发现很快就触发以此Mixedgc的过程，MixedGC几乎是几次YGC发生一次。并且MixedGC的垃圾回收的这个过程的次数很多，默认的是8次，几乎每次混合回收，执行的最终的回收过程都是快要接近8次了，每次整个MixedGC过程结束之后，就会空闲出大量的空间。很显然这个现像是不正常的。大家下图：其中绿色的region代表的是eden + survivor

![picture.png](http://wechatapppro-1252524126.cdn.xiaoeknow.com/apppuKyPtrl1086/image/ueditor/12895300_1644391898.png?imageView2/2/q/80%7CimageMogr2/ignore-error/1)

我们本来以为是参数配置的问题，但是查看了参数之后，没有发现调整新生代最大空间的这个参数设置。

所以一定不是手动配置参数导致的问题，而是G1的自动调整出的问题！那么自动调整新生代大小，有一个范围的，5% -60%的比例，还有什么因素呢？

 

答案其实很简单！我们前面讲到的停顿预测模型！停顿预测模型+YGC的时间结合起来，是G1动态调整新生代大小的一个依据。

预测我能够回收的region的个数是多少。 ---回收能力

我根据这个回收能力，结合回收垃圾的时间，停顿时间 ---得到新生代的大小

 

假如说，YGC需要的时间比较久，比如说，新生代现在占用了10G的内存，每次回收需要的时间大概是在200ms+，无法满足停顿时间，就只能调小新生代的总空间大小以此来尽量满足停顿时间。

![picture.png](http://wechatapppro-1252524126.cdn.xiaoeknow.com/apppuKyPtrl1086/image/ueditor/13443000_1644391898.png?imageView2/2/q/80%7CimageMogr2/ignore-error/1)

所以，即使新生代需要扩展，在接下来发生YGC的时候，结合停顿预测模型和历史GC数据，就会判定无法满足GC的时间，此时在YGC结束之后，还是调整region个数到一个合理的范围，不会增大很多，一直到新生代的region达到预测模型中的极限值左右，就会在这个附近徘徊，比如我们这个案例中的情况就是，从5%上涨到10%左右的时候，就一直保持在10%上下浮动。

![picture.png](http://wechatapppro-1252524126.cdn.xiaoeknow.com/apppuKyPtrl1086/image/ueditor/15555900_1644391898.png?imageView2/2/q/80%7CimageMogr2/ignore-error/1)

YGC之后，新生代region数量保持到一个G1认为合理的区间，如图所示：

 

![picture.png](http://wechatapppro-1252524126.cdn.xiaoeknow.com/apppuKyPtrl1086/image/ueditor/14322000_1644391898.png?imageView2/2/q/80%7CimageMogr2/ignore-error/1)

因此新生代的可用内存始终上不去。这就导致，如果说我们查询的qps比较高的时候，会有大量的短周期对象，进入到老年代。从而导致MixedGC的发生，从我们对MixedGC之后堆内存的空闲情况就可以看的出来，其实是有大量的对象晋升至了老年代的，而且这些对象大多数还都是垃圾对象，或者说是多周期对象。

 

4、问题总结

新生代内存比例始终上不去，导致老年代快速被填满达到45%从而触发MixedGC，最终导致频繁触发MixedGC。MixedGC时间比较长，包括各种标记，预清理，选择CSet，最终清理，最终导致的系统整体的性能抖动。

 

5、思考：如何解决？

思路：避免大量短周期存活对象进入老年代，这个是核心的思路。那么调优应该调什么呢？

（1）调大新生代的初始比例？是否可行？我直接把最小值从5%调整到20%

（2）预测模型相关的参数？ 比如说，有一个冷门参数，衰减平均差的衰减因子，这个值可以设置。

（3）调整一下停顿时间？ 调大了有什么影响？有可能导致GC的时候，响应失败？20ms有必要调大吗？