1、案例背景

业务背景：一个小时购电商系统。我们知道，电商平台一般都有几种模式，淘宝这种属于长距离电商，买的东西可能来自于全国各地。京东属于中距离电商平台，有自己的仓储物流系统，买东西基本上是走最近的仓库发货 ，速度上相对会快一点。而在这个基础之上还有近距离电商，比如天猫超市、京东到家、京东小时购等等这种类型的业务，购买之后，立马会有物流系统去接单，配送的。

 

这个系统的特点就是，需要使用大量的缓存，包括一些接入到我们平台的店铺信息，以及店铺的商品信息，平台自营的一些商品、店铺信息等等。并且在商品中心里面，商品更新、新商品上架这些操作会发送mq，我们这边儿的系统，一批一批的去取缓存数据，消费数据，更新redis缓存，一部分数据同步到本地缓存中。

![picture.png](http://wechatapppro-1252524126.cdn.xiaoeknow.com/apppuKyPtrl1086/image/ueditor/91988100_1646623855.png?imageView2/2/q/80%7CimageMogr2/ignore-error/1)

然后分批消费的数据会在内存里进行解析，更新到redis之后，再同步一部分数据到本地缓存中。

另外一个缓存更新的业务点是，有很多商品数据是直接批量上架的，尤其是自营类型的商品，会直接批量上架一批次的商品，那么在商品更新之后，会发送一条通知消息给这个缓存系统，缓存系统拿到通知消息后，去生成一个job任务，然后执行这个job，去读取商品系统里面的一些数据，缓存到系统中去。

2、问题现场

整个这个过程，在平常系统正常运行的时候，是没什么问题的，因为商品本身上架的频率就不高，商品信息的一些数据更新也并不是很频繁，因此在日常的运行中这个系统运行起来没有任何问题。

其实从业务逻辑上来说，只要没有特殊情况，这个业务逻辑上也是没有任何问题的，因为只是一个缓存更新的逻辑而已。

然而在双十一前夕，商户运营那边儿反馈，有少量商品的缓存信息不显示，或者显示的很慢，要加载好几秒才能加载到，实时性比较差。虽然这个问题听起来不是很严重，但是毕竟是个问题，尤其是在双十一这种大促时间结点的前夕。

于是，我们团队开始去排查这个问题，具体的表现是在双十一前夕，商品中心的qps并不是很大，单台机器，在高峰期只有4-500的qps，总qps也不过就是5k+。然后再去观察redis集群的qps，总体也是在一个比较健康的范围内，不管是带宽使用率（我们带宽是100MB，当时高峰期查看只占用了20MB左右的带宽），还是CPU、内存，都是比较合理的值。那为什么还是会出现商品系统查询商品信息的时候加载慢的情况呢？这个时候我们只能去看看出现加载慢的时候的具体情况。查看商品系统的日志发现，在出现加载慢的时候，日志中有一条 “写入数据到缓存中……”log日志，在这个日志打印之后大概过了有四五秒中才继续往后打印日志。

![picture.png](http://wechatapppro-1252524126.cdn.xiaoeknow.com/apppuKyPtrl1086/image/ueditor/92984200_1646623855.png?imageView2/2/q/80%7CimageMogr2/ignore-error/1)

那么这个日志有啥意义呢？其实很简单，因为我们在缓存没有命中的时候，是需要从数据库中查询数据，然后加载到缓存中去的，然后加载完成之后，会把查询到的数据返回给前端。如果缓存设置卡住的时间比较长，就会造成请求的整体响应时间比较长。

![picture.png](http://wechatapppro-1252524126.cdn.xiaoeknow.com/apppuKyPtrl1086/image/ueditor/94438000_1646623855.png?imageView2/2/q/80%7CimageMogr2/ignore-error/1)

在QPS不高的情况下，出现查询超时，并且是经过数据库查询之后，设置数据到缓存中导致的超时。而redis本身又没有什么问题（刚刚提到的带宽，CPU，内存指标都是正常的）。于是没有办法，我们就只能继续针对redis本身来查问题。

 

3、redis缓存有啥问题？

这里给大家补充一个细节，就是，更新商品的缓存，我们是按照店铺这个来加锁的，因为这样做不至于产生大量的分布式锁在redis中。因为按照店铺的话，这个粒度其实已经够了，每个店铺，更新商品的频率哪怕是双十一前的准备，频率也不会很高。

言归正传，查redis的时候，因为我们其实已经知道缓存更新的时候是按照店铺的维度来加的锁，那么就直接查看一下这个锁相关的内容，结合redis分布式锁的日志发现，获取锁失败进入等待的时间比较长，导致没有直接把这个缓存设置到redis中，以至于，我们这个请求的接口等待的时间比较长，大家想想看，4-5s钟的等待时间，很多接口如果使用默认的超时时间，直接就判定超时了！所以这个问题还是非常严重的。

 

![picture.png](http://wechatapppro-1252524126.cdn.xiaoeknow.com/apppuKyPtrl1086/image/ueditor/94011400_1646623855.png?imageView2/2/q/80%7CimageMogr2/ignore-error/1)

知道这个问题之后，我们开始尝试排查解决，首先要找到的就是为什么会超时？谁在持有这把锁，导致更新的时候出现的这么长时间的等待？要查这个问题，其实相对容易一点儿，我们直接通过redis的客户端，来查看相关redis 分布式锁的lock key就可以了。这个其实也简单，大家了解redis分布式锁的都知道，其实加锁的本质就是先去获取一个key，这个key对应的value里面保存了一些加锁的信息。

很快我们查到了匹配这个商铺相关的分布式锁，此时，发现，加锁的机器，居然是我们上面提到的那个小时购平台的缓存同步系统的其中一台机器！

![picture.png](http://wechatapppro-1252524126.cdn.xiaoeknow.com/apppuKyPtrl1086/image/ueditor/92952900_1646623855.png?imageView2/2/q/80%7CimageMogr2/ignore-error/1)

到了这一步，很显然我们已经知道大概的原因了，那就是因为这个缓存同步服务里面的一些更新操作，获取到了锁，去更新这个商铺的商品缓存，然而更新的时间比较长，导致商品系统查询数据库->更新缓存这个操作被阻塞了，最终导致接口请求时间非常长。那么接下来我们就是要找到这个原因，为啥同步缓存会这么久？