记一次由于大量大对象产生导致的系统吞吐量降低优化实践（一）

 

1、案例背景回顾

案例的业务背景：一个提供订单数据分析的业务系统。

数据报表系统的配置：32G 16C，给报表系统的堆内存大小：20G，可以看到这个配置是相当相当高的了。一般来说，4C 8G的机器扛1500+qps是没什么问题的。这套系统因为主要是查询的数据量大，查询的qps较高，总体的qps在8k左右，因为报表系统也是集群化部署，单台也就3-5K之间徘徊，所以整体的性能是完全够用的。

 

这个系统的职责就是，前置服务是一个订单查询服务，以及一个大盘系统，订单查询系统会有大量用户日常使用，并根据一些条件来发起一些查询请求，调用这个数据查询服务来查询一套数据报表。但是请求相对比较均衡，对数据报表系统产生的请求的压力在4000-6000qps的水平，大盘系统一般是一些卖家在一些特殊活动的时期，或者是特殊的交易窗口的时候会开启，用户量大概在20W左右，日活1W-2W左右，平常对报表系统的压力，也就是在3000qps的水平。如图所示：

![picture.png](http://wechatapppro-1252524126.cdn.xiaoeknow.com/apppuKyPtrl1086/image/ueditor/18838200_1644392136.png?imageView2/2/q/80%7CimageMogr2/ignore-error/1)

 

另外数据大盘系统还有一些自动刷新页面，每隔5s更新一下页面最新的交易数据，这种页面一般都是在交易窗口期，或者是特殊时间段才会开启。类似于秒杀场景的时候的交易数据监控。

![picture.png](http://wechatapppro-1252524126.cdn.xiaoeknow.com/apppuKyPtrl1086/image/ueditor/19333800_1644392136.png?imageView2/2/q/80%7CimageMogr2/ignore-error/1)

这套系统经过优化以后，最终的参数是：

-XX:InitialHeapSize=20G -XX:MaxHeapSize=20G -Xss1M -XX:+UseG1GC -XX:SurvivorRatio=8 -XX:MaxGCPauseMillis=300 -XX:G1HeapRegionSize=4M -XX:MaxTenuringThreshold=15 -XX:InitiatingHeapOccupancyPercent=45

经过优化后，抖动问题最终消失，所有请求均可以正常返回，并且region数量也保持在一个比较合理的范围，如图所示：

![picture.png](https://wechatapppro-1252524126.cdn.xiaoeknow.com/appAKLWLitn7978/image/b_u_5b2225aa46488_oGKN7IvA/ky1dg72m078r.png)

 

2、场景介绍

本次问题发生的场景是在一次需求上线之后，这次的需求是在订单数据分析系统上添加一个功能。这个功能简单来说就是，一个数据对比页面。比如价格环比，价格波动，订单量增涨率，增涨环比，平均价格，平均价格环比，中位数，离散分布图等等。

大家如果有过数据大盘开发经历的应该都知道，做这些环比的页面和简单的数据查询不太一样，数据查询多数还是按照某个周期，或者是某几个条件去查，可以通过分页，分日期维度，时间维度来保证每次查询的数据量不会太大，即使是实时监控页面，需要展示的数据量也不多，主要的压力来源是QPS。

而环比这种操作，需要的是大量历史数据的抽取，计算，对比的，要么就是提前计算好一些数据，然后呢把它直接做展示（大数据计算，直接拿一个结论）。然后把最终的结果展示到页面中。这种页面，对内存使用的压力会比较大。

在增加了这么一个页面以后，最开始用的人比较少，可能每天就有那么几百次请求。随着系统的运行，这个页面因为各种数据分析能够非常全面的反映出一段时间的交易情况，请求量就开始逐步上升。最终达到了高峰期单台服务每秒几百的请求量。

![picture.png](https://wechatapppro-1252524126.cdn.xiaoeknow.com/appAKLWLitn7978/image/b_u_5b2225aa46488_oGKN7IvA/ky1dg72m078r.png)

此时，开始有商户逐步反应说，有时候系统页面刷新要好久才能刷新出来，有时候甚至会出现报错，重新刷新才能刷新出来数据。

这个问题的现像和前面的现像有点类似。经过我们观察GC日志，发现Eden区的大小也正常，当时MixedGC又开始非常频繁。并且经过我们对日志的大量观察，发现新生代区域的对象增涨速度其实并不快，反而是老年代增涨速度非常快。如图所示，

![picture.png](http://wechatapppro-1252524126.cdn.xiaoeknow.com/apppuKyPtrl1086/image/ueditor/21627900_1644392136.png?imageView2/2/q/80%7CimageMogr2/ignore-error/1)

直接导致的结果就是，YGC经常是InitialMark，也就是MixedGC的初始标记阶段，然后出现了大量的MixedGC。最终就导致我们这个系统的整体吞吐量下降的非常多。直观的表现就是，我们在添加新页面之前的单台服务器的QPS可以达到6K，添加了这个页面的时候，平常问题不大，一到月中，月末就会有大量的商家打开这个环比页面，导致吞吐量骤降至单台3K左右，于是就有部分用户反馈系统反应慢，偶尔出现超时的现像。

这个现像最开始我们也尝试修改了一些参数，比如调大停顿时间（毕竟上一次尝到了甜头了），包括增大堆内存等等手段。最终的结果是，刚开始还好，运行了一段时间后，依然会出现上面的现像，没有从根本上解决掉问题。

 

3、问题原因分析

频繁发生MixedGC，导致系统吞吐量下降，并造成大量请求超时。产生问题的直接原因很简单，就是这个MixedGC频繁的问题。那么MixedGC频繁的原因又是什么呢？除了我们上节课说的大量的短周期对象进入老年代之外，有没有其他的原因导致大量的对象进入老年代？

在我们这个案例里面，其实存在这样的一个原因，那就是在大量报表分析的时候，由于它的处理的数据比较多，一次取出来很多数据，导致存储数据的对象直接走的大对象分配。最终导致老年代占比急剧上升。（注意，虽然大对象的分配是专门找的分区存储，但是它占用的空间是会算在老年代空间中的）如图所示：

![picture.png](http://wechatapppro-1252524126.cdn.xiaoeknow.com/apppuKyPtrl1086/image/ueditor/23157700_1644392136.png?imageView2/2/q/80%7CimageMogr2/ignore-error/1)

正是这个原因才导致了系统经常进入MixedGC，虽然说MixedGC也会按照满足停顿时间进行，但是频繁的发生MixedGC就导致经常要停顿，导致QPS会被拖的比较慢。因为你需要大量是STW去处理GC。并且MixedGC的回收阶段又会持续很多次（最多8次）。

 

同时，因为走大对象分配，其实容易出现加锁分配对象的情况，导致这个分配过程其实速度也不如对象能够直接走TLAB的速度快。

当然上面的是我们最终总结出来的结论，分析过程其实还是很曲折的，因为最开始盲目的调整停顿时间，堆内存大小等参数没有效果，最后经过仔细观察，同时又打开了打印region使用详情的参数，以及打印TLAB的日志开关，才发现原来是大量的region都被标上了HUMS的类型，才最终确定是这个原因。TLAB分配是不是有慢速分配一些数据。一个线程里面有多少次慢速分配的过程。

参数如下：

-XX:+PrintTLAB -XX:+UnlockDiagnosticVMOptions -XX:+G1PrintRegionLivenessInfo

 

4、问题总结？

由于对象过大，导致大量走大对象分配的请求，直接拖慢了环比页面的速度。

又因为大量的大对象分配，导致MixedGC触发的频繁，导致了系统总吞吐量的下降。

5、解决思路

思路：避免大对象分配导致大量短周期的对象进入老年代，这个是核心的思路。在这个思路上，我们应该通过怎样的调整来解决这个问题？

 

（1）大对象的判定规则是什么？

（2）能否通过调整TLAB来增大TLAB分配对象的次数占总对象分配次数的比例？