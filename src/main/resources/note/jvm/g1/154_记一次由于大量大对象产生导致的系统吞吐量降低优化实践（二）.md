1、案例背景回顾

案例的业务背景：一个提供订单数据分析的业务系统。

数据报表系统的配置：32G 16C，给报表系统的堆内存大小：20G，可以看到这个配置是相当相当高的了。一般来说，4C 8G的机器扛1500+qps是没什么问题的。这套系统因为主要是查询的数据量大，查询的qps较高，总体的qps在8k左右，因为报表系统也是集群化部署，单台也就3-5K之间徘徊，所以整体的性能是完全够用的。

 

这个系统的职责就是，前置服务是一个订单查询服务，以及一个大盘系统，订单查询系统会有大量用户日常使用，并根据一些条件来发起一些查询请求，调用这个数据查询服务来查询一套数据报表。但是请求相对比较均衡，对数据报表系统产生的请求的压力在4000-6000qps的水平，大盘系统一般是一些卖家在一些特殊活动的时期，或者是特殊的交易窗口的时候会开启，用户量大概在20W左右，日活1W-2W左右，平常对报表系统的压力，也就是在3000qps的水平。如图所示：

![picture.png](http://wechatapppro-1252524126.cdn.xiaoeknow.com/apppuKyPtrl1086/image/ueditor/46137800_1644392208.png?imageView2/2/q/80%7CimageMogr2/ignore-error/1)

 

另外数据大盘系统还有一些自动刷新页面，每隔5s更新一下页面最新的交易数据，这种页面一般都是在交易窗口期，或者是特殊时间段才会开启。类似于秒杀场景的时候的交易数据监控。

![picture.png](http://wechatapppro-1252524126.cdn.xiaoeknow.com/apppuKyPtrl1086/image/ueditor/95533400_1644392208.png?imageView2/2/q/80%7CimageMogr2/ignore-error/1)

这套系统经过优化以后，最终的参数是：

-XX:InitialHeapSize=20G -XX:MaxHeapSize=20G -Xss1M -XX:+UseG1GC -XX:SurvivorRatio=8 -XX:MaxGCPauseMillis=300 -XX:G1HeapRegionSize=4M -XX:MaxTenuringThreshold=15 -XX:InitiatingHeapOccupancyPercent=45

 

经过优化后，抖动问题最终消失，所有请求均可以正常返回，并且region数量也保持在一个比较合理的范围，如图所示：

![picture.png](https://wechatapppro-1252524126.cdn.xiaoeknow.com/appAKLWLitn7978/image/b_u_5b2225aa46488_oGKN7IvA/ky1dg72m078r.png)

 

2、场景介绍

本次问题发生的场景是在一次需求之后，这次的需求是在订单数据分析系统上添加一个功能。这个功能简单来说就是，一个数据对比页面。比如价格环比，价格波动，订单量增涨率，增涨环比，平均价格，平均价格环比，中位数，离散分布图等等。

大家如果有过数据大盘开发经历的应该都知道，做这些环比的页面和简单的数据查询不太一样，数据查询多数还是按照某个周期去查，可以通过分页，分日期维度，时间维度来保证每次查询的数据量不会太大，即使是实时监控页面，需要展示的数据量也不多，主要的压力来源是QPS。而环比这种操作，需要的是大量历史数据的抽取，计算，对比的，然后把最终的结果展示到页面中。这种页面，对内存使用的压力会比较大。

在增加了这么一个页面以后，最开始用的人比较少，可能每天就有那么几百次请求。随着系统的运行，这个页面因为各种数据分析能够非常全面的反映出一段时间的交易情况，请求量就开始逐步上升。最终达到了高峰期单台服务每秒几百的请求量。

![picture.png](https://wechatapppro-1252524126.cdn.xiaoeknow.com/appAKLWLitn7978/image/b_u_5b2225aa46488_oGKN7IvA/ky1dg72m078r.png)

此时，开始有商户逐步反应说，有时候系统页面刷新要好久才能刷新出来，有时候甚至会出现报错，重新刷新才能刷新出来数据。

这个问题的现像和前面的现像有点类似。经过我们观察GC日志，发现Eden区的大小也正常，当时MixedGC又开始非常频繁。并且经过我们对日志的大量观察，发现新生代区域的对象增涨速度其实并不快，反而是老年代增涨速度非常快。如图所示，

![picture.png](https://wechatapppro-1252524126.cdn.xiaoeknow.com/appAKLWLitn7978/image/b_u_5b2225aa46488_oGKN7IvA/ky1dg72m078r.png)

直接导致的结果就是，YGC经常是InitialMark，也就是MixedGC的初始标记阶段，然后出现了大量的MixedGC。最终就导致我们这个系统的整体吞吐量下降的非常多。直观的表现就是，我们在添加新页面之前的单台服务器的QPS可以达到6K，添加了这个页面的时候，平常问题不大，一到月中，月末就会有大量的商家打开这个环比页面，导致吞吐量骤降至单台3K左右，于是就有部分用户反馈系统反应慢，偶尔出现超时的现像。

这个现像最开始我们也尝试修改了一些参数，比如调大停顿时间（毕竟上一次尝到了甜头了），包括增大堆内存等等手段。最终的结果是，刚开始还好，运行了一段时间后，依然会出现上面的现像，没有从根本上解决掉问题。

 

3、问题原因分析

频繁发生MixedGC，导致系统吞吐量下降，并造成大量请求超时。产生问题的直接原因很简单，就是这个MixedGC频繁的问题。那么MixedGC频繁的原因又是什么呢？除了我们上节课说的大量的垃圾对象进入老年代之外，有没有其他的原因导致大量的对象进入老年代？

在我们这个案例里面，其实存在这样的一个原因，那就是在大量报表分析的时候，由于它的处理的数据比较多，一次取出来很多数据，导致存储数据的对象直接走的大对象分配。最终导致老年代占比急剧上升。（注意，虽然大对象的分配是专门找的分区存储，但是它占用的空间是会算在老年代空间中的）如图所示：

![picture.png](https://wechatapppro-1252524126.cdn.xiaoeknow.com/appAKLWLitn7978/image/b_u_5b2225aa46488_oGKN7IvA/ky1dg72m078r.png)

正是这个原因才导致了系统经常进入MixedGC，虽然说MixedGC也会按照满足停顿时间进行，但是频繁的发生MixedGC就导致经常要停顿，导致QPS会被拖的比较慢。因为你需要大量是STW去处理GC。并且MixedGC的回收阶段又会持续很多次（最多8次）。

 

同时，因为走大对象分配，其实容易出现加锁分配对象的情况，导致这个分配过程其实速度也不如对象能够直接走TLAB的速度快。

当然上面的是我们最终总结出来的结论，分析过程其实还是很曲折的，因为最开始盲目的调整停顿时间，堆内存大小等参数没有效果，最后经过仔细观察，同时又打开了打印region使用详情的参数，以及打印TLAB的日志开关，才发现原来是大量的region都被标上了HUMS的类型，才最终确定是这个原因。

参数如下：

-XX:+PrintTLAB -XX:+UnlockDiagnosticVMOptions -XX:+G1PrintRegionLivenessInfo

 

4、问题总结？

由于对象过大，导致大量走大对象分配的请求，直接拖慢了环比页面的速度。

又因为大量的大对象分配，导致MixedGC触发的频繁，导致了系统总吞吐量的下降。

5、解决思路

思路：避免大对象分配导致大量短周期的对象进入老年代，这个是核心的思路。在这个思路上，我们应该通过怎样的调整来解决这个问题？

（1）大对象的判定规则是什么？

（2）能否通过调整TLAB来增大TLAB分配的比例？

首先第一点，大对象的判定规则很简单，对象大小达到一个region的一半儿的时候，就会走大对象分配，那么第一个思路就是把region的大小调大。调大的基准是什么呢？调到多大合适呢？

其实这个很简单，就是我们根据环比页面的功能，看看里面的大量的查询请求，所分配的对象到底有多大就好了，如果说我们是一次性查出来了10000条数据，就会导致一个List非常大。可能就直接走大对象的分配了。所以要对系统里面的数据进行分析。

List有没有过大，另外一个就是普通的对象有没有过大的。

4M的region是我们调优前的region大小。一个订单对象，或者是商品对象直接达到2M？

经过我们的分析，发现我们后端对批量查询的设置最大是2000条数据，然后分批次去查。根据计算，一批数据最大的占用空间6M左右。因此我们把region设置成了16MB。

![picture.png](http://wechatapppro-1252524126.cdn.xiaoeknow.com/apppuKyPtrl1086/image/ueditor/99441100_1644392208.png?imageView2/2/q/80%7CimageMogr2/ignore-error/1)

然后再一次测试，发现很少出现请求超时了。也就是，基本上避免了直接进入大对象分配，然后导致MixedGC的情况。

但是还是会有一个并不影响系统使用的小问题，就是我们在做压测的时候，发现刚开始一段时间，QPS还是上不去，会有一个爬升的过程。过了一段时间，QPS才会稳步上升到一个比较高的水准。

考虑到对象分配是优先走的TLAB分配，而我们在分析问题的时候，把TLAB的相关内容也打开了，发现TLAB的refill次数非常多，并且在开始一段时间的slow分配次数，非常多。很明显这个是因为没有走TLAB分配。

所以我们经过一段时间的调试，最终把TLAB的初始大小设置到了1M，TLAB 4K 8K这样的值，就已经非常非常大了。

这样的设置能够让直接让系统在启动初期就能达到一个比较高的qps，即大量的普通查询请求，基本上都可以直接走TLAB分配，并且允许TLAB自动调整，在重新测试之后，发现系统到达最高QPS的速度明显快了很多，基本上启动之后就可以成功达到最高qps，并且能够持续很长时间稳定到这个qps。

**注意，**在调整TLAB的时候，最好不要指定TLABSize，因为它相当于直接指定TLAB的大小，不允许系统自动调整。如果直接设置了这个值，G1就无法在内存碎片和分配效率直接找一个平衡点。另外设置了最小值的时候，不要关闭ResizeTLAB这个开关，否则也是无法达到自动调整的目的。我们只需要设置一下MinTLABSize=1M即可。

 

TLAB本身不是G1的专属，是JVM本身就有的一个对象分配的优化。一定要记住，G1根据region分区的这个特点，做了一下自己的适配。

 

至此这个系统参数基本上就调优完毕了。调优后的参数：

 

-XX:InitialHeapSize=20G -XX:MaxHeapSize=20G -Xss1M -XX:MinTLABSize=1M -XX:+UseG1GC -XX:SurvivorRatio=8 -XX:MaxGCPauseMillis=300 -XX:G1HeapRegionSize=16M -XX:MaxTenuringThreshold=15 -XX:InitiatingHeapOccupancyPercent=45

 

6、总结

（1）regionSize要设置合理，避免大对象分配（大量的短周期对象走大对象分配）

（2）TLAB本身如果没有大量请求走TLAB分配，是会导致吞吐量下降一些的。我们就需要调整TLAB的大小，如果默认直接等待G1自己去调整TLAB的大小，可能会有一段时间的爬坡期。所以说，可以根据系统的情况，设置一个稍微大一点的TLAB的初始值-XX:MinTLABSize