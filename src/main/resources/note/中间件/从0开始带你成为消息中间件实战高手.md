
> 从0开始带你成为消息中间件实战高手 的笔记



### 01 一个真实电商订单系统的整体架构、业务流程及负载情况

#### 一个订单系统的业务流程

<img src="https://s1.ax1x.com/2020/07/20/U4vBKH.jpg" alt="U4vBKH.jpg" border="0" />


####   一个订单系统的非核心流程
<img src="https://s1.ax1x.com/2020/07/20/U4xISO.jpg" alt="U4xISO.jpg" border="0" />

### 02 授人以渔：能概括一下你们系统的架构设计、业务流程以及负载情况吗？
> 首先你得知道现在你的系统，或者行业里其他普遍的一些系统，都有哪些技术难点和痛点，面临哪些问题。

>  接着要针对这些问题，反过来去学习一个技术，学习完这个技术之后，一定要思考如何将技术代入到真实的环境中，
  去解决对应的问题。
  
### 03 系统面临的现实问题：下订单的同时还要发券、发红包、Push推送，性能太差！

> 系统的压力来自哪

+ 电商这种系统,用户都会集中在晚上几个小时,为什么就不分析了, 他的访问曲线不是平均的,而是集中在一起的

<img src="https://s1.ax1x.com/2020/07/20/U5SORf.jpg" alt="U5SORf.jpg" border="0" />

+ 这种架构的压力都会落在单点上,上图就是mysql, 依据经验 4核8g mysql 最好1000-1500 能2000,16核32SSD 1万应该是极限,可能会出问题

+ 上面业务的问题, 在流程8中 ,支付回调中 ,推送,优惠券等,会有大量业务,太耗时


### 04 授人以渔：你们系统的核心流程性能如何？有没有哪个环节拖慢了速度？
> 普通项目还是业务处理和sql

> rpc 和第三方接口调用 ,同步的

要思考，在当前这样的系统压力下：

+ 系统的核心业务流程性能如何？
+ 核心流程的每个步骤要耗费多长时间？
+ 现在核心流程的性能你满意吗？是否还有优化的空间？
+ 在系统高峰期的时候，机器和数据库负载很高，是否对核心流程的性能有影响？
+ 如果有影响的话，会有多大的影响？

那你就想，你的这个系统做一个SaaS云平台的模式，提供给几万个公司，百万用户使用，不就可以了？你要自己去模拟这个场景。

然后，你按照文中的思路去推算出系统高峰期的负载，以及你的线上系统的机器的压力，到底要部署多少机器去满足这个压力。 


### 05 系统面临的现实问题：订单退款时经常流程失败，无法完成退款！
> 退款流程

<img src="https://s1.ax1x.com/2020/07/20/U5Fwxx.jpg" alt="U5Fwxx.jpg" border="0" />

+ 问题一: 和下单一样,流程过长  

+ 问题二: 如果退款失败怎么办

+ 下单之后不付款怎么办
> 下单之后会占用库存, 不付款 ,别人也买不了这个商品

给这种订单一个超时时间,超过 取消订单

+ 如果 下单之后不付款的单子 巨多,怎么处理
> 不停地去扫描表  效率太差,占用太多资源


### 06 授人以渔：你们系统出现过核心流程链路失败的情况吗？
> low 系统..

假设下 如果失败,可以保存失败操作,开始重试

### 07 系统面临的现实问题：第三方客户系统的对接耦合性太高，经常出问题！
> 还是上面的 订单支付 流程

+ 还是流程中有很多对接的第三方系统 ,比如支付,库仓 发货

<img src="https://s1.ax1x.com/2020/07/20/U5EDs0.jpg" alt="U5EDs0.jpg" border="0" />


+ 积分,发货,优惠券等系统都是和订单系统耦合在一起的

+ 这样订单系统和第三物流系统 也算耦合到一起, 会带来不确认性, 会基于网络,第三方系统大量原因导致 性能差

### 08 授人以渔：你们有没有跟第三方系统对接过，有遇到什么问题吗？
> 同步调第三方系统 真的一言难尽,  会各种坑, 随时保存日志,记得甩锅

### 09 系统面临的现实问题：大数据团队需要订单数据，该怎么办？

#### 大数据到底是干嘛的？
> 通过实时 采集来的数据,分析用户行为和其他结论 

每天如果有100万用户来访问你的APP，积累下来的一些浏览行为、访问行为、交易行为都是各种数据，这个数据量很大，所以你可以称之为“大数据”

大数据团队每天要负责的事情，说白了就是去尽可能的搜集每天100万用户在你的APP上的各种行为数据。

#### 大数据与我们系统的关系
> 订单数据等  他们需要分析每天几十万个订单，从中提取出老板最关心的APP交易数据报表！ 

方法

   +   select 查询
       
        大sql  而且查询次数不低,  数据库的cpu 和io 占用会很高, 其他操作就效率很低了
        

### 10 授人以渔：你们有没有遇到过自己系统的数据，其他团队需要获取的？
> 没有 

假设有, 比如微服务 过来取数据, 加缓存( 可以是缓存,也可以是新表), 异步同步  查询走缓存 

### 11 系统面临的现实问题：秒杀活动时数据库压力太大，该怎么缓解？

> 上面系统的缺点 是同步流程太长,效率太差

 假如在平时晚上的高峰使用期，最顶峰的时候大概是每秒2000左右的请求压力到订单系统上来。
 
 如果用户每秒会发起2000个请求到我们的订单系统的各类接口，包括下单接口、退款接口、查询接口等等，那么你觉得我们的订单系统每秒会执行多少条SQL在订单数据库上？
 
 一般你可以认为平均每个接口会执行2~3次的数据库操作。
 
 一般一个接口根据业务复杂度的不同，有的接口可能处理一个请求要执行五六次数据库操作，有的接口可能是1次数据库操作+两三个其他系统的接口调用（比如库存系统、营销系统）。

 总之，一般来说，业务系统的接口处理逻辑，基本都集中在对自己的数据库的操作以及对其他系统的调用上
 
 
#### 双11之类的大促活动有多恐怖

如果有200万用户参与双11活动，在双11购物最高峰的时候，假设会达到每秒至少1万的QPS。

也就是说，光是系统被请求的QPS就会达到1万以上，那么系统请求数据库的QPS就会达到2万以上。16核32G SSD 数据库性能，是无论如何扛不住每秒2万请求的。 

### 12 授人以渔：你们系统会不会遇到流量洪峰的场景，导致瞬时压力过大？
> 没有

假设有,异步处理, mq 削峰,  失败了就  开重试 ,最大重试次数还是失败  ,取消吧


### 13 阶段性复习：一张思维导图给你梳理高并发订单系统面临的技术痛点！

<img src="https://s1.ax1x.com/2020/07/21/UovGkR.jpg" alt="UovGkR.jpg" border="0" />

### 14 阶段性复习：放大100倍压力，也要找出你系统的技术挑战！

+ 第一，大家先思考一下系统的核心业务流程，当然不是指那种查询之类的操作。所谓核心链路指的是对你的系统进行的数据更新的操作，这才是核心链路，因为查询操作一般来说不涉及复杂的业务逻辑，主要是对数据的展示。
    
    对你的系统的核心链路分析一下，有哪些步骤，这些步骤各自的性能如何，综合起来让你的核心链路的性能如何？在这里是否有改进的空间？



+ 第二，大家可以思考一下，在你的系统中，是否有类似后台线程定时补偿的逻辑？

    比如订单长时间未支付就要自动关闭它，你们系统里有没有那种后台线程，会定时扫描你的数据，对异常数据进行补偿、自动修复等操作的？

    如果有的话，这种数据一般量有多大？如果没有，你可以思考一下，你们系统的核心数据是否需要类似的后台自动扫描机制？


+ 第三，大家可以思考一下，在你的系统里有没有跟第三方系统进行耦合？就是一些核心流程里需要同步调用第三方系统进行查询、更新等操作，第三方系统是否对你的核心链路有性能和稳定性上的影响？

+ 第四，大家可以思考一下，在你的核心链路中，是否存在那种关键步骤可能会失败的情况？万一失败了该怎么办？



+ 第五，大家可以思考一下，平时是否存在其他系统需要获取你们数据的情况？他们是如何获取你们数据的？

    是直接跑SQL从你们数据库里查询？或者是调用你们的接口来获取数据？是否存在这种情况？如果有，对你们有什么影响吗？



+ 第六，你们的系统是否存在流量洪峰的情况，有时候突然之间访问量增大好几倍，是否会对你们的系统产生无法承受的压力？

### 15 解决订单系统诸多问题的核心技术：消息中间件到底是什么？
#### 同步调用
用户发起一个请求，系统A收到请求，接着系统A必须立马去调用系统B，直到系统B返回了，系统A才能返回结果给用户，这种模式其实就是所谓的“同步调用”。

#### 消息中间件的异步

为系统A仅仅是发个消息到MQ，至于系统B什么时候获取消息，有没有获取消息，他是不管的。所以这种情况下，我们说系统A和系统B是异步调用。

#### 作用 

主要的作用有这么几个，包括异步化提升性能，降低系统耦合，流量削峰，等等

MQ进行流量削峰的效果，系统A发送过来的每秒1万请求是一个流量洪峰，然后MQ直接给扛下来了，都存储自己本地磁盘，这个过程就是流量削峰的过程，瞬间把一个洪峰给削下来了，让系统B后续慢慢获取消息来处理。

### 16 授人以渔：结合自己的系统问题思考一下，MQ有什么用处？

假设
1. 上传文件比如file是一个系统 具体业务一个系统 他们直接用mq ,file系统接收到文件存到文件服务器写一个消息给mq然后就返给用户结果 业务系统从mq接受消息进行业务处理 把处理结果写一个消息给mq , file系统接受消息更新文件处理结果， 当用户需要刷新文件上传结果的时候查询数据库就可以了
2. 在和硬件对接比如接受考勤信息也会用mq
3. 日志
4. 异步短信提示等

### 17 领导的要求：你来对 Kafka、RabbitMQ 以及 RocketMQ 进行技术选型调研

+ RabbitMQ  单机吞吐量 万级别, 基本不丢,功能全,web管理页面很方便, 集群模式麻烦 ,基于 erlang 开发

+ Kafka   10 万级，高吞吐 ,基本不丢 ,分布式, 功能不全, 但适合大数据和日志系统

+ RocketMQ 10 万级，支撑高吞吐, 基本不丢 ,分布式, 功能全, 可视化界面

### 18 授人以渔：你们公司主要使用的 MQ 是哪种？为什么要选用它？

 小项目和以前的 很多都是Rabbit ,熟悉,而且能支撑服务需求
 
 但现在Roket 好像用的不少

### 19 新技术引入：给团队分享 RocketMQ 的架构原理和使用方式
+ RocketMQ是如何集群化部署来承载高并发访问的？
+ 如果RocketMQ中要存储海量消息，如何实现分布式存储架构？

#### MQ如何集群化部署来支撑高并发访问？
发送消息到MQ的系统会把消息分散发送给多台不同的机器，假设一共有1万条消息，分散发送给10台机器，可能每台机器就是接收到1000条消息

每台机器上部署的RocketMQ进程一般称之为Broker，每个Broker都会收到不同的消息，然后就会把这批消息存储在自己本地的磁盘文件里

#### 高可用保障：万一Broker宕机了怎么办？
RocketMQ的解决思路是Broker主从架构以及多副本策略。

Master Broker收到消息之后会同步给Slave Broker，这样Slave Broker上就能有一模一样的一份副本数据！

这样同一条消息在RocketMQ整个集群里不就有两个副本了，一个在Master Broker里，一个在Slave Broker里！

这个时候如果任何一个Master Broker出现故障，还有一个Slave Broker上有一份数据副本，可以保证数据不丢失，还能继续对外提供服务，保证了MQ的可靠性和高可用性

#### 数据路由：怎么知道访问哪个Broker？

有一个NameServer的概念，他也是独立部署在几台机器上的 , 如果是集群, 注册的时候 会在每个NameServer 都注册


### 20 授人以渔：结合你对其他 MQ 的了解，思考 RocketMQ 的设计有何特点？

kafka集群架构分为leader和follower，每个topic下分为partition，partition分为primary和replication，partition主节点和副本节点存储在不同的节点上来保证集群的高可用，每个消息的partition可以分配到不同的节点来分布式存储，follower来同步leader节点的信息

kafka和Rocketmq都是分布式的消息系统，

在集群化部署方面，kafka通过zk进行节点协调，而rocketmq通过自身namesrv进行节点协调，所以在协调节点的设计上rocket显得更加轻。 

存储方面，在Kafka中，是1个topic（就是一个业务场景）有多个partition（对应3个物理文件目录），当需要存储数据的时候，会把topic中一个parition大文件分成多个小文件段。通过多个小文件段，就轻松实现定期清除或删除已经消费完文件。降低磁盘占用。

在rocketmq中，采用的是混合型的存储结构，即为Broker单个实例下所有的队列共用一个日志数据文件（即为CommitLog）来存储。

两者在对比上，Kafka采用的是独立型的存储结构，每个队列一个文件。RocketMQ采用混合型存储结构的缺点在于，会存在较多的随机读操作，因此读的效率偏低。同时消费消息需要依赖ConsumeQueue，构建该逻辑消费队列需要一定开销。 

主从备份方面：生产者向kafka写入消息时，一般会写入多个分区（partition），kafka提供冗余机制，即每个分区都有多个相同的备份(replica)，kafka把分区所有副本均匀分配到其他broker上，并从这些副本中挑选一个作为leader副本对外提供服务，其他副本称为follwer副本。当leader副本所在的broker有可能宕机，这时follower副本会竞争成为leader，继续提供服务。 

而当生产者者向rocketmq写入消息时，会将数据写入集群中的相关master broker上，而每个master broker都有1到多个slave broker, 这样在一定程度上保证master出现了不可恢复的故障时，不丢失数据。 同时如果master宕机了，消费者会自动重连到相应的salve上，不会出现消费停滞，那么同时在master和slave数据同步分为同步复制(有一定的效率损失)和异步复制(数据不一致) 

在生产和消费消息方面: 在kafka中，每条发布到Kafka集群的消息都有一个类别，这个类别被称为Topic，物理上不同Topic的消息分开存储，逻辑上一个Topic的消息虽然保存于一个或多个broker上但只需指定消息的Topic即可生产或消费数据而不必关心数据存于何处，而这种能力实现的底层我想应该就是通过zk来完成的。 在rocketmq中，NameSrv提供

### 21 设计生产架构之前的功课：消息中间件路由中心的架构原理是什么？

四个核心的部分：
+ 第一块就是他的NameServer，这个东西很重要，他要负责去管理集群里所有Broker的信息，让使用MQ的系统可以通过他感知到集群里有哪些Broker。

+ 第二块就是Broker集群本身了，必须得在多台机器上部署这么一个集群，而且还得用主从架构实现数据多副本存储和高可用。
+ 第三块就是向MQ发送消息的那些系统了，这些系统一般称之为生产者，这里也有很多细节是值得深究的，因为这些生产者到底是如何
    
    从NameServer拉取路由信息的？如何选择Broker机器建立连接以及发送消息的？

+ 第四块就是从MQ获取消息的那些系统，这些系统一般称之为消费者。

#### 关于RocketMQ NameServer设计原理

NameServer 如果要高可用 就要多部署几台,做成集群

每个Broker启动都得向所有的NameServer进行注册

### 系统如何从NameServer获取Broker信息？

每个系统自己每隔一段时间，定时发送请求到NameServer去拉取最新的集群Broker信息  自己主动去NameServer拉取Broker信息 的。

#### 如果Broker挂了，NameServer是怎么感知到的？
这个问题，靠的是Broker跟NameServer之间的心跳机制，Broker会每隔30s给所有的NameServer发送心跳，告诉每个NameServer自己目前还活着。

#### Broker挂了，系统是怎么感知到的？
刚开始集群里有10个Broker，各个系统从NameServer那里得知，都以为有10个Broker。

结果此时突然挂了一个Broker，120s没发心跳给NameServer，NameServer是知道现在只有9个Broker了。

但是此时其他系统是不知道只有9个Broker的，还以为有10个Broker，此时可能某个系统就会发送消息到那个已经挂掉的Broker上去，此时是绝对不可能成功发送消息的

而且过一会儿，系统又会重新从NameServer拉取最新的路由信息了，此时就会知道有一个Broker已经宕机了。

### 22 授人以渔：要是没有这个路由中心，消息中间件可以正常运作么？
假设这个NameServer集群整体都故障了，失去了这个NameServer集群之后：
+ RocketMQ还能正常运行吗？
+ 生产者还能发送消息到Broker吗？
+ 消费者还能从Broker拉取消息吗？

首先启动注册中心nameserver，每个nameserver之间互不通信，

启动broker时，会把自己的信息注册到每一个nameserver，broker每30s发送心跳包给注册中心，注册中心更新broker的最后更新时间。

nameserver会定时10秒检测更新时间是否超过120s，超过则将这个broker路由原信息剔除。

生产者和消费者定时去获取broker的路由信息，根据轮询生产消息和消费消息的负载。

当注册中心挂了，本地还会有缓存信息能够继续通信。

### 23 设计生产架构之前的功课：Broker的主从架构原理是什么？

#### Master Broker是如何将消息同步给Slave Broker的？

为了保证MQ的数据不丢失而且具备一定的高可用性，所以一般都是得将Broker部署成Master-Slave模式的，也就是一个Master Broker对应一个Slave Broker

然后Master需要在接收到消息之后，将数据同步给Slave，这样一旦Master Broker挂了，还有Slave上有一份数据。

说明：
+ Slave Broker也会向所有的NameServer进行注册
+ Slave Broker也会向所有的NameServer每30s发送心跳

RocketMQ的Master-Slave模式采取的是Slave Broker不停的发送请求到Master Broker去拉取消息。

所以首先要明白这一点，就是RocketMQ自身的Master-Slave模式采取的是Pull模式拉取消息

#### RocketMQ 实现读写分离了吗？

有可能从Master Broker获取消息，也有可能从Slave Broker获取消息

作为消费者的系统在获取消息的时候会先发送请求到Master Broker上去，请求获取一批消息，此时Master Broker是会返回一批消息给消费者系统的

然后Master Broker在返回消息给消费者系统的时候，会根据当时Master Broker的负载情况和Slave Broker的同步情况，向消费者系统建议下一次拉取消息的时候是从Master Broker拉取还是从Slave Broker拉取。

要是这个时候Master Broker负载很重，本身要抗10万写并发了，你还要从他这里拉取消息，给他加重负担，那肯定是不合适的。

所以此时Master Broker就会建议你从Slave Broker去拉取消息。

或者举另外一个例子，本身这个时候Master Broker上都已经写入了100万条数据了，结果Slave Broke不知道啥原因，同步的特别慢，才同步了96万条数据，落后了整整4万条消息的同步，这个时候你作为消费者系统可能都获取到96万条数据了，那么下次还是只能从Master Broker去拉取消息。

因为Slave Broker同步太慢了，导致你没法从他那里获取更新的消息了。

所以这一切都会由Master Broker根据情况来决定

#### 如果Slave Broke挂掉了有什么影响？
有一点影响，但是影响不太大

因为消息写入全部是发送到Master Broker的，然后消息获取也可以走Master Broker，只不过有一些消息获取可能是从Slave Broker去走的。

所以如果Slave Broker挂了，那么此时无论消息写入还是消息拉取，还是可以继续从Master Broke去走，对整体运行不影响。

只不过少了Slave Broker，会导致所有读写压力都集中在Master Broker上。

#### 如果Master Broker挂掉了该怎么办？

在RocketMQ 4.5版本之前，都是用Slave Broker同步数据，尽量保证数据不丢失，但是一旦Master故障了，Slave是没法自动切换成Master的。

所以在这种情况下，如果Master Broker宕机了，这时就得手动做一些运维操作，把Slave Broker重新修改一些配置，重启机器给调整为Master Broker，这是有点麻烦的，而且会导致中间一段时间不可用

所以这种Master-Slave模式不是彻底的高可用模式，他没法实现自动把Slave切换为Master

#### 基于Dledger实现RocketMQ高可用自动切换
在RocketMQ 4.5之后，这种情况得到了改变，因为RocketMQ支持了一种新的机制，叫做Dledger

简单来说，把Dledger融入RocketMQ之后，就可以让一个Master Broker对应多个Slave Broker，也就是说一份数据可以有多份副本，比如一个Master Broker对应两个Slave Broker。

然后依然会在Master和Slave之间进行数据同步

此时一旦Master Broker宕机了，就可以在多个副本，也就是多个Slave中，通过Dledger技术和Raft协议算法进行leader选举，直接将一个Slave Broker选举为新的Master Broker，然后这个新的Master Broker就可以对外提供服务了。

整个过程也许只要10秒或者几十秒的时间就可以完成，这样的话，就可以实现Master Broker挂掉之后，自动从多个Slave Broker中选举出来一个新的Master Broker，继续对外服务，一切都是自动的。

### 24 授人以渔：Broker主从同步有没有数据不一致问题？

问题：
+ 假设如果没有RocketMQ 4.5新版本引入的Dledger技术，仅仅是靠之前的Master-Slave主从同步机制，那么在Master崩溃的时
候，可能会造成多长时间的系统不可用？这个时候如何能够尽快的恢复集群运行？依赖手工运维的话，如何能尽快的去完成这个运
维操作？
+ 在RocketMQ 4.5之后引入了Dledger技术可以做到自动选举新的Master，那么在Master崩溃一直到新的Master被选举出来的这
个过程中，你觉得对于使用MQ的系统而言，会处于一个什么样的状态呢？

+ 希望大家去研究一下Kafka和RabbitMQ的多副本和高可用机制，Kafka是如何在集群里维护多个副本的？出现故障的时候能否实
现自动切换？RabbitMQ是如何在集群里维护多个数据副本的？出现故障的时候能否实现自动切换？

+ 既然有主从同步机制，那么有没有主从数据不一致的问题？Slave永远落后Master一些数据，这就是主从不一致。那么这种不一致
有没有什么问题？有办法保证主从数据强制一致吗？这样做又会有什么缺点呢？

可以和kafka一样做一个设置 保证只有消息至少被所有follwer同步成功后才算消息写入成功，这样即使leader挂了，从新选举出的follwer也会拥有全部的消息，只不过消息写入吞吐量会下降，这是肯定的 

所有的消息中间件主从要做的强一致性这里都要牺牲吞吐量，必须等待同步写到从节点，写入不成功就返回异常，具体场景具体考虑吧 

kafka这里可以配置多种模式，还可以直接发送后不等待写入成功就返回，还有一个是等待leader写入成功在返回，

Broker 采用主从架构存在延迟， 必然存在主从同步数据不一致的问题。 

1. producer 生产消息， 存放到 主Broker， 从Broker主动定时拉取消息。
 
2. consumer 拉取消息， 向 主Broker 拉取消息， 主Broker会记录消费相关信息， 然后从Broker再向主Broker同步。
  
3. 保证数据一致， 可以在producer写入消息， consumer 拉取消息后提交commitLog时改成同步， 多台机器成功之后才彻底成功。

###  25 落地第一步：设计一套高可用的消息中间件生产部署架构

#### NameServer集群化部署，保证高可用性
NameServer的设计是采用的Peer-to-Peer的模式来做的，也就是可以集群化部署，但是里面任何一台机器都是独立运行的，跟其他的机器没有任何通信。

每台NameServer实际上都会有完整的集群路由信息，包括所有的Broker节点信息，我们的数据信息，等等。所以只要任何一台NameServer存活下来，就可以保证MQ系统正常运行，不会出现故障。

#### 基于Dledger的Broker主从架构部署

采用RocketMQ 4.5以前的那种普通的Master-Slave架构来部署，能在一定程度上保证数据不丢失，也能保证一定的可用性。

但是那种方式的缺陷是很明显的，最大的问题就是当Master Broker挂了之后，没办法让Slave Broker自动切换为新的MasterBroker，需要手工做一些运维操作，修改配置以及重启机器才行，这个非常麻烦。

所以选择基于Dledger的主备自动切换的功能来进行生产架构的部署。

而且Dledger技术是要求至少得是一个Master带两个Slave，这样有三个Broke组成一个Group，也就是作为一个分组来运行。一旦Master宕机，他就可以从剩余的两个Slave中选举出来一个新的Master对外提供服务。

ps:每个Broker（不论是Master和Slave）都会把自己注册到所有的NameServer上去。


#### Broker是如何跟NameServer进行通信的？
Broker会每隔30秒发送心跳到所有的NameServer上去，然后每个NameServer都会每隔10s检查一次有没有哪个Broker超过120s没发送心跳的，
如果有，就认为那个Broker已经宕机了，从路由信息里要摘除这个Broker。

在RocketMQ的实现中，采用的是TCP长连接进行通信。

也就是说，Broker会跟每个NameServer都建立一个TCP长连接，然后定时通过TCP长连接发送心跳请求过去

#### 使用MQ的系统都要多机器集群部署

很多的系统使用RocketMQ，有些系统是作为生产者往MQ发送消息，有些系统是作为消费者从MQ获取消息，当然还有的系统是既作为生产者，又作为消费者，所以我们要考虑这些系统的部署。

对于这些系统的部署本身不应该在MQ的考虑范围内，但是我们还是应该给出一个建议，就是无论作为生产者还是消费者的系统，都应该多机器集群化部署，保证他自己本身作为生产者或者消费者的高可用性。

#### MQ的核心数据模型：Topic到底是什么？
Topic其实就是一个数据集合的意思，不同类型的数据你得放不同的Topic里去。

要是你有一些商品数据要发送消息到MQ里，你就应该创建一个Topic叫做“topic_product_info”，代表里面都是商品数据，那些想

要从MQ里获取商品数据的系统就可以从“topic_product_info”里获取了。

所以简单来说，你的系统如果要往MQ里写入消息或者获取消息，首先得创建一些Topic，作为数据集合存放不同类型的消息，比如说订单Topic，商品Topic，等等。

#### Topic作为一个数据集合是怎么在Broker集群里存储的？

首先我们来想一下，比如我们有一个订单Topic，可能订单系统每天都会往里面投递几百万条数据，然后这些数据在MQ集群上还得保留好多天，那么最终可能会有几千万的数据量，这还只是一个Topic。

那么如果有很多的Topic，并且里面都有大量的数据，最终加起来的总和也许是一个惊人的数字，此时这么大量的数据本身是不太可能存放在一台机器上的。


分布式存储。

我们可以在创建Topic的时候指定让他里面的数据分散存储在多台Broker机器上，比如一个Topic里有1000万条数据，此时有2台Broker，那么就可以让每台Broker上都放500万条数据。

这样就可以把一个Topic代表的数据集合分布式存储在多台机器上了

另外很重要的一件事是，每个Broke在进行定时的心跳汇报给NameServer的时候，都会告诉NameServer自己当前的数据情况，

比如有哪些Topic的哪些数据在自己这里，这些信息都是属于路由信息的一部分。

#### 生产者系统是如何将消息发送给Broker的？

+ 在发送消息之前，得先有一个Topic，然后在发送消息的时候你得指定你要发送到哪个Topic里面去。

+ 接着既然你知道你要发送的Topic，那么就可以跟NameServer建立一个TCP长连接，然后定时从他那里拉取到最新的路由信息，包括:

    集群里有哪些Broker，集群里有哪些Topic，每个Topic都存储在哪些Broker上

+ 然后生产者系统自然就可以通过路由信息找到自己要投递消息的Topic分布在哪几台Broker上，此时可以根据负载均衡算法，从里面选择一台Broke机器出来，比如round robine轮询算法，或者是hash算法，都可以。

+ 总之，选择一台Broker之后，就可以跟那个Broker也建立一个TCP长连接，然后通过长连接向Broker发送消息即可.Broker收到消息之后就会存储在自己本地磁盘里去

这里唯一要注意的一点，就是生产者一定是投递消息到Master Broker的，然后Master Broker会同步数据给他的Slave Brokers，实现
一份数据多份副本，保证Master故障的时候数据不丢失，而且可以自动把Slave切换为Master提供服务。


#### 消费者是如何从Broker上拉取消息的？

消费者系统其实跟生产者系统原理是类似的，他们也会跟NameServer建立长连接，然后拉取路由信息，接着找到自己要获取消息的Topic在哪几台Broker上，就可以跟Broker建立长连接，从里面拉取消息了。

#### 整体架构：高可用、高并发、海量消息、可伸缩

整个这套生产架构是实现完全高可用的，因为NameServer随便一台机器挂了都不怕，他是集群化部署的，每台机器都有完整的路由信息；

Broker随便挂了一台机器也不怕，挂了Slave对集群没太大影响，挂了Master也会基于Dledger技术实现自动Slave切换为Master；

生产者系统和消费者系统随便挂了一台都不怕，因为他们都是集群化部署的，其他机器会接管工作。

而且这个架构可以抗下高并发，因为假设订单系统对订单Topic要发起每秒10万QPS的写入，那么只要订单Topic分散在比如5台Broker上，实际上每个Broker会承载2万QPS写入，也就是说高并发场景下的10万QPS可以分散到多台Broker上抗下来。

然后集群足以存储海量消息，因为所有数据都是分布式存储的，每个Topic的数据都是存储在多台Broker机器上的，用集群里多台Master Broker就足以存储海量的消息。

所以，用多个Master Broker部署的方式，加上Topic分散在多台Broker上的机制，可以抗下高并发访问以及海量消息的分布式存储。

然后每个Master Broker有两个Slave Broker结合Dledger技术可以实现故障时的自动Slave-Master切换，实现高可用性。

最后，这套架构还具备伸缩性，就是说如果要抗更高的并发，存储跟多的数据，完全可以在集群里加入更多的Broker机器，这样就可以线性扩展集群了。

### 27 部署一个小规模的 RocketMQ 集群，为压测做好准备

<a  href="/src/main/resources/note/中间件/rocket配置.md"> Rocket 配置  </a>

### 28 授人以渔：动手完成一个小规模的RocketMQ集群的部署进行练习


### 29 生产运维：如何对RocketMQ集群进行可视化的监控和管理？

#### RocketMQ的大优势：可视化的管理界面
整个RocketMQ集群的元数据都集中在了NameServer里，包括有多少Broker，有哪些Topic，有哪些Producer，有哪些Consumer，目前集群里有多少消息，等等。

是RocketMQ里既然有大量的信息可以让我们进行监控和查看，他自然会提供一些办法来让我们看到，这就是他最大的优势之一，一个可视化的管理界面。

我们可以随便找一台机器，用NameServer的三台机器中的任意一台机器就可以，在里面执行如下命令拉取RocketMQ运维工作台的源码：
>git clone https://github.com/apache/rocketmq-externals.git

然后进入rocketmq-console的目录：
>cd rocketmq-externals/rocketmq-console

执行以下命令对rocketmq-cosole进行打包，把他做成一个jar包：
>mvn package -DskipTests

然后进入target目录下，可以看到一个jar包，接着执行下面的命令启动工作台：
>java -jar rocketmq-console-ng-1.0.1.jar --server.port=8080 --rocketmq.config.namesrvAddr=127.0.0.1:9876

这里务必要在启动的时候设置好NameServer的地址，如果有多个地址可以用分号隔开，接着就会看到工作台启动了，然后就通过浏览器访问那台机器的8080端口就可以了，就可以看到精美的工作台界面。

#### 如何通过工作台进行集群监控

你可以看到各个Broker的分组，哪些是Master，哪些是Slave，他们各自的机器地址和端口号，还有版本号

包括最重要的，就是他们每台机器的生产消息TPS和消费消息TPS，还有消息总数。

这是非常重要的，通过这个TPS统计，就是每秒写入或者被消费的消息数量，就可以看出RocketMQ集群的TPS和并发访问量。

#### 机器本身的监控应该如何做？
有了这个东西，我们是可以在压测的时候看到整个RocketMQ的TPS了，也就是Transaction PerSecond，就是每秒事务的意思，在这里就是每秒消息数量的意思。

但是我们要同时看到集群每台机器的CPU、IO、磁盘、内存、JVM GC的负载和情况怎么办呢？

其实这些东西都有很好的监控系统可以去看了，比如说Zabbix、Open-Falcon等等，一般公司都会用这些东西来监控机器的性能和资源使用率。

### 30 授人以渔：你们公司的MQ集群是如何进行监控和管理的？

假设

核心链路用的是rabbitmq，使用的监控是其自带的可视化控制面板rabbitmq_management， 运维的同事平时主要看概览，包括集群内节点状态（观察集群内broker状态），以及相关messag rates，消费监听者的连接进程(消费系统当前是否正常)，以及消息队列中的消息处理情况（比如失败的，是否存在消息堆积等， 总得来说，他们主要需求是监控Rabbit内部状态、确认RabbitMQ可用并且能够响应、观察队列状态检测消费者异常、检测消息通信结构中不合需求的配置更改等 如果我来负责 我除了上述的一些指标外，我还会关心，当前各个队列的准备完成的数据有多少，没有被ack的有多少，另外我会用到admin 管理，方便管理帐户信息及权限管理（非常方便），管理vhost(虚拟主机起到消息的逻辑区分)等， 此外我还需要部署Nagios：监控系统或服务状态异常时发出邮件或短信报警第一时间通知我，在状态恢复后发出正常的邮件或短信通知


