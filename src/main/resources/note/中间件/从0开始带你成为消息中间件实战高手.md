
> 从0开始带你成为消息中间件实战高手 的笔记



### 01 一个真实电商订单系统的整体架构、业务流程及负载情况

#### 一个订单系统的业务流程

<img src="https://s1.ax1x.com/2020/07/20/U4vBKH.jpg" alt="U4vBKH.jpg" border="0" />


####   一个订单系统的非核心流程
<img src="https://s1.ax1x.com/2020/07/20/U4xISO.jpg" alt="U4xISO.jpg" border="0" />

### 02 授人以渔：能概括一下你们系统的架构设计、业务流程以及负载情况吗？
> 首先你得知道现在你的系统，或者行业里其他普遍的一些系统，都有哪些技术难点和痛点，面临哪些问题。

>  接着要针对这些问题，反过来去学习一个技术，学习完这个技术之后，一定要思考如何将技术代入到真实的环境中，
  去解决对应的问题。
  
### 03 系统面临的现实问题：下订单的同时还要发券、发红包、Push推送，性能太差！

> 系统的压力来自哪

+ 电商这种系统,用户都会集中在晚上几个小时,为什么就不分析了, 他的访问曲线不是平均的,而是集中在一起的

<img src="https://s1.ax1x.com/2020/07/20/U5SORf.jpg" alt="U5SORf.jpg" border="0" />

+ 这种架构的压力都会落在单点上,上图就是mysql, 依据经验 4核8g mysql 最好1000-1500 能2000,16核32SSD 1万应该是极限,可能会出问题

+ 上面业务的问题, 在流程8中 ,支付回调中 ,推送,优惠券等,会有大量业务,太耗时


### 04 授人以渔：你们系统的核心流程性能如何？有没有哪个环节拖慢了速度？
> 普通项目还是业务处理和sql

> rpc 和第三方接口调用 ,同步的

要思考，在当前这样的系统压力下：

+ 系统的核心业务流程性能如何？
+ 核心流程的每个步骤要耗费多长时间？
+ 现在核心流程的性能你满意吗？是否还有优化的空间？
+ 在系统高峰期的时候，机器和数据库负载很高，是否对核心流程的性能有影响？
+ 如果有影响的话，会有多大的影响？

那你就想，你的这个系统做一个SaaS云平台的模式，提供给几万个公司，百万用户使用，不就可以了？你要自己去模拟这个场景。

然后，你按照文中的思路去推算出系统高峰期的负载，以及你的线上系统的机器的压力，到底要部署多少机器去满足这个压力。 


### 05 系统面临的现实问题：订单退款时经常流程失败，无法完成退款！
> 退款流程

<img src="https://s1.ax1x.com/2020/07/20/U5Fwxx.jpg" alt="U5Fwxx.jpg" border="0" />

+ 问题一: 和下单一样,流程过长  

+ 问题二: 如果退款失败怎么办

+ 下单之后不付款怎么办
> 下单之后会占用库存, 不付款 ,别人也买不了这个商品

给这种订单一个超时时间,超过 取消订单

+ 如果 下单之后不付款的单子 巨多,怎么处理
> 不停地去扫描表  效率太差,占用太多资源


### 06 授人以渔：你们系统出现过核心流程链路失败的情况吗？
> low 系统..

假设下 如果失败,可以保存失败操作,开始重试

### 07 系统面临的现实问题：第三方客户系统的对接耦合性太高，经常出问题！
> 还是上面的 订单支付 流程

+ 还是流程中有很多对接的第三方系统 ,比如支付,库仓 发货

<img src="https://s1.ax1x.com/2020/07/20/U5EDs0.jpg" alt="U5EDs0.jpg" border="0" />


+ 积分,发货,优惠券等系统都是和订单系统耦合在一起的

+ 这样订单系统和第三物流系统 也算耦合到一起, 会带来不确认性, 会基于网络,第三方系统大量原因导致 性能差

### 08 授人以渔：你们有没有跟第三方系统对接过，有遇到什么问题吗？
> 同步调第三方系统 真的一言难尽,  会各种坑, 随时保存日志,记得甩锅

### 09 系统面临的现实问题：大数据团队需要订单数据，该怎么办？

#### 大数据到底是干嘛的？
> 通过实时 采集来的数据,分析用户行为和其他结论 

每天如果有100万用户来访问你的APP，积累下来的一些浏览行为、访问行为、交易行为都是各种数据，这个数据量很大，所以你可以称之为“大数据”

大数据团队每天要负责的事情，说白了就是去尽可能的搜集每天100万用户在你的APP上的各种行为数据。

#### 大数据与我们系统的关系
> 订单数据等  他们需要分析每天几十万个订单，从中提取出老板最关心的APP交易数据报表！ 

方法

   +   select 查询
       
        大sql  而且查询次数不低,  数据库的cpu 和io 占用会很高, 其他操作就效率很低了
        

### 10 授人以渔：你们有没有遇到过自己系统的数据，其他团队需要获取的？
> 没有 

假设有, 比如微服务 过来取数据, 加缓存( 可以是缓存,也可以是新表), 异步同步  查询走缓存 

### 11 系统面临的现实问题：秒杀活动时数据库压力太大，该怎么缓解？

> 上面系统的缺点 是同步流程太长,效率太差

 假如在平时晚上的高峰使用期，最顶峰的时候大概是每秒2000左右的请求压力到订单系统上来。
 
 如果用户每秒会发起2000个请求到我们的订单系统的各类接口，包括下单接口、退款接口、查询接口等等，那么你觉得我们的订单系统每秒会执行多少条SQL在订单数据库上？
 
 一般你可以认为平均每个接口会执行2~3次的数据库操作。
 
 一般一个接口根据业务复杂度的不同，有的接口可能处理一个请求要执行五六次数据库操作，有的接口可能是1次数据库操作+两三个其他系统的接口调用（比如库存系统、营销系统）。

 总之，一般来说，业务系统的接口处理逻辑，基本都集中在对自己的数据库的操作以及对其他系统的调用上
 
 
#### 双11之类的大促活动有多恐怖

如果有200万用户参与双11活动，在双11购物最高峰的时候，假设会达到每秒至少1万的QPS。

也就是说，光是系统被请求的QPS就会达到1万以上，那么系统请求数据库的QPS就会达到2万以上。16核32G SSD 数据库性能，是无论如何扛不住每秒2万请求的。 

### 12 授人以渔：你们系统会不会遇到流量洪峰的场景，导致瞬时压力过大？
> 没有

假设有,异步处理, mq 削峰,  失败了就  开重试 ,最大重试次数还是失败  ,取消吧


### 13 阶段性复习：一张思维导图给你梳理高并发订单系统面临的技术痛点！

<img src="https://s1.ax1x.com/2020/07/21/UovGkR.jpg" alt="UovGkR.jpg" border="0" />

### 14 阶段性复习：放大100倍压力，也要找出你系统的技术挑战！

+ 第一，大家先思考一下系统的核心业务流程，当然不是指那种查询之类的操作。所谓核心链路指的是对你的系统进行的数据更新的操作，这才是核心链路，因为查询操作一般来说不涉及复杂的业务逻辑，主要是对数据的展示。
    
    对你的系统的核心链路分析一下，有哪些步骤，这些步骤各自的性能如何，综合起来让你的核心链路的性能如何？在这里是否有改进的空间？



+ 第二，大家可以思考一下，在你的系统中，是否有类似后台线程定时补偿的逻辑？

    比如订单长时间未支付就要自动关闭它，你们系统里有没有那种后台线程，会定时扫描你的数据，对异常数据进行补偿、自动修复等操作的？

    如果有的话，这种数据一般量有多大？如果没有，你可以思考一下，你们系统的核心数据是否需要类似的后台自动扫描机制？


+ 第三，大家可以思考一下，在你的系统里有没有跟第三方系统进行耦合？就是一些核心流程里需要同步调用第三方系统进行查询、更新等操作，第三方系统是否对你的核心链路有性能和稳定性上的影响？

+ 第四，大家可以思考一下，在你的核心链路中，是否存在那种关键步骤可能会失败的情况？万一失败了该怎么办？



+ 第五，大家可以思考一下，平时是否存在其他系统需要获取你们数据的情况？他们是如何获取你们数据的？

    是直接跑SQL从你们数据库里查询？或者是调用你们的接口来获取数据？是否存在这种情况？如果有，对你们有什么影响吗？



+ 第六，你们的系统是否存在流量洪峰的情况，有时候突然之间访问量增大好几倍，是否会对你们的系统产生无法承受的压力？

### 15 解决订单系统诸多问题的核心技术：消息中间件到底是什么？
#### 同步调用
用户发起一个请求，系统A收到请求，接着系统A必须立马去调用系统B，直到系统B返回了，系统A才能返回结果给用户，这种模式其实就是所谓的“同步调用”。

#### 消息中间件的异步

为系统A仅仅是发个消息到MQ，至于系统B什么时候获取消息，有没有获取消息，他是不管的。所以这种情况下，我们说系统A和系统B是异步调用。

#### 作用 

主要的作用有这么几个，包括异步化提升性能，降低系统耦合，流量削峰，等等

MQ进行流量削峰的效果，系统A发送过来的每秒1万请求是一个流量洪峰，然后MQ直接给扛下来了，都存储自己本地磁盘，这个过程就是流量削峰的过程，瞬间把一个洪峰给削下来了，让系统B后续慢慢获取消息来处理。

### 16 授人以渔：结合自己的系统问题思考一下，MQ有什么用处？

假设
1. 上传文件比如file是一个系统 具体业务一个系统 他们直接用mq ,file系统接收到文件存到文件服务器写一个消息给mq然后就返给用户结果 业务系统从mq接受消息进行业务处理 把处理结果写一个消息给mq , file系统接受消息更新文件处理结果， 当用户需要刷新文件上传结果的时候查询数据库就可以了
2. 在和硬件对接比如接受考勤信息也会用mq
3. 日志
4. 异步短信提示等

### 17 领导的要求：你来对 Kafka、RabbitMQ 以及 RocketMQ 进行技术选型调研

+ RabbitMQ  单机吞吐量 万级别, 基本不丢,功能全,web管理页面很方便, 集群模式麻烦 ,基于 erlang 开发

+ Kafka   10 万级，高吞吐 ,基本不丢 ,分布式, 功能不全, 但适合大数据和日志系统

+ RocketMQ 10 万级，支撑高吞吐, 基本不丢 ,分布式, 功能全, 可视化界面

### 18 授人以渔：你们公司主要使用的 MQ 是哪种？为什么要选用它？

 小项目和以前的 很多都是Rabbit ,熟悉,而且能支撑服务需求
 
 但现在Roket 好像用的不少

### 19 新技术引入：给团队分享 RocketMQ 的架构原理和使用方式
+ RocketMQ是如何集群化部署来承载高并发访问的？
+ 如果RocketMQ中要存储海量消息，如何实现分布式存储架构？

#### MQ如何集群化部署来支撑高并发访问？
发送消息到MQ的系统会把消息分散发送给多台不同的机器，假设一共有1万条消息，分散发送给10台机器，可能每台机器就是接收到1000条消息

每台机器上部署的RocketMQ进程一般称之为Broker，每个Broker都会收到不同的消息，然后就会把这批消息存储在自己本地的磁盘文件里

#### 高可用保障：万一Broker宕机了怎么办？
RocketMQ的解决思路是Broker主从架构以及多副本策略。

Master Broker收到消息之后会同步给Slave Broker，这样Slave Broker上就能有一模一样的一份副本数据！

这样同一条消息在RocketMQ整个集群里不就有两个副本了，一个在Master Broker里，一个在Slave Broker里！

这个时候如果任何一个Master Broker出现故障，还有一个Slave Broker上有一份数据副本，可以保证数据不丢失，还能继续对外提供服务，保证了MQ的可靠性和高可用性

#### 数据路由：怎么知道访问哪个Broker？

有一个NameServer的概念，他也是独立部署在几台机器上的 , 如果是集群, 注册的时候 会在每个NameServer 都注册


### 20 授人以渔：结合你对其他 MQ 的了解，思考 RocketMQ 的设计有何特点？

kafka集群架构分为leader和follower，每个topic下分为partition，partition分为primary和replication，partition主节点和副本节点存储在不同的节点上来保证集群的高可用，每个消息的partition可以分配到不同的节点来分布式存储，follower来同步leader节点的信息

kafka和Rocketmq都是分布式的消息系统，

在集群化部署方面，kafka通过zk进行节点协调，而rocketmq通过自身namesrv进行节点协调，所以在协调节点的设计上rocket显得更加轻。 

存储方面，在Kafka中，是1个topic（就是一个业务场景）有多个partition（对应3个物理文件目录），当需要存储数据的时候，会把topic中一个parition大文件分成多个小文件段。通过多个小文件段，就轻松实现定期清除或删除已经消费完文件。降低磁盘占用。

在rocketmq中，采用的是混合型的存储结构，即为Broker单个实例下所有的队列共用一个日志数据文件（即为CommitLog）来存储。

两者在对比上，Kafka采用的是独立型的存储结构，每个队列一个文件。RocketMQ采用混合型存储结构的缺点在于，会存在较多的随机读操作，因此读的效率偏低。同时消费消息需要依赖ConsumeQueue，构建该逻辑消费队列需要一定开销。 

主从备份方面：生产者向kafka写入消息时，一般会写入多个分区（partition），kafka提供冗余机制，即每个分区都有多个相同的备份(replica)，kafka把分区所有副本均匀分配到其他broker上，并从这些副本中挑选一个作为leader副本对外提供服务，其他副本称为follwer副本。当leader副本所在的broker有可能宕机，这时follower副本会竞争成为leader，继续提供服务。 

而当生产者者向rocketmq写入消息时，会将数据写入集群中的相关master broker上，而每个master broker都有1到多个slave broker, 这样在一定程度上保证master出现了不可恢复的故障时，不丢失数据。 同时如果master宕机了，消费者会自动重连到相应的salve上，不会出现消费停滞，那么同时在master和slave数据同步分为同步复制(有一定的效率损失)和异步复制(数据不一致) 

在生产和消费消息方面: 在kafka中，每条发布到Kafka集群的消息都有一个类别，这个类别被称为Topic，物理上不同Topic的消息分开存储，逻辑上一个Topic的消息虽然保存于一个或多个broker上但只需指定消息的Topic即可生产或消费数据而不必关心数据存于何处，而这种能力实现的底层我想应该就是通过zk来完成的。 在rocketmq中，NameSrv提供

### 21 设计生产架构之前的功课：消息中间件路由中心的架构原理是什么？

四个核心的部分：
+ 第一块就是他的NameServer，这个东西很重要，他要负责去管理集群里所有Broker的信息，让使用MQ的系统可以通过他感知到集群里有哪些Broker。

+ 第二块就是Broker集群本身了，必须得在多台机器上部署这么一个集群，而且还得用主从架构实现数据多副本存储和高可用。
+ 第三块就是向MQ发送消息的那些系统了，这些系统一般称之为生产者，这里也有很多细节是值得深究的，因为这些生产者到底是如何
    
    从NameServer拉取路由信息的？如何选择Broker机器建立连接以及发送消息的？

+ 第四块就是从MQ获取消息的那些系统，这些系统一般称之为消费者。

#### 关于RocketMQ NameServer设计原理

NameServer 如果要高可用 就要多部署几台,做成集群

每个Broker启动都得向所有的NameServer进行注册

### 系统如何从NameServer获取Broker信息？

每个系统自己每隔一段时间，定时发送请求到NameServer去拉取最新的集群Broker信息  自己主动去NameServer拉取Broker信息 的。

#### 如果Broker挂了，NameServer是怎么感知到的？
这个问题，靠的是Broker跟NameServer之间的心跳机制，Broker会每隔30s给所有的NameServer发送心跳，告诉每个NameServer自己目前还活着。

#### Broker挂了，系统是怎么感知到的？
刚开始集群里有10个Broker，各个系统从NameServer那里得知，都以为有10个Broker。

结果此时突然挂了一个Broker，120s没发心跳给NameServer，NameServer是知道现在只有9个Broker了。

但是此时其他系统是不知道只有9个Broker的，还以为有10个Broker，此时可能某个系统就会发送消息到那个已经挂掉的Broker上去，此时是绝对不可能成功发送消息的

而且过一会儿，系统又会重新从NameServer拉取最新的路由信息了，此时就会知道有一个Broker已经宕机了。

### 22 授人以渔：要是没有这个路由中心，消息中间件可以正常运作么？
假设这个NameServer集群整体都故障了，失去了这个NameServer集群之后：
+ RocketMQ还能正常运行吗？
+ 生产者还能发送消息到Broker吗？
+ 消费者还能从Broker拉取消息吗？

首先启动注册中心nameserver，每个nameserver之间互不通信，

启动broker时，会把自己的信息注册到每一个nameserver，broker每30s发送心跳包给注册中心，注册中心更新broker的最后更新时间。

nameserver会定时10秒检测更新时间是否超过120s，超过则将这个broker路由原信息剔除。

生产者和消费者定时去获取broker的路由信息，根据轮询生产消息和消费消息的负载。

当注册中心挂了，本地还会有缓存信息能够继续通信。

### 23 设计生产架构之前的功课：Broker的主从架构原理是什么？

#### Master Broker是如何将消息同步给Slave Broker的？

为了保证MQ的数据不丢失而且具备一定的高可用性，所以一般都是得将Broker部署成Master-Slave模式的，也就是一个Master Broker对应一个Slave Broker

然后Master需要在接收到消息之后，将数据同步给Slave，这样一旦Master Broker挂了，还有Slave上有一份数据。

说明：
+ Slave Broker也会向所有的NameServer进行注册
+ Slave Broker也会向所有的NameServer每30s发送心跳

RocketMQ的Master-Slave模式采取的是Slave Broker不停的发送请求到Master Broker去拉取消息。

所以首先要明白这一点，就是RocketMQ自身的Master-Slave模式采取的是Pull模式拉取消息

#### RocketMQ 实现读写分离了吗？

有可能从Master Broker获取消息，也有可能从Slave Broker获取消息

作为消费者的系统在获取消息的时候会先发送请求到Master Broker上去，请求获取一批消息，此时Master Broker是会返回一批消息给消费者系统的

然后Master Broker在返回消息给消费者系统的时候，会根据当时Master Broker的负载情况和Slave Broker的同步情况，向消费者系统建议下一次拉取消息的时候是从Master Broker拉取还是从Slave Broker拉取。

要是这个时候Master Broker负载很重，本身要抗10万写并发了，你还要从他这里拉取消息，给他加重负担，那肯定是不合适的。

所以此时Master Broker就会建议你从Slave Broker去拉取消息。

或者举另外一个例子，本身这个时候Master Broker上都已经写入了100万条数据了，结果Slave Broke不知道啥原因，同步的特别慢，才同步了96万条数据，落后了整整4万条消息的同步，这个时候你作为消费者系统可能都获取到96万条数据了，那么下次还是只能从Master Broker去拉取消息。

因为Slave Broker同步太慢了，导致你没法从他那里获取更新的消息了。

所以这一切都会由Master Broker根据情况来决定

#### 如果Slave Broke挂掉了有什么影响？
有一点影响，但是影响不太大

因为消息写入全部是发送到Master Broker的，然后消息获取也可以走Master Broker，只不过有一些消息获取可能是从Slave Broker去走的。

所以如果Slave Broker挂了，那么此时无论消息写入还是消息拉取，还是可以继续从Master Broke去走，对整体运行不影响。

只不过少了Slave Broker，会导致所有读写压力都集中在Master Broker上。

#### 如果Master Broker挂掉了该怎么办？

在RocketMQ 4.5版本之前，都是用Slave Broker同步数据，尽量保证数据不丢失，但是一旦Master故障了，Slave是没法自动切换成Master的。

所以在这种情况下，如果Master Broker宕机了，这时就得手动做一些运维操作，把Slave Broker重新修改一些配置，重启机器给调整为Master Broker，这是有点麻烦的，而且会导致中间一段时间不可用

所以这种Master-Slave模式不是彻底的高可用模式，他没法实现自动把Slave切换为Master

#### 基于Dledger实现RocketMQ高可用自动切换
在RocketMQ 4.5之后，这种情况得到了改变，因为RocketMQ支持了一种新的机制，叫做Dledger

简单来说，把Dledger融入RocketMQ之后，就可以让一个Master Broker对应多个Slave Broker，也就是说一份数据可以有多份副本，比如一个Master Broker对应两个Slave Broker。

然后依然会在Master和Slave之间进行数据同步

此时一旦Master Broker宕机了，就可以在多个副本，也就是多个Slave中，通过Dledger技术和Raft协议算法进行leader选举，直接将一个Slave Broker选举为新的Master Broker，然后这个新的Master Broker就可以对外提供服务了。

整个过程也许只要10秒或者几十秒的时间就可以完成，这样的话，就可以实现Master Broker挂掉之后，自动从多个Slave Broker中选举出来一个新的Master Broker，继续对外服务，一切都是自动的。

### 24 授人以渔：Broker主从同步有没有数据不一致问题？

问题：
+ 假设如果没有RocketMQ 4.5新版本引入的Dledger技术，仅仅是靠之前的Master-Slave主从同步机制，那么在Master崩溃的时
候，可能会造成多长时间的系统不可用？这个时候如何能够尽快的恢复集群运行？依赖手工运维的话，如何能尽快的去完成这个运
维操作？
+ 在RocketMQ 4.5之后引入了Dledger技术可以做到自动选举新的Master，那么在Master崩溃一直到新的Master被选举出来的这
个过程中，你觉得对于使用MQ的系统而言，会处于一个什么样的状态呢？

+ 希望大家去研究一下Kafka和RabbitMQ的多副本和高可用机制，Kafka是如何在集群里维护多个副本的？出现故障的时候能否实
现自动切换？RabbitMQ是如何在集群里维护多个数据副本的？出现故障的时候能否实现自动切换？

+ 既然有主从同步机制，那么有没有主从数据不一致的问题？Slave永远落后Master一些数据，这就是主从不一致。那么这种不一致
有没有什么问题？有办法保证主从数据强制一致吗？这样做又会有什么缺点呢？

可以和kafka一样做一个设置 保证只有消息至少被所有follwer同步成功后才算消息写入成功，这样即使leader挂了，从新选举出的follwer也会拥有全部的消息，只不过消息写入吞吐量会下降，这是肯定的 

所有的消息中间件主从要做的强一致性这里都要牺牲吞吐量，必须等待同步写到从节点，写入不成功就返回异常，具体场景具体考虑吧 

kafka这里可以配置多种模式，还可以直接发送后不等待写入成功就返回，还有一个是等待leader写入成功在返回，

Broker 采用主从架构存在延迟， 必然存在主从同步数据不一致的问题。 

1. producer 生产消息， 存放到 主Broker， 从Broker主动定时拉取消息。
 
2. consumer 拉取消息， 向 主Broker 拉取消息， 主Broker会记录消费相关信息， 然后从Broker再向主Broker同步。
  
3. 保证数据一致， 可以在producer写入消息， consumer 拉取消息后提交commitLog时改成同步， 多台机器成功之后才彻底成功。

###  25 落地第一步：设计一套高可用的消息中间件生产部署架构

#### NameServer集群化部署，保证高可用性
NameServer的设计是采用的Peer-to-Peer的模式来做的，也就是可以集群化部署，但是里面任何一台机器都是独立运行的，跟其他的机器没有任何通信。

每台NameServer实际上都会有完整的集群路由信息，包括所有的Broker节点信息，我们的数据信息，等等。所以只要任何一台NameServer存活下来，就可以保证MQ系统正常运行，不会出现故障。

#### 基于Dledger的Broker主从架构部署

采用RocketMQ 4.5以前的那种普通的Master-Slave架构来部署，能在一定程度上保证数据不丢失，也能保证一定的可用性。

但是那种方式的缺陷是很明显的，最大的问题就是当Master Broker挂了之后，没办法让Slave Broker自动切换为新的MasterBroker，需要手工做一些运维操作，修改配置以及重启机器才行，这个非常麻烦。

所以选择基于Dledger的主备自动切换的功能来进行生产架构的部署。

而且Dledger技术是要求至少得是一个Master带两个Slave，这样有三个Broke组成一个Group，也就是作为一个分组来运行。一旦Master宕机，他就可以从剩余的两个Slave中选举出来一个新的Master对外提供服务。

ps:每个Broker（不论是Master和Slave）都会把自己注册到所有的NameServer上去。


#### Broker是如何跟NameServer进行通信的？
Broker会每隔30秒发送心跳到所有的NameServer上去，然后每个NameServer都会每隔10s检查一次有没有哪个Broker超过120s没发送心跳的，
如果有，就认为那个Broker已经宕机了，从路由信息里要摘除这个Broker。

在RocketMQ的实现中，采用的是TCP长连接进行通信。

也就是说，Broker会跟每个NameServer都建立一个TCP长连接，然后定时通过TCP长连接发送心跳请求过去

#### 使用MQ的系统都要多机器集群部署

很多的系统使用RocketMQ，有些系统是作为生产者往MQ发送消息，有些系统是作为消费者从MQ获取消息，当然还有的系统是既作为生产者，又作为消费者，所以我们要考虑这些系统的部署。

对于这些系统的部署本身不应该在MQ的考虑范围内，但是我们还是应该给出一个建议，就是无论作为生产者还是消费者的系统，都应该多机器集群化部署，保证他自己本身作为生产者或者消费者的高可用性。

#### MQ的核心数据模型：Topic到底是什么？
Topic其实就是一个数据集合的意思，不同类型的数据你得放不同的Topic里去。

要是你有一些商品数据要发送消息到MQ里，你就应该创建一个Topic叫做“topic_product_info”，代表里面都是商品数据，那些想

要从MQ里获取商品数据的系统就可以从“topic_product_info”里获取了。

所以简单来说，你的系统如果要往MQ里写入消息或者获取消息，首先得创建一些Topic，作为数据集合存放不同类型的消息，比如说订单Topic，商品Topic，等等。

#### Topic作为一个数据集合是怎么在Broker集群里存储的？

首先我们来想一下，比如我们有一个订单Topic，可能订单系统每天都会往里面投递几百万条数据，然后这些数据在MQ集群上还得保留好多天，那么最终可能会有几千万的数据量，这还只是一个Topic。

那么如果有很多的Topic，并且里面都有大量的数据，最终加起来的总和也许是一个惊人的数字，此时这么大量的数据本身是不太可能存放在一台机器上的。


分布式存储。

我们可以在创建Topic的时候指定让他里面的数据分散存储在多台Broker机器上，比如一个Topic里有1000万条数据，此时有2台Broker，那么就可以让每台Broker上都放500万条数据。

这样就可以把一个Topic代表的数据集合分布式存储在多台机器上了

另外很重要的一件事是，每个Broke在进行定时的心跳汇报给NameServer的时候，都会告诉NameServer自己当前的数据情况，

比如有哪些Topic的哪些数据在自己这里，这些信息都是属于路由信息的一部分。

#### 生产者系统是如何将消息发送给Broker的？

+ 在发送消息之前，得先有一个Topic，然后在发送消息的时候你得指定你要发送到哪个Topic里面去。

+ 接着既然你知道你要发送的Topic，那么就可以跟NameServer建立一个TCP长连接，然后定时从他那里拉取到最新的路由信息，包括:

    集群里有哪些Broker，集群里有哪些Topic，每个Topic都存储在哪些Broker上

+ 然后生产者系统自然就可以通过路由信息找到自己要投递消息的Topic分布在哪几台Broker上，此时可以根据负载均衡算法，从里面选择一台Broke机器出来，比如round robine轮询算法，或者是hash算法，都可以。

+ 总之，选择一台Broker之后，就可以跟那个Broker也建立一个TCP长连接，然后通过长连接向Broker发送消息即可.Broker收到消息之后就会存储在自己本地磁盘里去

这里唯一要注意的一点，就是生产者一定是投递消息到Master Broker的，然后Master Broker会同步数据给他的Slave Brokers，实现
一份数据多份副本，保证Master故障的时候数据不丢失，而且可以自动把Slave切换为Master提供服务。


#### 消费者是如何从Broker上拉取消息的？

消费者系统其实跟生产者系统原理是类似的，他们也会跟NameServer建立长连接，然后拉取路由信息，接着找到自己要获取消息的Topic在哪几台Broker上，就可以跟Broker建立长连接，从里面拉取消息了。

#### 整体架构：高可用、高并发、海量消息、可伸缩

整个这套生产架构是实现完全高可用的，因为NameServer随便一台机器挂了都不怕，他是集群化部署的，每台机器都有完整的路由信息；

Broker随便挂了一台机器也不怕，挂了Slave对集群没太大影响，挂了Master也会基于Dledger技术实现自动Slave切换为Master；

生产者系统和消费者系统随便挂了一台都不怕，因为他们都是集群化部署的，其他机器会接管工作。

而且这个架构可以抗下高并发，因为假设订单系统对订单Topic要发起每秒10万QPS的写入，那么只要订单Topic分散在比如5台Broker上，实际上每个Broker会承载2万QPS写入，也就是说高并发场景下的10万QPS可以分散到多台Broker上抗下来。

然后集群足以存储海量消息，因为所有数据都是分布式存储的，每个Topic的数据都是存储在多台Broker机器上的，用集群里多台Master Broker就足以存储海量的消息。

所以，用多个Master Broker部署的方式，加上Topic分散在多台Broker上的机制，可以抗下高并发访问以及海量消息的分布式存储。

然后每个Master Broker有两个Slave Broker结合Dledger技术可以实现故障时的自动Slave-Master切换，实现高可用性。

最后，这套架构还具备伸缩性，就是说如果要抗更高的并发，存储跟多的数据，完全可以在集群里加入更多的Broker机器，这样就可以线性扩展集群了。

### 27 部署一个小规模的 RocketMQ 集群，为压测做好准备

<a  href="/src/main/resources/note/中间件/rocket配置.md"> Rocket 配置  </a>

### 28 授人以渔：动手完成一个小规模的RocketMQ集群的部署进行练习


### 29 生产运维：如何对RocketMQ集群进行可视化的监控和管理？

#### RocketMQ的大优势：可视化的管理界面
整个RocketMQ集群的元数据都集中在了NameServer里，包括有多少Broker，有哪些Topic，有哪些Producer，有哪些Consumer，目前集群里有多少消息，等等。

是RocketMQ里既然有大量的信息可以让我们进行监控和查看，他自然会提供一些办法来让我们看到，这就是他最大的优势之一，一个可视化的管理界面。

我们可以随便找一台机器，用NameServer的三台机器中的任意一台机器就可以，在里面执行如下命令拉取RocketMQ运维工作台的源码：
>git clone https://github.com/apache/rocketmq-externals.git

然后进入rocketmq-console的目录：
>cd rocketmq-externals/rocketmq-console

执行以下命令对rocketmq-cosole进行打包，把他做成一个jar包：
>mvn package -DskipTests

然后进入target目录下，可以看到一个jar包，接着执行下面的命令启动工作台：
>java -jar rocketmq-console-ng-1.0.1.jar --server.port=8080 --rocketmq.config.namesrvAddr=127.0.0.1:9876

这里务必要在启动的时候设置好NameServer的地址，如果有多个地址可以用分号隔开，接着就会看到工作台启动了，然后就通过浏览器访问那台机器的8080端口就可以了，就可以看到精美的工作台界面。

#### 如何通过工作台进行集群监控

你可以看到各个Broker的分组，哪些是Master，哪些是Slave，他们各自的机器地址和端口号，还有版本号

包括最重要的，就是他们每台机器的生产消息TPS和消费消息TPS，还有消息总数。

这是非常重要的，通过这个TPS统计，就是每秒写入或者被消费的消息数量，就可以看出RocketMQ集群的TPS和并发访问量。

#### 机器本身的监控应该如何做？
有了这个东西，我们是可以在压测的时候看到整个RocketMQ的TPS了，也就是Transaction PerSecond，就是每秒事务的意思，在这里就是每秒消息数量的意思。

但是我们要同时看到集群每台机器的CPU、IO、磁盘、内存、JVM GC的负载和情况怎么办呢？

其实这些东西都有很好的监控系统可以去看了，比如说Zabbix、Open-Falcon等等，一般公司都会用这些东西来监控机器的性能和资源使用率。

### 30 授人以渔：你们公司的MQ集群是如何进行监控和管理的？

假设

核心链路用的是rabbitmq，使用的监控是其自带的可视化控制面板rabbitmq_management， 运维的同事平时主要看概览，包括集群内节点状态（观察集群内broker状态），以及相关messag rates，消费监听者的连接进程(消费系统当前是否正常)，以及消息队列中的消息处理情况（比如失败的，是否存在消息堆积等， 总得来说，他们主要需求是监控Rabbit内部状态、确认RabbitMQ可用并且能够响应、观察队列状态检测消费者异常、检测消息通信结构中不合需求的配置更改等 如果我来负责 我除了上述的一些指标外，我还会关心，当前各个队列的准备完成的数据有多少，没有被ack的有多少，另外我会用到admin 管理，方便管理帐户信息及权限管理（非常方便），管理vhost(虚拟主机起到消息的逻辑区分)等， 此外我还需要部署Nagios：监控系统或服务状态异常时发出邮件或短信报警第一时间通知我，在状态恢复后发出正常的邮件或短信通知


### 31 RocketMQ生产集群准备：进行OS内核参数和JVM参数的调整

#### 对RocketMQ集群进行OS内核参数的调整
1. vm.overcommit_memory
    “vm.overcommit_memory”这个参数有三个值可以选择，0、1、2。
    
    如果值是0的话，在你的中间件系统申请内存的时候，os内核会检查可用内存是否足够，如果足够的话就分配内存给你，如果感觉剩余
    内存不是太够了，干脆就拒绝你的申请，导致你申请内存失败，进而导致中间件系统异常出错。
    
    因此一般需要将这个参数的值调整为1，意思是把所有可用的物理内存都允许分配给你，只要有内存就给你来用，这样可以避免申请内
    存失败的问题。
    
    比如我们曾经线上环境部署的Redis就因为这个参数是0，导致在save数据快照到磁盘文件的时候，需要申请大内存的时候被拒绝了，进
    而导致了异常报错。
    
    可以用如下命令修改：
    >echo 'vm.overcommit_memory=1' >> /etc/sysctl.conf。

2. vm.max_map_count
    这个参数的值会影响中间件系统可以开启的线程的数量，同样也是非常重要的
    
    如果这个参数过小，有的时候可能会导致有些中间件无法开启足够的线程，进而导致报错，甚至中间件系统挂掉。
    
    他的默认值是65536，但是这个值有时候是不够的，比如我们大数据团队的生产环境部署的Kafka集群曾经有一次就报出过这个异常，说无法开启足够多的线程，直接导致Kafka宕机了。
    
    因此建议可以把这个参数调大10倍，比如655360这样的值，保证中间件可以开启足够多的线程。
    
    可以用如下命令修改：
    >echo 'vm.max_map_count=655360' >> /etc/sysctl.conf。

3. vm.swappiness

    这个参数是用来控制进程的swap行为的，这个简单来说就是os会把一部分磁盘空间作为swap区域，然后如果有的进程现在可能不是太
    活跃，就会被操作系统把进程调整为睡眠状态，把进程中的数据放入磁盘上的swap区域，然后让这个进程把原来占用的内存空间腾出
    来，交给其他活跃运行的进程来使用。
    
    如果这个参数的值设置为0，意思就是尽量别把任何一个进程放到磁盘swap区域去，尽量大家都用物理内存。
    
    如果这个参数的值是100，那么意思就是尽量把一些进程给放到磁盘swap区域去，内存腾出来给活跃的进程使用。
    
    默认这个参数的值是60，有点偏高了，可能会导致我们的中间件运行不活跃的时候被迫腾出内存空间然后放磁盘swap区域去。
    
    因此通常在生产环境建议把这个参数调整小一些，比如设置为10，尽量用物理内存，别放磁盘swap区域去。
    
    可以用如下命令修改：
    >echo 'vm.swappiness=10' >> /etc/sysctl.conf。

4. ulimit

    这个是用来控制linux上的最大文件链接数的，默认值可能是1024，一般肯定是不够的，因为你在大量频繁的读写磁盘文件的时候，或
    者是进行网络通信的时候，都会跟这个参数有关系
    
    对于一个中间件系统而言肯定是不能使用默认值的，如果你采用默认值，很可能在线上会出现如下错误：error: too many open files。
    
    因此通常建议用如下命令修改这个值：
    > echo 'ulimit -n 1000000' >> /etc/profile。


+ 中间件系统肯定要开启大量的线程（跟vm.max_map_count有关）
+ 而且要进行大量的网络通信和磁盘IO（跟ulimit有关）
+ 然后大量的使用内存（跟vm.swappiness和vm.overcommit_memory有关）

#### 对JVM参数进行调整

<a  href="/src/main/resources/note/中间件/borkerjvm配置.md"> 对JVM参数进行调整  </a>

#### 对RocketMQ核心参数进行调整
dledger的示例配置文件：rocketmq/distribution/target/apacherocketmq/conf/dledger

在这里主要是有一个较为核心的参数：sendMessageThreadPoolNums=16

这个参数的意思就是RocketMQ内部用来发送消息的线程池的线程数量，默认是16

其实这个参数可以根据你的机器的CPU核数进行适当增加，比如机器CPU是24核的，可以增加这个线程数量到24或者30，都是可以的。


### 32 授人以渔：你们公司的MQ集群是如何配置生产参数的？
> 无 

Kafka，因为Kafka设计之初的原则就是尽量少的依赖JVM，比如他的两个比较重要的特性：磁盘顺序写和零拷贝，并且大量使用OS的cache，所以，在给JVM分配内存的时候，只要分配足够运行的内存就行了，剩下的大部分内存都要留出来给OS cache，用来提高Kafka的写和读的并发。其他针对网络通信（线程数量貌似也没有那么大的需求）以及磁盘IO（ulimit）的配置大体相同，主要是尽量开大Linux的阈值，而不至于因为这些参数限制了Kafka的吞吐和运行效率。补充一个相关的知识，因为用的是磁盘顺序写，所以Kafka的机器只要HDD就可以了，不需要机械硬盘SSD。


1、os的内核参数，在分配内存分配策略为1，内核允许分配所有的物理内存 2、可以开启的最大线程数为默认3、进程的内存交换 设置为默认，服务器只部署了mq，默认的没什么问题； 4、文件的最大连接数默认值为1024 jvm参数：jvm配置的一团糟，注册中心与broker是部署在一起，分配的jvm参数都是2g，年轻代为1，因为为4核8g内存，还需要留内存给os； 中间件的配置参数：压测环境过程中，运维把sendMessaageThreadPooNums 设置为256；

###  33 对小规模RocketMQ集群进行压测，同时为生产集群进行规划

> 压测:在RocketMQ的TPS和机器的资源使用率和负载之间取得一个平衡。

#### 一次RocketMQ小规模集群的压测

 <a  href="/src/main/resources/note/中间件/rocket压测.md"> 一次RocketMQ小规模集群的压测  </a>
 
### 34 授人以渔：你们公司的MQ集群做过压测吗？生产集群是如何规划的？

+ 他们对MQ集群做过压测吗？
+ 使用什么样的机器配置做的压测？
+ 使用多大规模的集群做的压测？如何压测的？
+ 在压测的过程中发现单Broker的TPS最高有多少？
+ 在压测过程中，cpu负载、内存使用率、jvm gc频率、磁盘io负载、网卡流量负载，这些值都是如何变化的？
+ 在压测过后，是如何规划生产集群的？
+ 目前公司线上MQ集群的TPS多高？机器资源的负载情况如何？能否抗住？ 

### 35 阶段性复习：一张思维导图给你梳理消息中间件集群生产部署架构规划

<img src="https://s1.ax1x.com/2020/07/22/UbszE4.jpg" alt="UbszE4.jpg" border="0" />

### 36 阶段性复习：按照你们公司的真实负载，设计消息中间件集群生产架构
+ 你们系统有没有使用MQ技术的业务场景？
+ 你们公司是如何进行技术选型的？
+ 你能对RocketMQ、Kafka、RabbitMQ三种技术的架构原理都进行一个思考和横向对比吗？
+ 如果RocketMQ没有路由中心了能正常运转吗？
+ 主从同步是否有数据一致性问题？
+ 你们公司的MQ集群是采用什么样的部署架构？
+ 你有没有动手完成一个小规模RocketMQ集群的部署？
+ 你们公司都是如何对MQ集群进行可视化监控的？
+ 你们公司的MQ集群是如何调整生产参数的？公司的MQ集群做过压测吗？你们公司的MQ集群生产环境是如何部署的？

rocketmq，主要进行异步，削峰，分布式事务一致性。

kafka吞吐量高，但功能简单不适合我们电商业务，适合日志采集不需要业务操作。

rocketmq公司有对源码进行二次开发封装客户端，增加发送失败的系统自动补偿机制。

没有了路由中心能运行一段时间，新的broker，生产者，消费者不能注册，还有缓存信息。

主从同步双写不会出现数据丢失。

我们公司broker采用多主零从同步刷盘，nameserver集群部署，生产者，消费者集群部署


### 37 基于MQ实现订单系统的核心流程异步化改造，性能优化完成！

#### 改造订单系统

1. 下单核心流程环节太多，性能较差
2. 订单退款的流程可能面临退款失败的风险
3. 关闭过期订单的时候，存在扫描大量订单数据的问题
4. 跟第三方物流系统耦合在一起，性能存在抖动的风险
5. 大数据团队要获取订单数据，存在不规范直接查询订单数据库的问题
6. 做秒杀活动时订单数据库压力过大

在用户支付完毕后，只要执行最核心的更新订单状态以及扣减库存就可以了，保证速度足够快。

然后诸如增加积分、发送优惠券、发送短信、通知发货的操作，都可以通过MQ实现异步化执行。

一旦你支付成功，实际上订单系统只需要更新订单状态（30ms）+扣减库存（80ms）+发送订单消息到
RocketMQ（10ms），一共120ms就可以了

#### 在订单系统中如何发送消息到RocketMQ？

<a href="https://github.com/apache/rocketmq/blob/master/docs/cn/RocketMQ_Example.md" >官网的demo 看生产者</a>

#### 其他系统改造为从RocketMQ中获取订单消息

<a href="https://github.com/apache/rocketmq/blob/master/docs/cn/RocketMQ_Example.md" >官网的demo 看消费者</a>

### 38 授人以渔：如果在你们系统的核心流程引入MQ，应该如何改造系统？
采用大量mq进行不同系统的交互，比如一个消息，多方都要订阅。自己做的一个项目，发货系统的改造，由第三方同步请求我们，把参数检验和更新数据库，通知其他部门发货信息全部解藕，提高了对外接口的响应，通过mq的重试消费加告警保证本地事务的执行成功。推送给第三方消息。

数据产品的系统，每次操作都需要记录审计信息。这类信息不是必须保证不丢失的，而且时效性要求没有那么高，所以，我们在切面拦截到，并把信息发送到MQ中，异步处理；还有一类是比较关键的数据（不允许丢，时效性要求不高），首先一次请求，可能会在多个分布式系统差生这类数据，而且我们需要在这些数据都保存到数据库后，再从数据库中另外一个表中查出来（前面生成的数据都有触发器）发送到搜索平台。上面这种就比较复杂，我们本来就使用了分布式事务，但是为了加快性能，把上传搜索平台的消息做成了异步，但是因为是一个分布式事务，可能会发生操作失败回滚，但是消息已经发出去了，没办法取消，从而产生脏数据的问题，针对上述问题，我们采用了分布式事务+RocketMQ的事务消息的机制解决的（实际上用的是阿里云的GTS+RocketMQ事务）

### 39 基于MQ实现订单系统的第三方系统异步对接改造，解耦架构完成！

上面那6个问题,如果用mq 事实上1,4 都解决了


<a href="https://github.com/apache/rocketmq/blob/master/docs/cn/RocketMQ_Example.md" >官网的demo </a>

#### 什么叫做同步发送消息到RocketMQ？
 > 普通的send 就是同步发送
 
#### 什么叫做异步发送消息到RocketMQ？
<a href="https://github.com/apache/rocketmq/blob/master/docs/cn/RocketMQ_Example.md#2%E5%8F%91%E9%80%81%E5%BC%82%E6%AD%A5%E6%B6%88%E6%81%AF" >官网的demo  异步发送</a>

主要代码片段
````
         // 启动Producer实例
          producer.start();
          producer.setRetryTimesWhenSendAsyncFailed(0);
          int messageCount = 100;
                  // 根据消息数量实例化倒计时计算器
          	final CountDownLatch2 countDownLatch = new CountDownLatch2(messageCount);
              	for (int i = 0; i < messageCount; i++) {
                          final int index = i;
                      	// 创建消息，并指定Topic，Tag和消息体
                          Message msg = new Message("TopicTest",
                              "TagA",
                              "OrderID188",
                              "Hello world".getBytes(RemotingHelper.DEFAULT_CHARSET));
                          // SendCallback接收异步返回结果的回调
                          producer.send(msg, new SendCallback() {
                              @Override
                              public void onSuccess(SendResult sendResult) {
                                   // 成功
                              }
                              @Override
                              public void onException(Throwable e) {
                	             // 异常
                              }
                      	});
              	}
```` 
 #### 什么叫做发送单向消息到RocketMQ？
 这种方式主要用在不特别关心发送结果的场景，例如日志发送。
 
  <a href="https://github.com/apache/rocketmq/blob/master/docs/cn/RocketMQ_Example.md#3%E5%8D%95%E5%90%91%E5%8F%91%E9%80%81%E6%B6%88%E6%81%AF" >官网的demo  单向消息</a>
  
#### 消费模式

rocket 两种消费模式

+ Push消费模式


<a href="https://github.com/apache/rocketmq/blob/master/docs/cn/RocketMQ_Example.md#2%E6%B6%88%E8%B4%B9%E8%80%85%E6%A0%B7%E4%BE%8B" >官网的demo  Push消费模式</a>

注册后,就是Broker会主动把消息发送给你的消费者，你的消费者是被动的接收Broker推送给过来的消息，然后进行处理
````
// 实例化消费者
  DefaultMQPushConsumer consumer = new DefaultMQPushConsumer("please_rename_unique_group_name");
  ````
 
 + 做Pull消费模式
 
 
<a href="https://github.com/apache/rocketmq/blob/master/docs/cn/RocketMQ_Example.md#82-omspullconsumer " >官网的demo 做Pull消费模式</a>

Broker不会主动推送消息给Consumer，而是消费者主动发送请求到Broker去拉取消息过来。


### 40 授人以渔：如果你们系统要对接第三方系统，应该如何设计？

mq对比:

kafka发送的三种模式：1.发送并忘记(单向) 2.同步发送 3.异步发送+回调函数，和rocket mq一样。 

kafa消费采用pull模式。 

rabbit mq confirm发送方确认模式：普通Confirm模式、批量确认模式、异步监听发送方确认模式。 

rabbit mq消费支持pull和push两种模式

kafka 消费是pull模式 客户端主动去服务端拉取消息 这样好处是可以更灵活的控制消费速度，要是服务端主动推送的话可能每个消费者消费速率不一样导致消费者消费不过来，kafka发送也有同步发送 异步发送带callback回调接口的，也可以发送后不关注结果配合acks=0 这样发送速率最大 但也是消息最不可靠的一种方式 大数据日志采集很适合 追求吞吐量

集群总结

1，zookeeper集群： 角色：leader,follower,observer 解读：只能写leader，可以从leader，follower和observer中读取数据，但observer没有投票权 
 
2，kafka集群： 角色：leader,follower 解读：只能读写leader，不可以从follower中读取数据，依靠zookeeper选举

3，rocketmq集群： 角色：master,slave 解读：只能写master，可以从master和slave中读取数据
   
4，redis集群： 角色：master,slave 解读：只能写master，可以从master和slave中读取数据

### 41 基于MQ实现订单数据同步给大数据团队，应该如何设计？

#### 大数据团队的几百行大SQL是如何影响订单数据库的？

实际上要解决这个问题，就必须要避免大数据团队直接查询订单数据库

比如最简单的办法，就是将订单数据落地到大数据团队自己的一个MySQL数据库中，然后从自己的MySQL数据库里统计报表。

还有MySQL Binlog同步系统

这种系统会监听MySQL数据库的Binlog，所谓Binlog大致可以理解为MySQL的增删改操作日志。

然后MySQL Binlog同步系统会将监听到的MySQL Binlog（也就是增删改操作日志）发送给你的系统，让你来处理这些增删改操作日志。

实际上大数据团队并没有必要仅仅只通过MySQL来出数据报表，完全可以采用Hadoop、Spark、Flink等大数据技术来出数据报表。

<img src="https://s1.ax1x.com/2020/07/22/UbTSOJ.jpg" alt="UbTSOJ.jpg" border="0" />

方案1: 刚开始的方案设计是通过job的方式拉去业务方的数据库来插入数据或更新es的数据存在时效性问题和业务数据多了厚性能问题，

方案2: 后来改造为canal监控binlog日志再通过canal adpater适配器写数据到rocketmq，消费者在消费消息进行业务插入后插入到es中

### 42 授人以渔：对其他团队要获取你们核心数据的问题，应该如何解决？

方案3:  mysql 主从, 主给业务系统用, 从给其他系统用

### 43 秒杀系统的技术难点以及秒杀商品详情页系统的架构设计

下问题清单：
1. 下单核心流程环节太多，性能较差
1. 订单退款的流程可能面临退款失败的风险
1. 关闭过期订单的时候，存在扫描大量订单数据的问题
1. 跟第三方系统耦合在一起，性能存在抖动的风险
1. 大数据团队要获取订单数据，存在不规范直接查询订单数据库的问题
1. 做秒杀活动时订单数据库压力过大

1,4,5 都解决了


#### 秒杀活动压力过大怎么办？难道是加机器吗？
+ 第一个问题，秒杀活动目前压力过大，应该如何解决？是不是简单的堆机器或者加机器就可以解决的？
    
    这个是没问题的，订单系统自己是可以通过部署更多的机器进行线性扩展的。
+ 第二个问题来了，那么数据库呢？是不是也要部署更多的服务器，进行分库分表，然后让更多的数据库服务器来抗超高的数据库高并发访问？
    
    这个思路是这样的，所谓分库分表，就是把目前的一台数据库服务器变成多台数据库服务器，然后把一张订单表变成多张订单表。
    
答案是不太靠谱的，除非是技术能力比较弱的公司，没有厉害的架构师去利用已有的技术合理设计优秀的架构，才会用这种堆机器的方
法简单的来抗下超高的并发。

因为如果用堆机器的方法来解决这个问题，必然存在一个问题，就是随着你的用户量越来越大，你的并发请求越来越多，会导致你要不
停的增加更多的机器

#### 不归订单管的部分：高并发的商品详情页请求
其实秒杀活动主要涉及到的并发压力就是两块，一个是高并发的读，一个是高并发的写。

在秒杀的时候,必然出现一种场景，就是首先大量用户会拿着APP不停的刷新一个秒杀商品的页面

本质上来说是从商品技术团队负责的商品详情页系统中加载出来的

在秒杀活动的时候，他面临的第一个问题就是，可能几十万人，甚至百万级的用户，会同一时间频繁的访问同一个秒杀商品的页面
比如“3折抢购原价6888的手机，限售100台”这样的活动，可能有几十万人在8:30之前会集中访问这个秒杀商品的活动页面，对商品
详情页系统造成过巨大的访问压力。

#### 商品团队的秒杀架构优化：页面数据静态化

实际上商品技术团队针对这个问题，采取的是页面数据静态化+多级缓存的方案。

以首先需要将这个秒杀活动的商品详情页里的数据做成静态化的，也就是说提前就从数据库里把这个页面需要的数据都提取出来组装
成一份静态数据放在别的地方，避免每次访问这个页面都要访问后端数据库。

#### 商品团队的秒杀架构优化：多级缓存

多级缓存的架构，我们会使用CDN + Nginx + Redis的多级缓存架构

可以将一些静态化好的数据放在就近的一个CDN上。

这个CDN缓存就是我们多级缓存架构里的第一级缓存。

那如果因为缓存过期之类的问题，CDN上没有用户要加载的商品详情页数据怎么办呢？

此时用户就会发送请求到我们公司的机房里的机器上去请求加载这个商品的数据了，这个时候我们需要在Nginx这样的服务器里做一级
缓存。

在Nginx中是可以基于Lua脚本实现本地缓存的，我们可以提前把秒杀商品详情页的数据放到Nginx中进行缓存，如果请求发送过来，
可以从Nginx中直接加载缓存数据，不需要把请求转发到我们商品系统上去

Nginx上的缓存数据过期之类的问题，导致没找到我们需要的数据?

此时就可以由Nginx中的Lua脚本发送请求到Redis集群中去加载我们提前放进去的秒杀商品数据

如果在Redis中还是没有找到呢？

那么就由Nginx中的Lua脚本直接把请求转发到商品详情页系统里去加载就可以了，此时就会直接从数据库中加载数据出来

### 44 授人以渔：你们有没有类似秒杀的业务场景？如果没有，自己想一个出来！

+ 秒杀的场景，应该采取差不多的方案，cdn+nginx缓存+redis缓存商详的静态页面化。后台可以通过redis扣减库存，mq更新数据操作。

+ 二级缓存架构， Redis缓存+Eache本地缓存，库存这些数据也是直接提前从数据预热到Redis缓存中，基于Redis做库存扣减，秒杀页面是动态，通过js使用ajax分模块加载不同的商品信息缓存，后台有商品基本数据介绍变更直接发送到MQ，然后秒杀服务监听MQ去缓存这些数据到Redis和本地缓存中。后期数量大了可以按照文章说的三级缓存架构+商品页面通过Nginx静态化生成

### 45 基于MQ实现秒杀订单系统的异步化架构以及精准扣减库存的技术方案

> 访问的问题 解决了,还有下单的问题

#### 用答题的方法避免作弊抢购以及延缓下单
考虑第一个问题，有没有可能会有人自己写一个抢购的脚本或者作弊软件，疯狂的发送请求去抢商品

答案是肯定的，肯定是有人会写作弊的脚本或者软件

所以一般来说，现在你要参与抢购，都会让你点击按钮之后先进行答题，就是说先弹出来一个框，让你回答一个问题，回答正确了你才
能发起抢购的请求

#### 为秒杀独立出来一套订单系统
用户的下单抢购的请求发送出去之后，会达到我们的后台系统，对于后台系统而言，我们需要思考一下，是否直接使用我们目前已
有的订单系统去抗所有的请求？

答案是否定的，这么做会有问题。

假设你有100万用户在这个时间段很活跃都会来购买商品，但是可能只有其中50万用户在参与秒杀活动，同一时间发送了大量的抢购请
求到后台系统，但是同时还有很多其他的用户这个时候并不在参与秒杀系统，他们在进行其他商品的常规性浏览和下单。

因此这个时候如果你让秒杀下单请求和普通下单请求都由一套订单系统来承载，那么可能会导致秒杀下单请求耗尽了订单系统的资源，
或者导致系统不稳定，然后导致其他普通下单请求也出现问题，没有办法完成的下单。

所以一般我们会对订单系统部署两个集群，一个集群是秒杀订单系统集群，一个集群是普通订单系统集群

#### 基于Redis实现下单时精准扣减库存

首先需要做的一个事情，就是扣减库存。

因为大家都知道，秒杀商品一般是有数量的限制的，比如几十万人可能就抢购1万个特价商品。

所以当大量的请求到达后台系统之后，首先第一步，就可以先去扣减库存。

扣减库存应该怎么来扣呢？如果还是直接由订单系统调用库存系统的接口，然后访问库存数据库去扣减，那么势必导致瞬时压力过大，可能让库存系统的压力很大。

因此在秒杀场景下，一般会采用另外一个思路。

通常在秒杀场景下，一般会将每个秒杀商品的库存提前写入Redis中，然后当请求到来之后，就直接对Redis中的库存进行扣减

Redis是可以轻松用单机抗每秒几万高并发的，因此这里就可以抗下高并发的库存扣减

#### 抢购完毕之后提前过滤无效请求
其实在Redis中的库存被扣减完之后，就说明后续其他的请求都没有必要发送到秒杀系统中了，因为商品已经被抢购完毕了

此时我们可以让Nginx在接收到后续请求的时候，直接就把后续请求过滤掉。

比如一旦商品抢购完毕，可以在ZooKeeper中写入一个秒杀完毕的标志位，然后ZK会反向通知Nginx中我们自己写的Lua脚本，通过

Lua脚本后续在请求过来的时候直接过滤掉，不要向后转发了。

#### 瞬时高并发下单请求进入RocketMQ进行削峰

哪怕是有1万件商品同时被1万人秒杀成功了，那么可能瞬间会有1万请求涌入正常的订单系统进行后续的处理，此时可能还是会有瞬间上万请求访问到订单数据库中创建订单。

所以这个时候，完全可以引入RocketMQ进行削峰处理

对于秒杀系统而言，如果判断发现通过Redis完成了库存扣减，此时库存还大于0，就说明秒杀成功了需要生成订单，此时就
直接发送一个消息到RocketMQ中即可。

然后让普通订单系统从RocketMQ中消费秒杀成功的消息进行常规性的流程处理即可，比如创建订单，等等。

这样的话，瞬间上万并发的压力会被RocketMQ轻松抗下来，然后普通的订单系统可以根据自己的工作负载慢慢的从RocketMQ中拉取

秒杀成功的消息，然后进行后续操作就可以了，不会对订单数据库造成过大的压力。

否则如果你让瞬间产生的一万或者几万的订单请求直接访问订单数据库，必然还是会让他压力过大，需要额外增加机器，那是没有必要
的。

因此在这里利用RocketMQ抗下每秒几万并发的下单请求，然后让订单系统以每秒几千的速率慢慢处理就可以了，也就是延迟个可能几
十秒，这些下单请求就会处理完毕。

#### 秒杀架构的核心要点
较重要的有以下几点：
1. 在前端/客户端设置秒杀答题，错开大量人下单的时间，阻止作弊器刷单
2. 独立出来一套秒杀系统，专门负责处理秒杀请求
3. 优先基于Redis进行高并发的库存扣减，一旦库存扣完则秒杀结束
4. 秒杀结束之后，Nginx层过滤掉无效的请求，大幅度削减转发到后端的流量
5. 瞬时生成的大量下单请求直接进入RocketMQ进行削峰，订单系统慢慢拉取消息完成下单操作

首先必须要避免直接基于数据库进行高并发的库存扣减

后续占据99%的请求，都可以直接在Nginx层面被拦截掉，不会转发到后台系统造成任何压力

用入RocketMQ中进行削峰，让RocketMQ轻松抗下高并发压力，让订单系统慢慢消费和处理下单操作

架构优化的核心就是独立出来一套系统专门处理，避免高并发请求落在MySQL上

因为MySQL天生不擅长抗高并发，我们需要通过Redis、Nginx、RocketMQ这些天生轻松可以单机抗几万甚至十万并发的系统来优化架构。


### 46 授人以渔：如果你们有类似秒杀的瞬时高并发场景，应该如何改造？
> mq 削峰, redis 先处理数据,异步同步到数据库

### 47 阶段性复习：一张思维导图给你梳理全面引入MQ的订单系统架构

<img src="https://s1.ax1x.com/2020/07/23/UbXRx0.jpg" alt="UbXRx0.jpg" border="0" />

### 48 阶段性复习：思考一下，如果你们系统全面接入MQ，架构该如何设计？

问题：

1. 你们的系统中是否存在核心链路环节过多导致性能较差的问题？如果有的话，是否可以引入MQ进行适当异步化提升链路性能？

1. 你们的系统是否存在核心链路耦合了第三方系统，进而导致链路性能不稳定的问题？如果有，是否可以引入MQ进行第三方系统的解耦，避免核心链路的性能受到影响？
 
1. 你们的系统是否存在有其他团队直接耦合访问你们数据库的情况，进而导致你们的数据库性能不稳定？如果有的话，是否可以引入MQ来推送你们的核心数据出去，跟其他团队进行解耦？
 
1. 你们的系统是否存在瞬时超高并发的场景？如果有的话，是否可以引入MQ来进行瞬时流量削峰，避免为了应对瞬时超高并发从而不停的增加机器？


### 49 精益求精：深入研究一下生产者到底如何发送消息的？
问题清单：
1. 下单核心流程环节太多，性能较差
1. 订单退款的流程可能面临退款失败的风险
1. 关闭过期订单的时候，存在扫描大量订单数据的问题
1. 跟第三方系统耦合在一起，性能存在抖动的风险
1. 大数据团队要获取订单数据，存在不规范直接查询订单数据库的问题
1. 做秒杀活动时订单数据库压力过大

1,4,5,6 解决

#### 研究RocketMQ底层原理的顺序和思路

思路:
1. 对生产者往Broker集群发送消息的底层原理做一个研究
2. 看看Broker对于接收到的消息，到底是如何存储到磁盘上去的？
3. 基于DLedger技术部署的Broker高可用集群，到底如何进行数据同步的？
4. 消费者到底是基于什么策略选择Master或Slave拉取数据的？
5. 消费者是如何从Broker拉取消息回来，进行处理以及ACK的？如果消费者故障了会如何处理？




