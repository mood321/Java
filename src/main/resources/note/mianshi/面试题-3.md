### 记面试题


<p>大概总结
<p> Java并发、mysql、网络、JDK集合、jvm、spring源码、tomcat、linux、系统设计、生产实践


<p>java 集合
<p> <a href="/src/main/resources/note/集合目录.md"> 这个可以看看之前写的集合</a>

<h3>1 HashMap   </h3>
<p><a href="/src/main/resources/note/conllection/HashMap源码分析.md">HashMap源码解析 </a>
<p> 数组+链表+红黑树
<p>在添加元素时，会根据hash值算出元素在数组中的位置，如果该位置没有元素，则直接把元素放置在此处，如果该位置有元素了，则把元素以链表的形式放置在链表的尾部。
<p>
<p>当一个链表的元素个数达到一定的数量（且数组的长度达到一定的长度）后，则把链表转化为红黑树，从而提高效率。
<p>
<p>数组的查询效率为O(1)，链表的查询效率是O(k)，红黑树的查询效率是O(log k)，k为桶中的元素个数，所以当元素数量非常多的时候，转化为红黑树能极大地提高效率。

<h4> hash 算法和寻址优化  (这个原来笔记没有)  </h4>
<pre>
  static final int hash(Object key) {
        int h;
        return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
}</pre>

<p>  比如说：有一个key的hash值
<pre>
     1111 1111 1111 1111 1111 1010 0111 1100
     0000 0000 0000 0000 1111 1111 1111 1111
     1111 1111 1111 1111 0000 0101 1000 0011 -> int值，32位
     </pre>
<p> 简而言之就是,高16 不变,低16变成 高16位于低16位异或结果
<h4>寻址算法优化    </h4>
<p>(n - 1) & hash -> 数组里的一个位置
<li> 用& 是因为 & 运算比取摸效率高,当然结果一样,这是个数学问题
<li> &也会导致一个问题 ,高16 的&运算 没有实际意义
<p>假设有两个hash值  ,低16一样,高16不一样, 这样&运算结果就会有问题
  <pre>
1111 1111 1111 1111 1111 1010 0111 1100 -> 1111 1111 1111 1111 0000 0101 1000 0011
1111 1111 1111 1110 1111 1010 0111 1100 -> 1111 1111 1111 1110 0000 0101 1000 0010</pre>
<p> 这时就是hash算法的优化,也就是上面是异或,  异或之后 ,低16位现在包含高低16两段的特征
<h4>总结   </h4>
<p>hash算法的优化：对每个hash值，在他的低16位中，让高低16位进行了异或，让他的低16位同时保持了高低16位的特征，尽量避免一些hash值后续出现冲突，大家可能会进入数组的同一个位置
<p>寻址算法的优化：用与运算替代取模，提升性能

<h4> HashMap是如何解决hash碰撞问题     </h4>
<p>两个key，多个key，他们算出来的hash的值，与n-1，与运算之后，发现定位出来的数组的位置还是一样的，hash碰撞，hash冲突
<p>get，如果定位到数组里发现这个位置挂了一个链表，此时遍历链表，从里面找到自己的要找的那个key-value对就可以了
<p>假设你的链表很长，可能会导致遍历链表，性能会比较差，O(n)
<p>优化，如果链表的长度达到了一定的长度之后，其实会把链表转换为红黑树，遍历一颗红黑树找一个元素，此时O(logn)，性能会比链表高一些
<p> 转红黑树条件:数组长度64,链表长度8 
<p>当单个桶中元素数量小于6时，进行反树化

<h4> HashMap是如何进行扩容的  </h4>
<p>（1）如果使用是默认构造方法，则第一次插入元素时初始化为默认值，容量为16，扩容门槛为12；
<p>（2）如果使用的是非默认构造方法，则第一次插入元素时初始化容量等于扩容门槛，扩容门槛在构造方法里等于传入容量向上最近的2的n次方；
<p>（3）如果旧容量大于0，则新容量等于旧容量的2倍，但不超过最大容量2的30次方，新扩容门槛为旧扩容门槛的2倍；
<p>（4）创建一个新容量的桶；
<p>（5）搬移元素，原链表分化成两个链表，低位链表存储在原来桶的位置，高位链表搬移到原来桶的位置加旧容量的位置；
<p>如果数组的长度扩容之后 = 32，重新对每个hash值进行寻址，也就是用每个hash值跟新数组的length - 1进行与操作
<pre>
n-1        0000 0000 0000 0000 0000 0000 0001 1111
hash1     1111 1111 1111 1111 0000 1111 0000 0101
&结果    0000 0000 0000 0000 0000 0000 0000 0101 = 5（index = 5的位置）
n-1        0000 0000 0000 0000 0000 0000 0001 1111
hash2     1111 1111 1111 1111 0000 1111 0001 0101
&结果    0000 0000 0000 0000 0000 0000 0001 0101 = 21（index = 21的位置）  </pre>
<p>判断二进制结果中是否多出一个bit的1，如果没多，那么就是原来的index，如果多了出来，那么就是index + oldCap，通过这个方式，就避免了rehash的时候，用每个hash对新数组.length取模，取模性能不高，位运算的性能比较高

<h3> 2  并发编程  </h3>
<p> synchronized实现原理、CAS无锁化的原理、AQS是什么、Lock锁、ConcurrentHashMap的分段加锁的原理、线程池的原理、java内存模型、volatile、对java并发包

<h4> synchronized关键字    </h4>
<p>synchronized关键字，在底层编译后的jvm指令中，会有monitorenter和monitorexit两个指令
<p>每个对象都有一个关联的monitor，比如一个对象实例就有一个monitor，一个类的Class对象也有一个monitor，如果要对这个对象加锁，那么必须获取这个对象关联的monitor的lock锁
<p>他里面的原理和思路大概是这样的，monitor里面有一个计数器，从0开始的。如果一个线程要获取monitor的锁，就看看他的计数器是不是0，如果是0的话，那么说明没人获取锁，他就可以获取锁了，然后对计数器加1

<p>如果一个线程第一次synchronized那里，获取到了myObject对象的monitor的锁，计数器加1，然后第二次synchronized那里，会再次获取myObject对象的monitor的锁，这个就是重入加锁了，然后计数器会再次加1，变成2
<p>这个时候，其他的线程在第一次synchronized那里，会发现说myObject对象的monitor锁的计数器是大于0的，意味着被别人加锁了，然后此时线程就会进入block阻塞状态，什么都干不了，就是等着获取锁
<p>接着如果出了synchronized修饰的代码片段的范围，就会有一个monitorexit的指令，在底层。此时获取锁的线程就会对那个对象的monitor的计数器减1，如果有多次重入加锁就会对应多次减1，直到最后，计数器是0
<p>然后后面block住阻塞的线程，会再次尝试获取锁，但是只有一个线程可以获取到锁

<h4> CAS的理解   </h4>
<p>有多个线程要同时读写类似上面的这种内存里的数据，此时必然出现多线程的并发安全问题
<p>CAS，compare and set
<p>CAS在底层的硬件级别给你保证一定是原子的，同一时间只有一个线程可以执行CAS，先比较再设置，其他的线程的CAS同时间去执行此时会失败

<h4> ConcurrentHashMap实现线程安全的底层原理
<p><a href="/src/main/resources/note/conllection/ConcurrentHashMap.md"> ConcurrentHashMap笔记</a>
<p>JDK并发包里推出了一个ConcurrentHashMap，他默认实现了线程安全性
<p>ps:对同一个元素执行put操作，此时是需要多线程是需要进行同步的
<p>[一个大的数组]，数组里每个元素进行put操作，都是有一个不同的锁，刚开始进行put的时候，如果两个线程都是在数组[5]这个位置进行put，这个时候，对数组[5]这个位置进行put的时候，采取的是CAS的策略
<p>同一个时间，只有一个线程能成功执行这个CAS，就是说他刚开始先获取一下数组[5]这个位置的值，null，然后执行CAS，线程1，比较一下，put进去我的这条数据，同时间，其他的线程执行CAS，都会失败
<p>分段加锁，通过对数组每个元素执行CAS的策略，如果是很多线程对数组里不同的元素执行put，大家是没有关系的，如果其他人失败了，其他人此时会发现说，数组[5]这位置，已经给刚才又人放进去值了
<p>就需要在这个位置基于链表+红黑树来进行处理，synchronized(数组[5])，加锁，基于链表或者是红黑树在这个位置插进去自己的数据
<p>如果你是对数组里同一个位置的元素进行操作，才会加锁串行化处理；如果是对数组不同位置的元素操作，此时大家可以并发执行的

<h6> 总结   </h6>
<p>（1）CAS + 自旋，乐观锁的思想，减少线程上下文切换的时间；
<p>（2）分段锁的思想，减少同一把锁争用带来的低效问题；
<p>（3）CounterCell，分段存储元素个数，减少多线程同时更新一个字段带来的低效；
<p>（4）@sun.misc.Contended（CounterCell上的注解），避免伪共享；（p.s.看笔记）
<p>（5）多线程协同进行扩容；
<h6> 不能解决的问题
<p>1  特定值put
<pre>
 public void unsafeUpdate(Integer key, Integer value) {
     Integer oldValue = map.get(key);
     if (oldValue == null) {
         map.put(key, value);
     }
 }</pre>
<p> putIfAbsent ,null才插入,
<p>另一个方法叫replace(K key, V oldValue, V newValue) 如果传入的ne程池中的最大线程数量。程池中的最大线程数量。程池中的最大线程数量。wValue是null，则会删除元素
<p> 2   不具备原子性  (多线程如果对同一个key操作 )
<p> 自己加锁,保证安全

<h4> JDK中的AQS理解     </h4>
<p> AQS，Abstract Queue Synchronizer，抽象队列同步器
<p>state变量 -> CAS -> 失败后进入队列等待 -> 释放锁后唤醒
<p>它维护了一个 volatile int state（代表共享资源）和一个 FIFO 线程等待队列（多线程争用资源被阻塞时会进入此队列）。这里 volatile 是核心关键词
<p> 等待线程进入等待队列
<p>ReentrantLock lock = new ReentrantLock();  => 非公平锁

<h4>线程池的底层工作原理   </h4>
<p>系统是不可能说让他无限制的创建很多很多的线程的，会构建一个线程池，有一定数量的线程，让他们执行各种各样的任务，线程执行完任务之后，不要销毁掉自己，继续去等待执行下一个任务
<li>提交任务，先看一下线程池里的线程数量是否小于corePoolSize，也就是3，如果小于，直接创建一个线程出来执行你的任务
<li>如果执行完你的任务之后，这个线程是不会死掉的，他会尝试从一个无界的LinkedBlockingQueue里获取新的任务，如果没有新的任务，此时就会阻塞住，等待新的任务到来
<li>你持续提交任务，上述流程反复执行，只要线程池的线程数量小于corePoolSize，都会直接创建新线程来执行这个任务，执行完了就尝试从无界队列里获取任务，直到线程池里有corePoolSize个线程
<li>接着再次提交任务，会发现线程数量已经跟corePoolSize一样大了，此时就直接把任务放入队列中就可以了，线程会争抢获取任务执行的，如果所有的线程此时都在执行任务，那么无界队列里的任务就可能会越来越多
<p>fixed，队列，LinkedBlockingQueue，无界阻塞队列

<h4> 线程池的核心配置参数   </h4>
<p>创建一个线程池就是这样子的，corePoolSize，maximumPoolSize，keepAliveTime，queue，这几个参数，如果你不用fixed之类的线程池，自己完全可以通过这个构造函数就创建自己的线程池
<li> corePoolSize：指定了线程池中的线程数量。
<li> maximumPoolSize：指定了线程池中的最大线程数量。
<li> keepAliveTime：当前线程池数量超过 corePoolSize 时，多余的空闲线程的存活时间，即多次时间内会被销毁。
<li> unit：keepAliveTime 的单位。
<li> workQueue：任务队列，被提交但尚未被执行的任务。
<li> threadFactory：线程工厂，用于创建线程，一般用默认的即可。
<li> handler：拒绝策略，当任务太多来不及处理，如何拒绝任务。
<p>拒绝策略如下：
<li>AbortPolicy ： 直接抛出异常，阻止系统正常运行。
<li>CallerRunsPolicy ： 只要线程池未关闭，该策略直接在调用者线程中，运行当前被丢弃的任务。显然这样做不会真的丢弃任务，但是，任务提交线程的性能极有可能会急剧下降。
<li> DiscardOldestPolicy ： 丢弃最老的一个请求，也就是即将被执行的一个任务，并尝试再次提交当前任务。
<li> DiscardPolicy ： 该策略默默地丢弃无法处理的任务，不予任何处理。如果允许任务丢失，这是最好的一种方案。
<li>  以上内置拒绝策略均实现了 RejectedExecutionHandler 接口，若以上策略仍无法满足实际需要，完全可以自己扩展 RejectedExecutionHandler 接口。   
      
<h4> 线程池中使用无界阻塞队列会发生什么问题   </h4>
<p>在远程服务异常的情况下，使用无界阻塞队列，是否会导致内存异常飙升？
<p>调用超时，队列变得越来越大，此时会导致内存飙升起来，而且还可能会导致你会OOM，内存溢出

<h4> 线上机器突然宕机，线程池的阻塞队列中的请求  ?    </h4>
<p>必然会导致线程池里的积压的任务实际上来说都是会丢失的
<p>如果说你要提交一个任务到线程池里去，在提交之前，麻烦你先在数据库里插入这个任务的信息，更新他的状态：未提交、已提交、已完成。提交成功之后，更新他的状态是已提交状态
<p>系统重启，后台线程去扫描数据库里的未提交和已提交状态的任务，可以把任务的信息读取出来，重新提交到线程池里去，继续进行执行

<h3> Java内存模型    </h3>
<p> 之前计算机组成原理写过一些( 说下volatile 在java中的实现)
<p>Java 提供给我们的 8 个原子操作：lock、unlock、read、load、use、assign、store、write
<p>一个变量从主内存拷贝到工作内存，再从工作内存同步回主内存的流程为：

>|主内存| -> read -> load -> |工作内存| -> user -> |Java线程| -> assign -> |工作内存| -> store -> write -> |主内存|

<p> 8 个原子操作
<li>lock：作用于主内存，把一个变量标识为一个线程独占状态。
<li>unlock：作用于主内存，释放一个处于锁定状态的变量。
<li>read：作用于主内存，把一个变量的值从主内存传输到线程工作内存中，供之后的 load 操作使用。
<li>load：作用于工作内存，把 read 操作从主内存中得到的变量值放入工作内存的变量副本中。
<li>use：作用于工作内存，把工作内存中的一个变量传递给执行引擎，虚拟机遇到使用变量值的字节码指令时会执行。
<li>assign：作用于工作内存，把一个从执行引擎得到的值赋给工作内存的变量，虚拟机遇到给变量赋值的字节码指令时会执行。
<li>store：作用于工作内存，把工作内存中的一个变量传送到主内存中，供之后的 write 操作使用。
<li>write：作用于主内存，把 store 操作从工作内存中得到的变量值存入主内存的变量中。
<p>主内存对应 系统内存空间,工作内存对应CPU高速缓存内存
<li>use 操作必须与 load、read 操作同时出现，不能只 use，不 load、read。
<ul>use <- load <- read     </ul>     

<p> 使用时必须去取主内存

<li>assign 操作必须与 store、write 操作同时出现，不能只 assign，不 store、write。
<ul>assign -> store -> write

<p> 更新必须写主内存


<h4> Java内存模型中的原子性、有序性、可见性</h4>
<p> Java内存模型 -> 原子性、可见性、有序性 -> volatile -> happens-before / 内存屏障
<p> 可见性
<p> 如果有一个线程修改了,会让其他线程工作空间的值失效,重新读主内存的值
<p> 原子性
<p>data++，必须是独立执行的，没有人影响我的，一定是我自己执行成功之后，别人才能来进行下一次data++的执行
<p>有序性
<p> 对于代码，同时还有一个问题是指令重排序，编译器和指令器，有的时候为了提高代码执行效率，会将指令重排序，就是说比如下面的代码
<p> 具备有序性，不会发生指令重排导致我们的代码异常；不具备有序性，可能会发生一些指令重排，导致代码可能会出现一些问题

<h4>volatile关键字的原理</h4>
<p>volatile关键字是用来解决可见性和有序性，在有些罕见的条件之下，可以有限的保证原子性，他主要不是用来保证原子性的


<h4> 指令重排以及happens-before原则</h4>
<p> volatile关键字和有序性的关系，volatlie是如何保证有序性的，如何避免发生指令重排的
<p>根据语义，Happens-Before，就是即便是对于不同的线程，前面的操作也应该发生在后面操作的前面，也就是说，<strong>Happens-Before 规则保证：前面的操作的结果对后面的操作一定是可见的</strong>。</p>
<p><strong>Happens-Before 规则本质上是一种顺序约束规范，用来约束编译器的优化行为</strong>。就是说，为了执行效率，我们允许编译器的优化行为，但是为了保证程序运行的正确性，我们要求编译器优化后需要满足 Happens-Before 规则。</p>
<p>根据类别，我们将 Happens-Before 规则分为了以下 4 类：</p>
<ul>
<li>操作的顺序：
<ul>
<li><strong>程序顺序规则：</strong> 如果代码中操作 A 在操作 B 之前，那么同一个线程中 A 操作一定在 B 操作前执行，即在本线程内观察，所有操作都是有序的。</li>
<li><strong>传递性：</strong> 在同一个线程中，如果 A 先于 B ，B 先于 C 那么 A 必然先于 C。</li>
</ul>
</li>
<li>锁和 volatile：
<ul>
<li><strong>监视器锁规则：</strong> 监视器锁的解锁操作必须在同一个监视器锁的加锁操作前执行。</li>
<li><strong>volatile 变量规则：</strong> 对 volatile 变量的写操作必须在对该变量的读操作前执行，保证时刻读取到这个变量的最新值。</li>
</ul>
</li>
<li>线程和中断：
<ul>
<li><strong>线程启动规则：</strong> <code>Thread#start()</code> 方法一定先于该线程中执行的操作。</li>
<li><strong>线程结束规则：</strong> 线程的所有操作先于线程的终结。</li>
<li><strong>中断规则：</strong> 假设有线程 A，其他线程 interrupt A 的操作先于检测 A 线程是否中断的操作，即对一个线程的 <code>interrupt()</code> 操作和 <code>interrupted()</code> 等检测中断的操作同时发生，那么 <code>interrupt()</code> 先执行。</li>
</ul>
</li>
<li>对象生命周期相关：
<ul>
<li><strong>终结器规则：</strong> 对象的构造函数执行先于 <code>finalize()</code> 方法。</li>
</ul>
</li>
</ul>
<p>规则制定了在一些特殊情况下，不允许编译器、指令器对你写的代码进行指令重排，必须保证你的代码的有序性
<p>指令重排 -> happens-before -> volatile起到避免指令重排

<h4> volatile底层是如何基于内存屏障保证可见性和有序性的？</h4>
<p> 内存模型 -> 原子性、可见性、有序性 - > volatile+可见性 -> volatile+有序性（指令重排 + happens-before） -> voaltile+原子性 -> volatile底层的原理（内存屏障级别的原理）

<h5>lock指令：volatile保证可见性</h5>
<p>对volatile修饰的变量，执行写操作的话，JVM会发送一条lock前缀指令给CPU，CPU在计算完之后会立即将这个值写回主内存，同时因为有MESI缓存一致性协议，所以各个CPU都会对总线进行嗅探，自己本地缓存中的数据是否被别人修改
<p>如果发现别人修改了某个缓存的数据，那么CPU就会将自己本地缓存的数据过期掉，然后这个CPU上执行的线程在读取那个变量的时候，就会从主内存重新加载最新的数据了
<p>lock前缀指令 + MESI缓存一致性协议

<h5> volatile 的有序实现</h5>
<p>对于volatile修改变量的读写操作，都会加入内存屏障
<p>每个volatile写操作前面，加StoreStore屏障，禁止上面的普通写和他重排；每个volatile写操作后面，加StoreLoad屏障，禁止跟下面的volatile读/写重排
<p>每个volatile读操作后面，加LoadLoad屏障，禁止下面的普通读和voaltile读重排；每个volatile读操作后面，加LoadStore屏障，禁止下面的普通写和volatile读重排

<p>synchronized、volatile，底层都对应着一套复杂的cpu级别的硬件原理，大量的内存屏障的原理；lock API，concurrenthashmap，都是各种复杂的jdk级别的源码，技术深度是很深入的


<h3> Spring</h3>

<h4>Spring的 IOC 机制</h4>
<p>Spring IOC框架，控制反转，依赖注入
<p>tomcat在启动的时候，直接会启动spring容器
<p>spring ioc，spring容器，根据xml配置，或者是你的注解，去实例化你的一些bean对象，然后根据xml配置或者注解，去对bean对象之间的引用关系，去进行依赖注入，某个bean依赖了另外一个bean
<p>底层的核心技术，反射，他会通过反射的技术，直接根据你的类去自己构建对应的对象出来，用的就是反射技术
<p>spring ioc，系统的类与类之间彻底的解耦合

<h4> pring的AOP机制的理解</h4>
<p> spring核心框架里面，最关键的两个机制，就是ioc和aop，根据xml配置或者注解，去实例化我们所有的bean，管理bean之间的依赖注入，让类与类之间解耦，维护代码的时候可以更加的轻松便利
<p>他有几个概念，可以做一个切面，语法、用法、术语和概念
<p>做一个切面，如何定义呢？MyServiceXXXX的这种类，在这些类的所有方法中，都去织入一些代码，在所有这些方法刚开始运行的时候，都先去开启一个事务，在所有这些方法运行完毕之后，去根据是否抛出异常来判断一下，如果抛出异常，就回滚事务，如果没有异常，就提交事务 => AOP

<p>spring在运行的时候，动态代理技术，AOP的核心技术，就是动态代理
<p>他会给你的那些类生成动态代理,把你本身的类注入到代理类
<p>事务，mysql，数据库里都提供一个事务机制，我们如果开启一个事务，在这个事务里执行多条增删改的sql语句，这个过程中，如果任何一个sql语句失败了，会导致这个事务的回滚，把其他sql做的数据更改都恢复回去
<p>在一个事务里的所有sql，要么一起成功，要么一起失败，事务功能可以保证我们的数据的一致性，在业务逻辑组件里去加入这个事务

<h4>cglib动态代理？他跟jdk动态代理的区别</h4>
<p> 其实就是动态的创建一个代理类出来，创建这个代理类的实例对象，在这个里面引用你真正自己写的类，所有的方法的调用，都是先走代理类的对象，他负责做一些代码上的增强，再去调用你写的那个类
<p> spring里使用aop，比如说你对一批类和他们的方法做了一个切面，定义好了要在这些类的方法里增强的代码，spring必然要对那些类生成动态代理，在动态代理中去执行你定义的一些增强代码
<p> 如果你的类是实现了某个接口的，spring aop会使用jdk动态代理，生成一个跟你实现同样接口的一个代理类，构造一个实例对象出来，jdk动态代理，他其实是在你的类有接口的时候，就会来使用
<p> 很多时候我们可能某个类是没有实现接口的，spring aop会改用cglib来生成动态代理，他是生成你的类的一个子类，他可以动态生成字节码，覆盖你的一些方法，在方法里加入增强的代码

<p> AspectJ和spring aop
<p> AspectJ是一个代码生成工具
<p> AspectJ有自己的类装载器，支持在类装载时织入切面，即所谓的LTW机制
<p> AspectJ同样也支持运行时织入，运行时织入是基于动态代理的机制。（默认机制）
<p>spring aop是aop实现方案的一种，它支持在运行期基于动态代理的方式将aspect织入目标代码中来实现aop。
<p>但是spring aop的切入点支持有限，而且对于static方法和final方  法都无法支持aop（因为此类方法无法生成代理类）；另外spring aop只支持对于ioc容器管理的bean，其他的普通java类无法支持aop。同时spring整合了aspectj，使得在spring  体系中可以使用aspectj语法来实现aop

<h4>Spring中的Bean是线程安全的吗？</h4>
<p>Spring容器中的bean可以分为5个范围：

<li>（1）singleton：默认，每个容器中只有一个bean的实例
<li>（2）prototype：为每一个bean请求提供一个实例
<p>一般来说下面几种作用域，在开发的时候一般都不会用，99.99%的时候都是用singleton单例作用域
<p>（3）request：为每一个网络请求创建一个实例，在请求完成以后，bean会失效并被垃圾回收器回收
<p>（4）session：与request范围类似，确保每个session中有一个bean的实例，在session过期后，bean会随之失效
<p>（5）global-session
<p>答案是否定的，绝对不可能是线程安全的，spring bean默认来说，singleton，都是线程不安全的，java web系统，一般来说很少在spring bean里放一些实例变量，一般来说他们都是多个组件互相调用，最终去访问数据库的
<p> 如果bean 有变量,多个请求是会不安全的


<h4>Spring的事务实现原理是什么？能聊聊你对事务传播机制的理解吗？</h4>
<p>事务的实现原理，事务传播机制，如果说你加了一个@Transactional注解，此时就spring会使用AOP思想，对你的这个方法在执行之前，先去开启事务，执行完毕之后，根据你方法是否报错，来决定回滚还是提交事务


<li>① PROPAGATION_REQUIRED：如果当前没有事务，就创建一个新事务，如果当前存在事务，就加入该事务，该设置是最常用的设置。
<li>② PROPAGATION_SUPPORTS：支持当前事务，如果当前存在事务，就加入该事务，如果当前不存在事务，就以非事务执行。‘
<li>③ PROPAGATION_MANDATORY：支持当前事务，如果当前存在事务，就加入该事务，如果当前不存在事务，就抛出异常。
<li>④ PROPAGATION_REQUIRES_NEW：创建新事务，无论当前存不存在事务，都创建新事务。
<li>⑤ PROPAGATION_NOT_SUPPORTED：以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。
<li>⑥ PROPAGATION_NEVER：以非事务方式执行，如果当前存在事务，则抛出异常。
<li>⑦ PROPAGATION_NESTED：如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则按REQUIRED属性执行。
<p>出去面试，事务传播机制
<p>嵌套事务，外层的事务如果回滚，会导致内层的事务也回滚；但是内层的事务如果回滚，仅仅是回滚自己的代码

<h4> Spring Boot的核心架构 </h4>
<p>spring框架，mybatis，spring mvc，去做一些开发，打包部署到线上的tomcat里去，tomcat启动了，他就会接收http请求，转发给spring mvc框架，调用controller -> service -> dao -> mybatis（sql语句）
<p>java web开发的时候，在这里整合进来redis、elasticsearch、还有很多其他的一些东西，rabbitmq、zookeeper，等等，诸如此类的一些东西
<p>国外的spring开源社区，就发起了一个项目，spring boot，我们基于spring boot直接进行开发，里面还是使用spring + spring mvc + mybatis一些框架，我们可以一定程度上来简化我们之前的开发流程
<img src="/src/main/resources/img-demo/advanced/springboot.jpg">

<h4>能画一张图说说Spring的核心架构吗？</h4>

<p>spring bean生命周期，从创建 -> 使用 -> 销毁

<p>你在系统里用xml或者注解，定义一大堆的bean

<li>（1）实例化Bean：如果要使用一个bean的话
<li>（2）设置对象属性（依赖注入）：他需要去看看，你的这个bean依赖了谁，把你依赖的bean也创建出来，给你进行一个注入，比如说通过构造函数，setter
<li>（3）处理Aware接口：如果这个Bean已经实现了ApplicationContextAware接口，spring容器就会调用我们的bean的setApplicationContext(ApplicationContext)方法，传入Spring上下文，把spring容器给传递给这个bean
<li>（4）BeanPostProcessor：如果我们想在bean实例构建好了之后，此时在这个时间带你，我们想要对Bean进行一些自定义的处理，那么可以让Bean实现了BeanPostProcessor接口，那将会调用postProcessBeforeInitialization(Object obj, String s)方法。
<li>（5）InitializingBean 与 init-method：如果Bean在Spring配置文件中配置了 init-method 属性，则会自动调用其配置的初始化方法。
<li>（6）如果这个Bean实现了BeanPostProcessor接口，将会调用postProcessAfterInitialization(Object obj, String s)方法
<li>（7）DisposableBean：当Bean不再需要时，会经过清理阶段，如果Bean实现了DisposableBean这个接口，会调用其实现的destroy()方法；
<li>（8）destroy-method：
<p>最后，如果这个Bean的Spring配置中配置了destroy-method属性，会自动调用其配置的销毁方法。


<h4>Spring中都使用了哪些设计模式</h4>
<p>工厂模式，单例模式，代理模式
<p>工厂模式，spring ioc核心的设计模式的思想提现，他自己就是一个大的工厂，把所有的bean实例都给放在了spring容器里（大工厂），如果你要使用bean，就找spring容器就可以了，你自己不用创建对象了
<p>如果说你要对一些类的方法切入一些增强的代码，会创建一些动态代理的对象，让你对那些目标对象的访问，先经过动态代理对象，动态代理对象先做一些增强的代码，调用你的目标对象
<p>spring默认来说，对每个bean走的都是一个单例模式，确保说你的一个类在系统运行期间只有一个实例对象，只有一个bean，用到了一个单例模式的思想，保证了每个bean都是单例的
<p>在设计模式里，就是一个代理模式的体现和运用，让动态代理的对象，去代理了你的目标对象，在这个过程中做一些增强的访问，你可以把面试突击的内容作为一个抛砖引玉的作用，去更加深入的学习一些技术
<p>模版模式，在各种BeanFactory以及ApplicationContext实现中也都用到了
<p>策略模式，加载资源文件的方式，使用了不同的方法，比如：ClassPathResourece，FileSystemResource，ServletContextResource，UrlResource但他们都有共同的借口Resource；在Aop的实现中，采用了两种不同的方式，JDK动态代理和CGLIB代理

<h4> Spring Web MVC的核心架构</h4>
<li>（1）tomcat的工作线程将请求转交给spring mvc框架的DispatcherServlet
<li>（2）DispatcherServlet查找@Controller注解的controller，我们一般会给controller加上你@RequestMapping的注解，标注说哪些controller用来处理哪些请求，此时根据请求的uri，去定位到哪个controller来进行处理
<li>（3）根据@RequestMapping去查找，使用这个controller内的哪个方法来进行请求的处理，对每个方法一般也会加@RequestMapping的注解
<li>（4）他会直接调用我们的controller里面的某个方法来进行请求的处理
<li>（5）我们的controller的方法会有一个返回值，以前的时候，一般来说还是走jsp、模板技术，我们会把前端页面放在后端的工程里面，返回一个页面模板的名字，spring mvc的框架使用模板技术，对html页面做一个渲染；返回一个json串，前后端分离，可能前端发送一个请求过来，我们只要返回json数据
<li>（6）再把渲染以后的html页面返回给浏览器去进行显示；前端负责把html页面渲染给浏览器就可以了



<h4>说说Spring Cloud的核心架构吗？</h4>
<img  src="/src/main/resources/img-demo/advanced/springbootcloud.jpg">
<p>eureka、ribbon、feign、zuul、hystrix、链路追踪、其他组件，服务于分布式系统的，hystrix主要用于服务之间调用的熔断、隔离、降级

<p> 细节后面加

<h3> JVM 初级 </h3>
<p>jvm笔记有详细  但不是很详细
<h4>JVM中有哪几块内存区域？Java 8之后对内存分代做了什么改进？</h4>
<p>执行我们的一些对象的方法，执行代码的时候肯定会有很多的线程，tomcat里就有很多自己的工作线程，去执行我们写的代码，每个工作线程都会有自己的一块数据结构，栈内存，这个里面是存放一些东西
<p>java 8以后的内存分代的改进，永久代里放了一些常量池+类信息，常量池 -> 堆里面，类信息 -> metaspace（元区域）

<h4>JVM是如何运行起来的？我们的对象是如何分配的？</h4>

<p>比如说我们有一个类里面包含了一个main方法，你去执行这个main方法，此时会自动一个jvm进程，他会默认就会有一个main线程，这个main线程就负责执行这个main方法的代码，进而创建各种对象
<p>tomcat，类都会加载到jvm里去，spring容器而言都会对我们的类进行实例化成bean，有工作线程会来执行我们的bean实例对象里的方法和代码，进而也会创建其他的各种对象，实现业务逻辑

<h4>JVM在哪些情况下会触发垃圾回收</h4>
<p>jvm的内存其实是有限制的，不可能是无限的，昂贵的资源，2核4G的机器，堆内存也就2GB左右，4核8G的机器，堆内存可能也就4G左右，栈内存也需要空间，metaspace区域放类信息也需要空间
<p>在jvm里必然是有一个内存分代模型，年轻代和老年代
<p>比如说给年轻代一共是2GB内存，给老年代是2GB内存，默认情况下eden和2个s的比例：8:1:1，eden是1.6GB，S是0.2GB
<p>如果说eden区域满了，此时必然触发垃圾回收，young gc，ygc，谁是可以回收的垃圾对象呢？就是没有人引用的对象就是垃圾对象

<h4> JVM的年轻代垃圾回收算法？对象什么时候转移到老年代？</h4>
<p>如果说你让代码一边运行，一边有变动，一边判断哪些对象是可以回收的，这个是不现实的，垃圾回收的时候有一个概念，叫做stop the world，停止你的jvm里的工作线程的运行，然后扫描所有的对象，判断哪些可以回收，哪些不可以回收的
<p>年轻代，大部分情况下，对象生存周期是很短的，可能在0.01ms之内，线程执行了3个方法，创建了几个对象，0.01ms之后就方法都执行结束了，此时那几个对象就会在0.01ms之内变成垃圾，可以回收的
<p>复制算法，一次young gc，年轻代的垃圾回收
<p>三种场景，
<li> 1   在新生代 Survivor被回收次数默认为15，会进入老年代
<li> 2  大对象会直接进入老年代
<li> 3  当Survivor区相当年龄的对象 大小超过Survivor的一般  年龄大于或等于该年龄的对象进去老年代

<h4>老年代的垃圾回收算法？常用的垃圾回收器都有什么？</h4>
<p>GC 算法原理（垃圾收集算法）
<li>基础：标记 - 清除算法
<li>解决效率问题：复制算法
<li>解决空间碎片问题：标记 - 整理算法
<li>进化：分代收集算法
<p>GC 算法的真正实现：7 个垃圾收集器
<li>新生代：Serial、ParNew、Parallel Scavenge
<li>老年代：Serial Old、Parallel Old、CMS
<li>全能：G1

<p>老年代对象越来越多，是不是会发现说，老年代的内存空间也会满的，可以不可以使用类似年轻代的复制算法，不合适的，因为老年代里的对象，很多都是被长期引用的，spring容器管理的各种bean
<p>对老年代而言，他里面垃圾对象可能是没有那么多的，标记-清理，找出来那些垃圾对象，然后直接把垃圾对象在老年代里清理掉，标记-整理，把老年代里的存活对象标记出来，移动到一起，存活对象压缩到一片内存空间里去
<p>剩余的空间都是垃圾对象整个给清理掉，剩余的都是连续的可用的内存空间，解决了内存碎片的一个问题
<p>parnew+cms的组合，g1直接分代回收，新版本，慢慢的就是主推g1垃圾回收器了，以后会淘汰掉parnew+cms的组合，jdk 8~jdk 9比较居多一些，parnew+cms的组合比较多一些，是这么一个情况
<p>分成好几个阶段，初始标记，并发标记，并发清理，等等，老年代垃圾回收是比较慢的，一般起码比年轻代垃圾回收慢个10倍以上，cms的垃圾回收算法，刚开始用标记-清理，标记出来垃圾对象，清理掉一些垃圾对象，整理，把一些存活的对象压缩到一起，避免内存碎片的产生
<p>执行一个比较慢的垃圾回收，还要stop the world，需要100mb，此时就会让系统停顿100ms，不能处理任何请求，尽可能的让垃圾回收和工作线程的运行，并发着来执行

<h4>生产环境中的Tomat是如何设置JVM参数的？如何检查JVM运行情况？</h4>
<p>你确实必须得去看一下你当前生产系统的jvm参数都是如何设置的，如果说你是tomcat部署的java web系统，jvm进程对应的tomcat自己，你的系统仅仅是在tomcat的jvm进程来执行
<p>tomcat的一个配置脚本，catalina脚本里去找一下，jvm专栏都有说明的，里面是有对应的tomcat启动的一些jvm参数的设置
<p>比如通过java命令直接启动你的一个main方法跑起来的系统，就是你自己启动的时候，java命令可以带上一些jvm参数
<p>对你自己系统的jvm参数有一个了解，内存区域大小的分配，每个线程的栈大小，metaspace大小，堆内存的大小，年轻代和老年代分别的大小，eden和survivor区域的大小分别是多少，如果没有设置，会有一些默认值
<p>jvm专栏里，在中间有一些地方，他是讲了一些命令的，可以查看jvm的启动默认参数
<p>垃圾回收器，年轻代是用了什么，老年代，每种垃圾回收器是否有对应的一些特殊的参数有设置，那些特殊的参数分别都是用来干什么的
<p>为什么要这么设置呢？当前线上系统运行的时候，jvm的表现如何？
<p>预估完毕之后，根据预估的情况，可以去设置一些jvm参数
<p>进行压测，在压测的时候，其实就需要去观察jvm运行的情况，jstat工具去分析jvm运行的情况，他的年轻代里的eden区域的对象增长的情况，ygc的频率，每次ygc过后有多少对象存活，s能否放的下，老年代对象增长速率，老年代多久会触发一次fgc
<p>就可以根据压测的情况去进行一定的jvm参数的调优，一个系统的QPS，一个是系统的接口的性能，压测到一定程度的时候 ，机器的cpu、内存、io、磁盘的一些负载情况，jvm的表现
<p>可能需要对一些代码进行优化，比如优化性能，或者减轻一点cpu负担，减轻io和磁盘负担，发现jvm的gc过于频繁，内存泄漏，此时就需要对jvm的各个内存区域的大小以及一些参数进行调优
<p>跑到线上实际生产环境里去，运行的过程中，也需要基于一些监控工具，或者是jstat，除了观察系统的QPS和性能，接口可用性，调用成功率，机器的负载，jvm的表现，gc的频率，gc耗时，内存的消耗


<h4>你在实际项目中是否做过JVM GC优化，怎么做的？</h4>
<p> 主要还是上面那个

<h4> 发生OOM之后，应该如何排查和处理线上系统的OOM问题？</h4>
<p>找他自动导出的内存快照，分析，XX对象，直接去定位代码，修改代码
<p>你一定要把案例的业务、背景和思想给吸收了，就得融入到自己的业务里去，我负责的业务系统，在什么样的情况下，可能说会出现一大批的对象卡在内存里，无法回收，导致我系统没法放更多的对象了
<p>产生OOM，内存泄漏的问题，少数场景在互联网公司，超高并发下的oom问题，瞬时大量存活对象占据内存， 导致没法创建更多的对象了
<p>你也得去思考，甚至去模拟一下，最好可以模拟出来，oom不是你自己的代码，可能是你依赖的第三方的组件，netty导致的，结合自己的项目去一步一步的分析，oom问题的产生，和解决的过程

<h3>网络协议</h3>
<h4> 你能聊聊TCP/IP四层网络模型吗？OSI七层网络模型也说一下！</h4>
<p>设想一下，各个电脑厂商，比如IBM、苹果啥的，都弄自己的协议，结果就苹果电脑和苹果电脑自己可以通信，和IBM电脑就不可以通信，这不是尴尬么。所以搞一个国际通行的协议，大家都按照这个来，所有电脑都可以通信，不是很好么。
<p> 
<p>此时就必须搞一个标准的网络模型出来，大家都按照这个来走，大家都要遵守统一的规范。这就是所谓OSI七层模型，他们分别是：应用层、表示层、会话层、传输层、网络层、数据链路层、物理层。那么在这个基础上，又简化出了TCP/IP四层模型，数据链路层、网络层、传输层、应用层
<a href="https://mp.weixin.qq.com/s/MV1-UeiOzwKm_xWlNSFUvA">详细博客</a>
<img  src="/src/main/resources/img-demo/advanced/osi.jpg">
<p> 博客总结
<li>1. 物理层,网线,光纤等，物理层负责传输0和1的电路信号。，计算机的最最底层，就是0/1，电信号
<li>2. 数据链路层,以太网协议，以太网。一组电信号是一个数据包，叫一个帧（frame），每个帧分成两个部分，标头（head）和数据（data）,
<p>一个局域网内的每台机器都有自己的ARP cache，这个ARP就是用来在一个局域网内让各个设备都知道每个设备的ip地址和mac地址的对应关系的
<li>3. 网络层  太网协议通过子网广播,mac地址比较的方式找到对应机器 ,ip+子网掩码 的&运算,判断是不是一个子网  .路由器配置了两块网卡，每个网卡可以连到一个局域网内
<p>ip地址 -> mac地址 -> 交换机 -> 路由器 -> ip地址 -> mac地址 -> 交换机的方式来通过路由器进行通信。
<li>4）传输层  多程序通过端口完成多程序数据传输,udp和tcp都是传输层的协议，作用就是在数据包里加入端口号，可以通过端口号进行点对点的通信了。udp协议是不可靠的，发出去人家收到没有就不知道了；tcp协议是可靠的，要求三次握手，而且要求人家接收到数据必须回复你。
<li>5）应用层 通过传输层的tcp协议可以传输数据 ,这个应用层，我们就假设综合了会话层、表示层和应用层了，3层合成1层。负责解析和处理
<p>DNS服务器，DNS服务器告诉你www.baidu.com对应的ip地址的。

<h4>浏览器请求www.baidu.com的全过程大概是怎么样的</h4>
<li>1 这个时候找DNS服务器，DNS服务器解析域名之后，返回一个ip地址
<li>2 拿到网关ip地址的mac地址的，现在我们从应用层出发，通过浏览器访问一个网站，是走应用层的http协议的，把浏览器发出的请求打包成数据包
<p>比如常见的可以放一个json这就构成了一个http请求报文浏览器请求一个地址，先按照应用层的http协议，封装一个应用层数据包，数据包里就放了http请求报文，这个时候会将这个http请求报文打包成一个数据包，仅仅只是数据包的数据部分，此时是数据包是没有头的。上面根据http协议搞一个http请求报文，然后搞一个数据包出来，就是网络模型中到的应用层干的事儿了。
<li>3 接着就是跑传输层来了，这个层是tcp协议，这个tcp协议会让你设置端口，发送方的端口随机选一个，接收方的端口一般是默认的80端口。
<p>这个时候，会把应用层数据包给封装到tcp数据包中去，而且会加一个tcp头，这个tcp数据包是对应一个tcp头的，这个tcp头里就放了端口号信息
<li>4 接着跑到网络层来了，走ip协议，这个时候会把tcp头和tcp数据包，放到ip数据包里去，然后再搞一个ip头，ip头里本机和目标机器的ip地址。
 <pre>
 这里本机ip地址是192.168.31.37，
 目标机器是172.194.26.108。</pre>
<p>因为，通过ip协议，可以判断说，两个ip地址不是在一个子网内的，所以此时只能将数据包先通过以太网协议广播到网关上去，通过网关再给他发送出去

<li>5 接着是数据链路层，这块走以太网协议，这里是把ip头和ip数据包封到以太网数据包里去，然后再加一个以太网数据包的头，头里放了本机网卡mac地址，和网关的mac地址。但是以太网数据包的限制是1500个字节，但是假设这个时候ip数据包都5000个字节了，那么需要将ip数据包切割一下。
<p>这个时候一个以太网数据包要切割为4个数据包，每个数据包包含了以太网头、ip头和切割后的ip数据包，4个数据包的大小分别是1500，1500,1500，560。ip头里包含了每个数据包的序号。

<li>6 百度服务器接收到4个以太网数据包以后，根据ip头的序号，把4个以太网数据包里的ip数据包给拼起来，就还原成一个完整的ip数据包了。接着就从ip数据包里面拿出来tcp数据包，再从tcp数据包里取出来http数据包，读取出来http数据包里的各种协议内容，接着就是做一些处理，然后再把响应结果封装成htp响应报文，封装在http数据包里，再一样的过程，封装tcp数据包，封装ip数据包，封装以太网数据包，接着通过网关给发回去

<h4>TCP三次握手流程图？为啥是三次而不是二次或者四次呢？</h4>
<p>tcp三次握手过程
<p>通过传输层的tcp协议建立网络连接的时候，其实走的是三次握手的过程
<li>建立三次握手的时候，TCP报头用到了下面几个东西，ACK、SYN、FIN。
<li>第一次握手，客户端发送连接请求报文，此时SYN=1、ACK=0，这就是说这是个连接请求，seq = x，接着客户端处于SYN_SENT状态，等待服务器响应。
<li>第二次握手，服务端收到SYN=1的请求报文，需要返回一个确认报文，ack = x + 1，SYN=1，ACK = 1，seq = y，发送给客户端，自己处于SYN_RECV状态。
<li>第三次握手，客户端收到了报文，将ack = y + 1，ACK = 1，seq = x + 1
<p>其实三次握手说白了，就是来回来去三次请求，每次请求带上一堆TCP报文头，根据报文头是否正确，就是越好的协议来建立连接。简单说就是这样。

 <p>（2）为啥不是2次或者4次握手呢？
<p>假设两次握手就ok了，要是客户端第一次握手过去，结果卡在某个地方了，没到服务端；完了客户端再次重试发送了第一次握手过去，服务端收到了，ok了，大家来回来去，三次握手建立了连接。
<p>结果，尴尬的是，后来那个卡在哪儿的老的第一次握手发到了服务器，服务器直接就返回一个第二次握手，这个时候服务器开辟了资源准备客户端发送数据啥的，结果呢？客户端根本就不会理睬这个发回去的二次握手，因为之前都通信过了。
<p>但是如果是三次握手，那个二次握手发回去，客户端发现根本不对，就会发送个复位的报文过去，让服务器撤销开辟的资源，别等着了。
<p>因为3次握手就够了，不需要4次或者5次浪费资源了

<h5>（3）tcp断开连接的4次挥手</h5>
<li>第一次挥手，客户端发送报文，FIN=1，seq=u，此时进入FIN-WAIT-1状态
<li>第二次挥手，服务端收到报文，这时候进入CLOSE_WATI状态，返回一个报文，ACK=1，ack=u+1，seq=v。客户端收到这个报文之后，直接进入FIN-WAIT-2状态，此时客户端到服务端的连接就释放了。
<li>第三次挥手，服务端发送连接释放报文，FIN=1，ack=u+1，seq=w，服务端进入LAST-ACK状态
<li>第四次挥手，客户端收到连接释放报文之后，发应答报文，ACK=1，ack=w+1，seq=u+1，进入TIME_WAIT状态，等待一会儿客户端进入CLOSED状态，服务端收到报文之后就进入CLOSED状态。

<h4>HTTP协议的工作原理</h4>
<p>http请求封装到应用层数据包，封装在tcp数据包，封装在ip数据包，封装在以太网数据包，如果过大，可能会拆成几个包，走以太网协议+交换机 -> 广播 -> 网关 -> 多个网关 -> 目标的机器 -> 一层一层拆包 -> http请求报文 -> 传递给tomcat -> spring mvc -> http响应 -> 一样的路径会去
<li>http 1.0要指定keep-alive来开启持久连接，默认是短连接，就是浏览器每次请求都要重新建立一次tcp连接，完事儿了就释放tcp连接。早期的网页都很low，没啥东西，就一点文字，就用这个没问题。但是现在，一个网页打开之后，还要加载大量的图片、css、js，这就坑爹了，发送多次请求
<li>http 1.1默认支持长连接，就是说，浏览器打开一个网页之后，底层的tcp连接就保持着，不会立马断开，之后加载css、js之类的请求，都会基于这个tcp连接来走。http 1.1还支持host头，也就可以支持虚拟主机；而且对断点续传有支持。
<p>浏览器，第一次请求去一个网站的一个页面的时候，就会打开一个tcp连接，接着就在一段时间内都不关闭了，然后接下来这个网页加载css、js、图片大量的请求全部走同一个tcp连接，频繁的发送请求获取响应，最后过了一段时间，这些事儿都完了，然后才会去释放那一个tcp连接。大幅度的提升复杂网页的打开的速度，性能。
<li>http 2.0，支持多路复用，基于一个tcp连接并行发送多个请求以及接收响应，解决了http 1.1对同一时间同一个域名的请求有限制的问题。二进制分帧，将传输数据拆分为更小的帧（数据包），frame（数据包，帧），提高了性能，实现低延迟高吞吐

<h4>HTTPS的工作原理？为啥用HTTPS就可以加密通信？</h4>
<p>https的工作原理大概是这样的：
<li>（1）浏览器把自己支持的加密规则发送给网站
<li>（2）网站从这套加密规则里选出来一套加密算法和hash算法，然后把自己的身份信息用证书的方式发回给浏览器，证书里有网站地址、加密公钥、证书颁发机构
<li>（3）浏览器验证证书的合法性，然后浏览器地址栏上会出现一把小锁；浏览器接着生成一串随机数密码，然后用证书里的公钥进行加密，这块走的非对称加密；用约定好的hash算法生成握手消息的hash值，然后用密码对消息进行加密，然后把所有东西都发给网站，这块走的是对称加密
<li>（4）网站，从消息里面可以取出来公钥加密后的随机密码，用本地的私钥对消息解密取出来密码，然后用密码解密浏览器发来的握手消息，计算消息的hash值，并验证与浏览器发送过来的hash值是否一致，最后用密码加密一段握手消息，发给浏览器
<li>（5）浏览器解密握手消息，然后计算消息的hash值，如果跟网站发来的hash一样，握手就结束，之后所有的数据都会由之前浏览器生成的随机密码，然后用对称加密来进行进行加密。

<h4>http的长连接的工作原理到底是啥？</h4>
<p>http本身没什么所谓的长连接短连接之说，其实说白了都是http下层的tcp连接是长连接还是短连接，tcp连接保持长连接，那么多个http请求和响应都可以通过一个链接来走。其实http 1.1之后，默认都是走长连接了，就是底层都是一个网页一个tcp连接，一个网页的所有图片、css、js的资源加载，都走底层一个tcp连接，来多次http请求即可。
<p>http 1.0的时候，底层的tcp是短连接，一个网页发起的请求，每个请求都是先tcp三次握手，然后发送请求，获取响应，然后tcp四次挥手断开连接；每个请求，都会先连接再断开。短连接，建立连接之后，发送个请求，直接连接就给断开了
<p>http 1.1，tcp长连接，tcp三次握手，建立了连接，无论有多少次请求都是走一个tcp连接的，走了n多次请求之后，然后tcp连接被释放掉了