### 收集本人常见的面试题和本人在群或论坛看到的奇怪问题 

## 合集
 + Q: HashMap 
    <pre><code>
     A:（1）HashMap是一种散列表，采用（数组 + 链表 + 红黑树）的存储结构；
       （2）HashMap的默认初始容量为16（1&lt;&lt;4），默认装载因子为0.75f，容量总是2的n次方；
       （3）HashMap扩容时每次容量变为原来的两倍；
       （4）当桶的数量小于64时不会进行树化，只会扩容；
       （5）当桶的数量大于64且单个桶中元素的数量大于8时，进行树化；
       （6）当单个桶中元素数量小于6时，进行反树化；
       （7）HashMap是非线程安全的容器；
       （8）HashMap查找添加元素的时间复杂度都为O(1)；
    </code></pre>
 + hashtable和concurrenthashmap如何实现线程安全？
 [concurrenthashmap 部分代码](./src/main/resources/note/conllection/ConcurrentHashMap.md)
    ````
    A: 1 hashtable 线程安全是在主要方法上加的 synchronized  所以执行效率并不高
       2 concurrenthashmap 
       （1）ConcurrentHashMap是HashMap的线程安全版本；</p>
         （2）ConcurrentHashMap采用（数组 + 链表 + 红黑树）的结构存储元素；</p>
         （3）ConcurrentHashMap相比于同样线程安全的HashTable，效率要高很多；</p>
         （4）ConcurrentHashMap采用的锁有 synchronized，CAS，自旋锁，分段锁，volatile等；</p>
         （5）ConcurrentHashMap中没有threshold和loadFactor这两个字段，而是采用sizeCtl来控制；</p>
         （6）sizeCtl = -1，表示正在进行初始化；</p>
         （7）sizeCtl = 0，默认值，表示后续在真正初始化的时候使用默认容量；</p>
         （8）sizeCtl > 0，在初始化之前存储的是传入的容量，在初始化或扩容后存储的是下一次的扩容门槛； </p>
         （9）sizeCtl = (resizeStamp &lt;&lt; 16) + (1 + nThreads)，表示正在进行扩容，高位存储扩容邮戳，低位存储扩容线程数加1；</p>
         （10）更新操作时如果正在进行扩容，当前线程协助扩容；</p>
         （11）更新操作会采用synchronized锁住当前桶的第一个元素，这是分段锁的思想；</p>
         （12）整个扩容过程都是通过CAS控制sizeCtl这个字段来进行的，这很关键；</p>
         （13）迁移完元素的桶会放置一个ForwardingNode节点，以标识该桶迁移完毕；</p>
         （14）元素个数的存储也是采用的分段思想，类似于LongAdder的实现；</p>
         （15）元素个数的更新会把不同的线程hash到不同的段上，减少资源争用；</p>
         （16）元素个数的更新如果还是出现多个线程同时更新一个段，则会扩容段（CounterCell）；</p>
         （17）获取元素个数是把所有的段（包括baseCount和CounterCell）相加起来得到的；</p>
         （18）查询操作是不会加锁的，所以ConcurrentHashMap不是强一致性的；</p>
         （19）ConcurrentHashMap中不能存储key或value为null的元素；</p>
         （20）ConcurrentHashMap 扩容大小是原大小两倍 sizeCtl是新的扩容门槛 原来数据会hash&n 分成两部分 低位在原处 高位在原位置+n 处
 
            
    ````
    
    
    
## JVM
  + jvm的内存布局和垃圾回收机制
  [jvm 部分笔记](./src/main/resources/note/JVM%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0.md)
    ````
       1 内存模型
            1.线程私有
                A.程序计数器
                B.本地方法栈
                C.虚拟机栈 （-Xss 128k 默认1M）
                    a 栈帧 （方法执行时创建）
                    1 局部变量表
                    2 操作数栈
                    3 动态链接
                    4 返回地址
            。。。
            2.线程共有
            A.堆区（ 所有java对象和数组）
               a 新生代（1/3）-XXSurvivorRatio：Eden区和Survior区的占用比例 
                    1.Eden空间 
                    |  没有空间时 会执行 MIinor  GC----复制回收算法
                    2.From Survivor空间-----------------------
                    3.To Survivor空间----------------------------Survivor 用做交换 只有一个区有数据
               b 老年代（2/3）
                    1 在新生代 Survivor被回收次数默认为15，会进入老年代
                    2  大对象会直接进入老年代
                    3  当Survivor区相当年龄的对象 大小超过Survivor的一般  年龄大于或等于该年龄的对象进去老年代
                    
                    4 当老年代内存不够 进入FULL GC（新生代，老年代都回收 jvm会停止）
            B.方法区(元数据区)
                 类信息，常量，编译的代码信息
            C 直接内存
       2 回收算法
            标记清除算法(Mark-Sweep )
            复制算法(copying)
            标记整理算法(Mark-Compact)
            分代收集算法
       3  垃圾回收器
        Java 堆内存被划分为新生代和年老代两部分，新生代主要使用复制和标记-清除垃圾回收 算法 ；
        年老代主要使用标记-整理垃圾回收算法，因此 java 虚拟中针对新生代和年老代分别提供了多种不
        同的垃圾收集器
            1 Serial 垃圾收集器  （单线程、 复制算法）
            2 ParNew 垃圾收集器 （ （Serial+多线程 多线程）
            3 Parallel Scavenge  收集器（多线程复制算法、高效）
            4 Serial Old  收集器（单线程标记整理算法 
            5 Parallel Old  收集器（多线程标记整理算法）
            6 CMS 收集器 （多线程标记清除算法）
            7 G1  收集器
    ````
  + 类加载机制和双亲委派模型
    ````
        1 类加载子系统
          负责从文件系统或者网络中加载Class信息，加载的类信息存放于一块称为方法区的内存空间
          JVM 类加载机制分为五个部分：加载，验证，准备，解析，初始化， 验证，准备，解析算连接
          
        2 类加载器
          1 启动类加载器(Bootstrap ClassLoader)
          2 扩展类加载器(Extension ClassLoader)
          3 应用程序类加载器(Application ClassLoader)
          4 自定义加载器
        3  双亲委派
          1 当一个类收到了类加载请求，他首先不会尝试自己去加载这个类，而是把这个请求委派给父
           类去完成，每一个层次类加载器都是如此，因此所有的加载请求都应该传送到启动类加载其中，
           只有当父类加载器反馈自己无法完成这个请求的时候（在它的加载路径下没有找到所需加载的
           Class），子类加载器才会尝试自己去加载。
          2  采用双亲委派的一个好处是比如加载位于 rt.jar 包中的类 java.lang.Object，不管是哪个加载
           器加载这个类，最终都是委托给顶层的启动类加载器进行加载，这样就保证了使用不同的类加载
           器最终得到的都是同样一个 Object 对象
          3 据深入理解jvm所讲 加载器有类名称空间 在同一加载器内 才能判断加载类是否一致   不同加载器加载同一个类 他们并不相等
          
    ````  
   
   
## Spring
   + 阐述事务的隔离级别和传播属性
     ````
     1 spring 传播属性
        PROPAGATION_REQUIRED 如果存在一个事务，则支持当前事务。如果没有事务则开启一个新的事务。
        
        PROPAGATION_SUPPORTS 如果存在一个事务，支持当前事务。如果没有事务，则非事务的执行。但是对于事务同步的事务管理器，PROPAGATION_SUPPORTS与不使用事务有少许不同。
        
        PROPAGATION_MANDATORY 如果已经存在一个事务，支持当前事务。如果没有一个活动的事务，则抛出异常。
        
        PROPAGATION_REQUIRES_NEW 总是开启一个新的事务。如果一个事务已经存在，则将这个存在的事务挂起。
        
        PROPAGATION_NOT_SUPPORTED 总是非事务地执行，并挂起任何存在的事务。
        
        PROPAGATION_NEVER 总是非事务地执行，如果存在一个活动事务，则抛出异常
        
        PROPAGATION_NESTED如果一个活动的事务存在，则运行在一个嵌套的事务中. 如果没有活动事务, 则按TransactionDefinition.PROPAGATION_REQUIRED 属性执行
     
     2 事物 存在的问题
        脏读：事务A读到了事务B未提交的数据。
        不可重复读：事务A第一次查询得到一行记录row1，事务B提交修改后，事务A第二次查询得到row1，但列内容发生了变化。
        幻读：事务A第一次查询得到一行记录row1，事务B提交修改后，事务A第二次查询得到两行记录row1和row2。
        脏读：所谓的脏读，其实就是读到了别的事务回滚前的脏数据。比如事务B执行过程中修改了数据X，在未提交前，事务A读取了X，而事务B却回滚了，这样事务A就形成了脏读。
        
            也就是说，当前事务读到的数据是别的事务想要修改成为的但是没有修改成功的数据。
        
        不可重复读：事务A首先读取了一条数据，然后执行逻辑的时候，事务B将这条数据改变了，然后事务A再次读取的时候，发现数据不匹配了，就是所谓的不可重复读了。
        
            也就是说，当前事务先进行了一次数据读取，然后再次读取到的数据是别的事务修改成功的数据，导致两次读取到的数据不匹配，也就照应了不可重复读的语义。
        
        幻读：事务A首先根据条件索引得到N条数据，然后事务B改变了这N条数据之外的M条或者增添了M条符合事务A搜索条件的数据，导致事务A再次搜索发现有N+M条数据了，就产生了幻读。
        
            也就是说，当前事务读第一次取到的数据比后来读取到数据条目少。
        不可重复读和幻读比较：
             两者有些相似，但是前者针对的是update或delete，后者针对的insert。
      3 spring的隔离级别
        DEFAULT 使用数据库设置的隔离级别 ( 默认 ) ，由 DBA 默认的设置来决定隔离级别 .
        READ_UNCOMMITTED (读未提交)会出现脏读、不可重复读、幻读 ( 隔离级别最低，并发性能高 )
        READ_COMMITTED  (读已提交或者叫不可重复读)会出现不可重复读、幻读问题（锁定正在读取的行）
        REPEATABLE_READ (可重复读 mysql默认)会出幻读（锁定所读取的所有行） 
        SERIALIZABLE 保证所有的情况不会发生（锁表）
        隔离级别等级越高 影响数据越多 性能越差
     ````   

   + <h4>transation 声明式事物的使用
       <h5>transation 使用的情况
       <p> 1. 使用在接口上(不推荐)  接口aop即使用jdk代理会生效 而cglib不会生效
       <p> 1.1 记下spring aop使用哪种代理方式的方式（默认方式）  如果是接口就用jdk的代理 如果是类使用cglib
       <p> 2. 使用类（推荐）
       <p> 2.1 必须使用public 不然不会生效
       <p> 2.2 本地方法调用会失效
       <p> 解释下为什么。。<a href="https://www.ibm.com/developerworks/cn/java/j-master-spring-transactional-use/index.html">参考资料<a>
       <p> 在类上面调用  transation 他的实现方式是这样的
       <p> 源代码   <pre><code>
       public class A {
           a() {
               b();
           }
           //声明事务
           @Transactional
           b() {
               sql操作
           }
       }
       </code></pre>
       <p> 代理生成的代码是这样的
       <pre><code>
       public class Proxy$A {
            A a = new A();
            a() {
                a.a();
            }
            b() {
               //开启事务
               startTransaction();
                a.b();
            }
       }
     </code></pre>
       <p>  实际调用并不是调用的代理类的b() 而是类本身的  所以不会有事物
       <p> 解决办法 强转成代理类<store> ((A)AopContext.currentProxy).b()</store>
   + <h5> transation 主要参数 
       <p> 1. 就是上面spring的传播属性 略
       <p> 2. 回滚异常指定  默认RuntimeException
       <p> 2.1 noRollbackFor 指定后该异常不会回滚
       <p> 2.2 rollbackFor  指定回滚异常类型
       
       <h4> spring bean 的生命周期 
        <p>主要是org.springframework.context.support.AbstractApplicationContext refresh() 方法的 finishBeanFactoryInitialization() 
         <p>1.  Spring对bean进行实例化；
         <p>2.  Spring将值和bean的引用注入到bean对应的属性中；
         <p>3.  如果bean实现了BeanNameAware接口，Spring将bean的ID传递给setBean-Name()方法；
         <p>4.  如果bean实现了BeanFactoryAware接口，Spring将调用setBeanFactory()方法，将BeanFactory容器实例传入；
         <p>5.  如果bean实现了ApplicationContextAware接口，Spring将调用setApplicationContext()方法，将bean所在的应用上下文的引用传入进来；
         <p>6.  如果bean实现了BeanPostProcessor接口，Spring将调用它们的post-ProcessBeforeInitialization()方法；
         <p>7.  如果bean实现了InitializingBean接口，Spring将调用它们的after-PropertiesSet()方法。类似地，如果bean使用initmethod声明了初始化方法，该方法也会被调用；
         <p>8.  如果bean实现了BeanPostProcessor接口，Spring将调用它们的post-ProcessAfterInitialization()方法；
         <p>9.  此时，bean已经准备就绪，可以被应用程序使用了，它们将一直驻留在应用上下文中，直到该应用上下文被销毁；
         <p>10.  如果bean实现了DisposableBean接口，Spring将调用它的destroy()接口方法。(会释放所有已注册的bean)同样，如果bean使用destroy-method声明了销毁方法，该方法也会被调用。
   
   + <h4> spring boot 启动流程（这个有点多 主要是spi 要答上）
       <p> 1） 如果我们使用的是SpringApplication的静态run方法，那么，这个方法里面首先要创建一个SpringApplication对象实例，然后调用这个创建好的SpringApplication的实例方法
           <p> 1.1   根据classpath里面是否存在某个特征类（org.springframework.web.context.ConfigurableWebApplicationContext）来决定是否应该创建一个为Web应用使用的ApplicationContext类型。
           <p> 1.2  使用SpringFactoriesLoader在应用的classpath中查找并加载所有可用的ApplicationContextInitializer。
           <p> 1.3  使用SpringFactoriesLoader在应用的classpath中查找并加载所有可用的ApplicationListener。
           <p> 1.4   推断并设置main方法的定义类。
        <p> 2） SpringApplication实例初始化完成并且完成设置后，就开始执行run方法的逻辑了，方法执行伊始，首先遍历执行所有通过SpringFactoriesLoader可以查找到并加载的SpringApplicationRunListener。调用它们的started()方法，告诉这些SpringApplicationRunListener，开始！
        <p> 3） 创建并配置当前Spring Boot应用将要使用的Environment（包括配置要使用的PropertySource以及Profile）。
        <p> 4） 遍历调用所有SpringApplicationRunListener的environmentPrepared()的方法，告诉他们：“当前SpringBoot应用使用的Environment准备好了咯！”。
        <p> 5） 如果SpringApplication的showBanner属性被设置为true，则打印banner。
        <p> 6） 根据用户是否明确设置了applicationContextClass类型以及初始化阶段的推断结果，决定该为当前SpringBoot应用创建什么类型的ApplicationContext并创建完成，然后根据条件决定是否添加ShutdownHook，决定是否使用自定义的BeanNameGenerator，决定是否使用自定义的ResourceLoader，当然，最重要的，将之前准备好的Environment设置给创建好的ApplicationContext使用。
        <p> 7） ApplicationContext创建好之后，SpringApplication会再次借助Spring-FactoriesLoader，查找并加载classpath中所有可用的ApplicationContext-Initializer，然后遍历调用这些ApplicationContextInitializer的initialize（applicationContext）方法来对已经创建好的ApplicationContext进行进一步的处理。
        <p> 8） 遍历调用所有SpringApplicationRunListener的contextPrepared()方法。
        <p> 9） 最核心的一步，将之前通过@EnableAutoConfiguration获取的所有配置以及其他形式的IoC容器配置加载到已经准备完毕的ApplicationContext。
        <p> 10） 遍历调用所有SpringApplicationRunListener的contextLoaded()方法。
        <p> 11） 调用ApplicationContext的refresh()方法，完成IoC容器可用的最后一道工序。（同spring）
        <p> 12） 查找当前ApplicationContext中是否注册有CommandLineRunner，如果有，则遍历执行它们。
        <p> 13） 正常情况下，遍历执行SpringApplicationRunListener的finished()方法、（如果整个过程出现异常，则依然调用所有SpringApplicationRunListener的finished()方法，只不过这种情况下会将异常信息一并传入处理）
   + <h5> java spi 机制
       <p> springboot 启动很重要的概念 spi 加载各种容器(tomcat ,mvc..) 
       <p> <a href="https://www.jianshu.com/p/0d196ad23915">springboot  spi 的讲解<a>
    
 
## 数据库
#### NoSql
   + redis 的高性能原因
    <p>1. 数据存放在内存中 （这是最主要原因 你放在磁盘 设计再怎么秀 都没用）
    <p>2. 存储的数据 结构简单
    <p>3. 单线程操作 没有阻塞
    <p>4. io模型 多路复用（ 这部分笔记还没重写。）
    <p>5. resp  简单协议 实现简单 解析简单（这个我被问过）
    
   + 一致性Hash算法
        [一致性Hash算法及实现](https://blog.csdn.net/suifeng629/article/details/81567777)
            <p> 解决了服务器增减 产生的 负载均衡问题
            <h5>  hash 环
            <p>一致性Hash算法将整个哈希值空间组织成一个虚拟的圆环，如假设某哈希函数H的值空间为0-2^32-1（即哈希值是一个32位无符号整形） 服务ip 放在上面
            <h5> 数据存放
            <p> 对数据hash(之前写错了  在一致性Hash中没有取摸的操作 2^32 取模 虽然不算错但是不准确) 得到值 在Hash环上顺时针找到服务器节点(逻辑是hash环  实现数据结构应该是有序数组 用二分查找 -可以用TreeMap 直接tailMap() 大于的 第一个就是需要的节点)
            <h5>  如果服务器节点过少 会有负载不均衡的问题（这是hash算法 决定的）
            <p>  解决办法 ：虚拟节点 （生成路由表 虚拟现实对照 虚拟放在hash环  维持负载均衡）
      
     
  <h4> 缓存雪崩，缓存穿透，缓存预热 ，缓存更新，缓存降级
    <h4>1 缓存雪崩
     <p>1.1 由于原有缓存失效，新缓存未到期间(例如：我们设置缓存时采用了相同的过期时间，在同一时刻出现大面积的缓存过期)，所有原本应该访问缓存的请求都去查询数据库了，而对数据库CPU和内存造成巨大压力，严重的会造成数据库宕机
     <p>1.2.1 加锁或者队列的方式保证来保证不会有大量的线程对数据库一次性进行读写(我遇到过这个)
     <p>1.2.2 缓存失效时间分散开，比如我们可以在原有的失效时间基础上增加一个随机值，比如1-5分钟随机，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件
     <p>1.2.3 “二级缓存”的解决方法 加一个缓存标记 标记后通知后台更新 但数据并不会立即过期 时间自己定 这样就不会蹦 后台也会去处理数据
     
   <h4>缓存穿透
   <p>2.1 用户查询数据，在数据库没有，自然在缓存中也不会有。这样就导致用户查询的时候，在缓存中找不到，每次都要去数据库再查询一遍，然后返回空
   <p>2.2.1 最常见的则是采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被这个bitmap拦截掉，从而避免了对底层存储系统的查询压力
   <p>2.2.2  也有一个更为简单粗暴的方法，如果一个查询返回的数据为空（不管是数据不存在，还是系统故障），我们仍然把这个空结果进行缓存
   
   <h4>缓存预热
   <p>3.1 缓存预热就是系统上线后，将相关的缓存数据直接加载到缓存系统。这样就可以避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题！用户直接查询事先被预热的缓存数据
   <p>3.2.1、直接写个缓存刷新页面，上线时手工操作下；
   <p>3.2.2、数据量不大，可以在项目启动的时候自动进行加载；
   <p>3.2.3、定时刷新缓存
   
   <h4>缓存更新 <a href="https://github.com/mood321/springboot-demo/blob/master/springboot-redis/%E7%AC%94%E8%AE%B0.md"> 以前写的redis缓存方案优缺<a>
   <p>4.1除了缓存服务器自带的缓存失效策略之外（Redis默认的有6中策略可供选择），我们还可以根据具体的业务需求进行自定义的缓存淘汰
   <p>4.2.1 最终一致性 定时去清理过期的缓存 
   <p>4.2.2 准一致性  更新数据库后 异步更新缓存（多线程或者队列） 
   <p>4.2.3 强一致性  更新数据库后 主动淘汰缓存  读请求更新缓存 为了避免缓存雪崩 
   <p>更新过程同步 同一时间只能一个请求去更新缓存 为了保证数据一致性 要给数据加上缓存失效时间
   
   <h4> 缓存降级
    <p>当访问量剧增、服务出现问题（如响应时间慢或不响应）或非核心服务影响到核心流程的性能时，仍然需要保证服务还是可用的，即使是有损服务。系统可以根据一些关键数据进行自动降级，也可以配置开关实现人工降级。</p>
    <p >降级的最终目的是保证核心服务可用，即使是有损的。而且有些服务是无法降级的（如加入购物车、结算）。</p>
    <p>在进行降级之前要对系统进行梳理，看看系统是不是可以丢卒保帅；从而梳理出哪些必须誓死保护，哪些可降级；比如可以参考日志级别设置预案：</p>
    <p >（1）一般：比如有些服务偶尔因为网络抖动或者服务正在上线而超时，可以自动降级；</p>
    <p> （2）警告：有些服务在一段时间内成功率有波动（如在95~100%之间），可以自动降级或人工降级，并发送告警；</p>
    <p >（3）错误：比如可用率低于90%，或者数据库连接池被打爆了，或者访问量突然猛增到系统能承受的最大阀值，此时可以根据情况自动降级或者人工降级；</p>
    <p >（4）严重错误：比如因为特殊原因数据错误了，此时需要紧急人工降级。</p>
      
   <h4> redis的过期策略以及内存淘汰机制
   
   <p >redis采用的是定期删除+惰性删除策略。
   <p >为什么不用定时删除策略?
   <p >定时删除,用一个定时器来负责监视key,过期则自动删除。虽然内存及时释放，但是十分消耗CPU资源。在大并发请求下，CPU要将时间应用在处理请求，而不是删除key,因此没有采用这一策略.
   <p >定期删除+惰性删除是如何工作的呢?
   <p >定期删除，redis默认每个100ms检查，是否有过期的key,有过期key则删除。需要说明的是，redis不是每个100ms将所有的key检查一次，而是随机抽取进行检查(如果每隔100ms,全部key进行检查，redis岂不是卡死)。因此，如果只采用定期删除策略，会导致很多key到时间没有删除。
   <p >于是，惰性删除派上用场。也就是说在你获取某个key的时候，redis会检查一下，这个key如果设置了过期时间那么是否过期了？如果过期了此时就会删除。
   <p >采用定期删除+惰性删除就没其他问题了么?
   <p >不是的，如果定期删除没删除key。然后你也没即时去请求key，也就是说惰性删除也没生效。这样，redis的内存会越来越高。那么就应该采用内存淘汰机制。
   <p >在redis.conf中有一行配置
    <pre><code>
   maxmemory-policy volatile-lru   </code></pre>
   <p >该配置就是配内存淘汰策略的(什么，你没配过？好好反省一下自己)
   <p >volatile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰
   <p >volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰
   <p >volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰
   <p >allkeys-lru：从数据集（server.db[i].dict）中挑选最近最少使用的数据淘汰
   <p >allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰
   <p >no-enviction（驱逐）：禁止驱逐数据，新写入操作会报错
   <p >ps：如果没有设置 expire 的key, 不满足先决条件(prerequisites); 那么 volatile-lru, volatile-random 和 volatile-ttl 策略的行为, 和 noeviction(不删除) 基本上一致。
 
 
## 线程
   + 按线程池内部机制，当提交新任务时需要做些什么
    [java多线程线程池和JUC学习笔记](./src/main/resources/note/Java多线程学习笔记-线程池.md)
   <h4>线程池优点</h4>
   <p>1 降低资源的消耗。降低线程创建和销毁的资源消耗；
   <p>2 提高响应速度：线程的创建时间为T1，执行时间T2,销毁时间T3，免去T1和T3的时间
   <p>3 提高线程的可管理性。
   <h4>线程池组件
     <p>1.  线程池管理器：用于创建并管理线程池
     <p>       2.  工作线程：线程池中的线程
     <p>      3.  任务接口：每个任务必须实现的接口，用于工作线程调度其运行
     <p>       4.  任务队列：用于存放待处理的任务，提供一种缓冲机制
     <p>       Java 中的线程池是通过 Executor 框架实现的，该框架中用到了 Executor，Executors，
     <p>       ExecutorService，ThreadPoolExecutor ，Callable 和 Future、FutureTask 这几个类
   <h4>线程池执行机制</h4>
    <pre><code>
           public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize, long keepAliveTime,
           TimeUnit unit, BlockingQueue<Runnable> workQueue) {
                this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue,
                Executors.defaultThreadFactory(), defaultHandler);
           }
    </code></pre>
     <p>  1.  corePoolSize：指定了线程池中的线程数量。
     <p>  2.  maximumPoolSize：指定了线程池中的最大线程数量。
     <p>  3.  keepAliveTime：当前线程池数量超过 corePoolSize 时，多余的空闲线程的存活时间，即多次时间内会被销毁。
     <p> 4.  unit：keepAliveTime 的单位。
     <p> 5.  workQueue：任务队列，被提交但尚未被执行的任务。
     <p>  6.  threadFactory：线程工厂，用于创建线程，一般用默认的即可。
     <p> 7.  handler：拒绝策略，当任务太多来不及处理，如何拒绝任务。
     
   <h4> 拒绝策略
    <blockquote>
     线程池中的线程已经用完了，无法继续为新任务服务，同时，等待队列也已经排满了，再也
     塞不下新任务了。这时候我们就需要拒绝策略机制合理的处理这个问题。
    </blockquote>
    <h5> JDK 内置的拒绝策略如下：
    <p>1. AbortPolicy ： 直接抛出异常，阻止系统正常运行。
    <p>2. CallerRunsPolicy ： 只要线程池未关闭，该策略直接在调用者线程中，运行当前被丢弃的
     任务。显然这样做不会真的丢弃任务，但是，任务提交线程的性能极有可能会急剧下降。
     <p>3. DiscardOldestPolicy ： 丢弃最老的一个请求，也就是即将被执行的一个任务，并尝试再
     次提交当前任务。
    <p> 4. DiscardPolicy ： 该策略默默地丢弃无法处理的任务，不予任何处理。如果允许任务丢
     失，这是最好的一种方案。
    <p> 以上内置拒绝策略均实现了 RejectedExecutionHandler 接口，若以上策略仍无法满足实际
     需要，完全可以自己扩展 RejectedExecutionHandler 接口。   
    <h4> Java 线程池工作过程
     <p>      1.  线程池刚创建时，里面没有一个线程。任务队列是作为参数传进来的。不过，就算队列里面
     <p>      有任务，线程池也不会马上执行它们。
     <p>      2.  当调用 execute() 方法添加一个任务时，线程池会做如下判断：
     <p>      a)  如果正在运行的线程数量小于 corePoolSize，那么马上创建线程运行这个任务；
     <p>     b) 如果正在运行的线程数量大于或等于 corePoolSize，那么将这个任务放入队列；
     <p>     c)  如果这时候队列满了，而且正在运行的线程数量小于 maximumPoolSize，那么还是要
          创建非核心线程立刻运行这个任务；
     <p>      d) 如果队列满了，而且正在运行的线程数量大于或等于 maximumPoolSize，那么线程池
           会抛出异常 RejectExecutionException。
      <p>      3.  当一个线程完成任务时，它会从队列中取下一个任务来执行。
      <p>      4.  当一个线程无事可做，超过一定的时间（keepAliveTime）时，线程池会判断，如果当前运
           行的线程数大于 corePoolSize，那么这个线程就被停掉。所以线程池的所有任务完成后，它
           最终会收缩到 corePoolSize 的大小。
   
## 设计
  + 高并发下，如何做到安全的修改同一行数据
    [网上博客大概讲解](https://www.jianshu.com/p/83224c0f3bb9)
    <p>1. 在单体架构中 即数据修改下都在同意jvm下 可以给方法加锁 lock和synchronized 都可以
    <p>2. 在不同jvm中 即分布式下 分布式锁的特性是排他、避免死锁、高可用
    <p>2.1 数据库的乐观锁(通过版本号)或者悲观锁(通过for update)
    <p>2.2.1  Redis的setnx()命令
    <p>2.2.2  Redisson 实现了JDK中的Lock接口，所以使用方式一样，只是Redssion的锁是分布式的 可重入 重入加1  
   [笔记](https://github.com/mood321/springboot-demo/blob/master/springboot-redisson/%E7%AC%94%E8%AE%B0.md)
    <p>。获取锁流程</p>
    <pre><code>  
    1、判断有没有一个叫“abc”的key
    2、如果没有，则在其下设置一个字段为“6f0829ed-bfd3-4e6f-bba3-6f3d66cd176c:Thread-1”，值为“1”的键值对 ，并设置它的过期时间
    3、如果存在，则进一步判断“6f0829ed-bfd3-4e6f-bba3-6f3d66cd176c:Thread-1”是否存在，若存在，则其值加1，并重新设置过期时间
    4、返回“abc”的生存时间（毫秒）
     </code> </pre>
     <p>。释放锁流程
     <pre><code>
     1、判断是否存在一个叫“abc”的key
     2、如果不存在，向Channel中广播一条消息，广播的内容是0，并返回1
     3、如果存在，进一步判断字段6f0829ed-bfd3-4e6f-bba3-6f3d66cd176c:Thread-1是否存在
     4、若字段不存在，返回空，若字段存在，则字段值减1
     5、若减完以后，字段值仍大于0，则返回0
     6、减完后，若字段值小于或等于0，则广播一条消息，广播内容是0，并返回1；
    </code> </pre>
    <p>2.3 Zookeeper一共四种节点类型
    <p>   1 持久型 2 持久带序号 3 临时节点 4 临时带序号节点
    <p>2.3.1 Zookeeper(在某个持久节点添加临时有序节点，判断当前节点是否是序列中最小的节点，如果不是则监听比当前节点还要小的节点。如果是，获取锁成功。当被监听的节点释放了锁(也就是被删除)，会通知当前节点。然后当前节点再尝试获取锁，如此反复)
    <p>2.3.2 Zookeeper 可以同不带序号节点 如果存在 添加会报异常 完成分布式锁的功能

  + a服务调用b服务多接口，响应时间最短方案    
       ````
       用多线程或者线程池跑  拿到返回future（线程池是FutureTask）   
       还有service内多线程执行任务 也可以拿到FutureTask 统一提交或者回滚
      ````
  +  a系统给b系统转100块钱，如何实现
    <p>  产生的问题： 数据一致性,性能问题,重复提交的问题
    <p> 1 事物解决数据一致性问题 2 编程式事物一定程度优化了性能 3 cas 加版本号 完成幂等性
  
  +  多线程下读概率远远大于写概率，如何解决并发问题？
    <p> 1 volatile 多用于一写多读
    <p> 2 自己加读写锁 ReentrantReadWriteLock 多写多读
    <p> 3 CopyOnWrite系列容器  (读多写少  有脏读问题和性能内存问题  他会创建新数组添加 然后添加 把新赋值给原来引用)
 
  + 限流 令牌桶和漏斗算法
    <p>1 漏斗算法
    <p>1.1 请求先放在桶里面（一般是队列） 以一定速度处理桶里请求 请求过多就会溢出（熔断） 能强制限流
    <p>2 令牌桶
    <p>2.1 令牌桶里令牌就是最大请求数 令牌未归还 新的请求拿不到就会被拒绝
## 中间件
#### MQ
   + MQ 重复消费的问题
    <p>1. 问题的产生 
    <p>1.1 可能是生产 给中间件时 中间件答复失败（中间件发送 生产者接受都可能）
    <p>1.2 可能是队列 给消费者时 消费者答复失败（消费者发送 队列接受都可能）
    <p> 解决办法
    <p>  幂等性（乐观锁或者记录是否操作的去重表） 保持对数据处理的唯一
   
   
    
### 其他
#### 不想单独分出来 有不属于上面的
   + http和Https 区别
       <p> 主要区别 http 数据明文 容易被数据拦截 篡改 攻击  https 加密
       <p> 加密方式 主要  对称加密( 用同一个秘钥加密) 非对称加密(一对秘钥 )
       <p> https 流程一般是 1 客户端获取公钥  2 使用公钥加密一个随机数 给服务端 3 公钥加密一个随机数加私钥 给服务端 服务端得到私钥 
       <p> 4 最后客户端和服务端 和非对称的一对秘钥  加解密数据 打到数据安全
   
   + Cookie 和Seesion
        <p> 1 cookie存放在客户端 session 存放在服务端
        <p> 2 cookie 存放在客户端 并不能保证安全性 一个cookie 一般在4k左右 一个浏览器一个站点限制一般是20
        <p> 3 seesion 存放在服务端 数据太多会影响服务器性能
        <p> 4 浏览器禁止cookie 能用url重写 传输
        
   
   